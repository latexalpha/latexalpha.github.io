<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>信号处理-稀疏分解：MP, OMP and BP - ZSY&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="ZSY&#039;s Blogs"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="ZSY&#039;s Blogs"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="本文主要介绍了稀疏分解的基本概念，匹配追踪（MP），正交匹配追踪（OMP）和基追踪（BP）的原理和算法流程。"><meta property="og:type" content="blog"><meta property="og:title" content="信号处理-稀疏分解：MP, OMP and BP"><meta property="og:url" content="https://latexalpha.github.io/696da30c5fab/"><meta property="og:site_name" content="ZSY&#039;s Blog"><meta property="og:description" content="本文主要介绍了稀疏分解的基本概念，匹配追踪（MP），正交匹配追踪（OMP）和基追踪（BP）的原理和算法流程。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://raw.githubusercontent.com/latexalpha/image_bed/main/images23/OMP_algo.jpg"><meta property="article:published_time" content="2024-03-01T06:37:54.000Z"><meta property="article:modified_time" content="2024-03-01T12:40:40.571Z"><meta property="article:author" content="Shangyu ZHAO"><meta property="article:tag" content="DSP"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://raw.githubusercontent.com/latexalpha/image_bed/main/images23/OMP_algo.jpg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://latexalpha.github.io/696da30c5fab/"},"headline":"信号处理-稀疏分解：MP, OMP and BP","image":["https://raw.githubusercontent.com/latexalpha/image_bed/main/images23/OMP_algo.jpg"],"datePublished":"2024-03-01T06:37:54.000Z","dateModified":"2024-03-01T12:40:40.571Z","author":{"@type":"Person","name":"Shangyu ZHAO"},"publisher":{"@type":"Organization","name":"ZSY's Blog","logo":{"@type":"ImageObject","url":"https://latexalpha.github.io/img/logo.png"}},"description":"本文主要介绍了稀疏分解的基本概念，匹配追踪（MP），正交匹配追踪（OMP）和基追踪（BP）的原理和算法流程。"}</script><link rel="canonical" href="https://latexalpha.github.io/696da30c5fab/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.0.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.png" alt="ZSY&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">博客主页</a><a class="navbar-item" href="/archives">博客归档</a><a class="navbar-item" href="/academic-index">学术索引</a><a class="navbar-item" href="/official-projects">项目文档</a><a class="navbar-item" href="/online-resources">在线资源</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Google Scholar" href="https://scholar.google.com/"><i class="fab fa-google"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2024-03-01T06:37:54.000Z" title="2024/3/1 14:37:54">2024-03-01</time>发表</span><span class="level-item"><time dateTime="2024-03-01T12:40:40.571Z" title="2024/3/1 20:40:40">2024-03-01</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E7%9F%A5%E8%AF%86%E5%AD%A6%E4%B9%A0/">知识学习</a></span><span class="level-item">19 分钟读完 (大约2922个字)</span></div></div><h1 class="title is-3 is-size-4-mobile">信号处理-稀疏分解：MP, OMP and BP</h1><div class="content"><p>本文主要介绍了稀疏分解的基本概念，匹配追踪（MP），正交匹配追踪（OMP）和基追踪（BP）的原理和算法流程。</p>
<span id="more"></span>

<p>[[2021-03-19稀疏分解.pdf]]</p>
<h2 id="稀疏分解的基本概念"><a href="#稀疏分解的基本概念" class="headerlink" title="稀疏分解的基本概念"></a>稀疏分解的基本概念</h2><p>稀疏分解，又称为稀疏近似、稀疏表示（Sparse Decomposition &#x2F; Sparse Approximation &#x2F; Sparse Representation of Signals）</p>
<p>假定信号为$f$，其长度为$n$，<em>Hilbert</em>空间记为$H$，在希尔伯特空间$H$里，由一组向量${x_1, x_2, ⋯, x_m}$构成字典矩阵$D$，其中每个列向量为一个原子，其长度与被表示的信号$f$的长度相同，并且这些向量已经经过归一化处理，即每一个列向量都是单位向量，其模长为1.</p>
<p>如果字典的原子张成了整个信号空间，那么字典就是完全的。如果有原子之间线性相关，那么字典就是冗余的。在大多数稀疏分解的应用中，字典都是完全且冗余的。</p>
<blockquote>
<p>用数学语言表示为：$|x_i| &#x3D; 1, 1 ≤ i ≤ m$，</p>
</blockquote>
<p>信号可以被表示成为这些原子的稀疏表示，也就是信号 <em>f</em> 可以被表示为$f &#x3D; Dβ$，或者是$f ≈ Dβ, ∥f − Dβ∥p ≤ ε$。</p>
<blockquote>
<p>字典矩阵中所谓的过完备性（有时也称作冗余，over-complete&#x2F;redundant），指的是原子的个数远远大于信号的长度，即为：$n ≪ m$.</p>
</blockquote>
<p>信号的稀疏分解，也就是需要求出$β$。由于字典矩阵是冗余的，原子之间存在相关关系，所以信号的稀疏表示不唯一，问题的关键在于如何找到一个最优表示（Optimal Representation）。最直观的方式就是找到一个内积最大的表示，这也就是后面说到的匹配追踪的思想。</p>
<h2 id="匹配追踪（Matching-Pursuit）"><a href="#匹配追踪（Matching-Pursuit）" class="headerlink" title="匹配追踪（Matching Pursuit）"></a>匹配追踪（Matching Pursuit）</h2><h3 id="匹配追踪概述"><a href="#匹配追踪概述" class="headerlink" title="匹配追踪概述"></a>匹配追踪概述</h3><p>匹配追踪是对信号进行稀疏分解的经典方法，它将信号在完备字典库上进行分解。</p>
<p>MP算法的基本思想是：从字典矩阵$D$（也称为过完备字典库）里选择一个与信号$f$最为匹配的原子，也就是选择某一个列向量，构建一个稀疏近似，并求出信号的残差，然后继续选择与信号残差最匹配的原子，反复迭代该过程，直至达到终止条件。最终信号$f$便可以由选择的这些原子表示出来(<strong>由于选择的字典矩阵是完备的，其中的某一个原子可能可以由其他的原子线性表示出来，所以这个表示不一定的线性的。</strong>)有以下几个问题需要回答：</p>
<ul>
<li>（1）如何选择与信号$f$最为匹配的原子呢？</li>
<li>（2）如何构建稀疏近似并求出残差呢？</li>
<li>（3）如何进行迭代呢？</li>
</ul>
<p>（1）计算信号<em>f</em>与字典矩阵$D$里的每一个原子的内积（也就是和字典矩阵的每一列作内积），内积绝对值最大的一个原子即为本次迭代中与信号$f$最为匹配的原子。 用数学语言描述就是：</p>
<p>$$<br>f ∈ H, R_0f &#x3D; f |⟨f, x_{r_0}⟩| &#x3D; sup_{i ∈ {1, ⋯, k}}|⟨f, x_{r_i}⟩|<br>$$</p>
<p>$<em>r_i</em>$表示字典矩阵$D$的列索引。</p>
<p>(2) 这样，信号$f$就可以被分解为在最匹配原子$x_{r_0}$的投影分量和残差两部分：</p>
<p>$$<br>R_nf&#x3D;\langle R_jf,x_{r_j} \rangle x_{r_j} + R_{j+1}f \tag{1}<br>$$</p>
<p> 在这里的残差和投影分量之间是正交的：$⟨R_{j + 1}f, x_{r_j}⟩ &#x3D; 0$（类似于欧几里得空间的垂直投影的效果，<em>Hilbert</em>空间是欧氏空间的推广）。</p>
<p>(3) 对残差$R_1f$进行上述分解，经过$j$次迭代之后，信号可以表示为:</p>
<p>$$<br>f&#x3D;\sum_{n&#x3D;0}^{j-1}\langle R_nf,x_{r_n} \rangle x_{r_n} + R_jf \tag{2}<br>$$</p>
<h3 id="匹配追踪算法（English）"><a href="#匹配追踪算法（English）" class="headerlink" title="匹配追踪算法（English）"></a>匹配追踪算法（English）</h3><p>Matching pursuit is a greedy algorithm that computes the best nonlinear approximation to a signal in a complete, redundant dictionary. Matching pursuit builds a sequence of sparse approximations to the signal stepwise. Let $D &#x3D; {x_{r_i}}_{i &#x3D; 1}^m$ denote a dictionary of unit-norm atoms. Let $f$be your signal.</p>
<ul>
<li>Start by defining $R_0f &#x3D; f$</li>
<li>Begin the matching pursuit by selecting the atom from the dictionary that maximizes the absolute value of the inner product with $R_0f &#x3D; f$. Denote that atom by $x_{r_0}$.</li>
<li>Form the residual $R_1f$ by subtracting the orthogonal projection of <em>R</em>0<em>f</em> onto the space spanned by $x_{r_0}$.</li>
</ul>
<p>$$<br>R_1f &#x3D; R_0f − ⟨R_0f, x_{r_0}⟩x_{r_0}<br>$$</p>
<ul>
<li>Iterate by repeating steps 2 and 3 on the residual.</li>
</ul>
<p>$$<br>R_{j+1}f&#x3D;R_jf−\langle R_jf,x_{r_j} \rangle x_{r_j}<br>$$</p>
<ul>
<li>Stop the algorithm when you reach some specified stopping criterion. In nonorthogonal (or basic) matching pursuit, the dictionary atoms are not mutually orthogonal vectors. Therefore, subtracting subsequent residuals from the previous one can introduce components that are not orthogonal to the span of previously included atoms.</li>
</ul>
<h3 id="匹配追踪收敛性证明"><a href="#匹配追踪收敛性证明" class="headerlink" title="匹配追踪收敛性证明"></a>匹配追踪收敛性证明</h3><p>The proof of convergence of MP relies essentially on the fact that:</p>
<p>$$<br>\langle R_{j+1}f,x_{r_j} \rangle &#x3D; 0<br>$$</p>
<p>Together with $(2)$, this orthogonality of the residual to the last vector selected leads to the following “energy conservation” equation:</p>
<p>$$<br>|R_jf|^2 &#x3D; |R_{j+1}f|^2 + 2\langle R_jf, x_{r_j} \rangle \langle R_{j+1}f, x_{r_j} \rangle + |\langle R_jf, x_{r_j} \rangle |^2 |x_{r_j}|^2<br>$$</p>
<p>And with $|x_{r_j}|^2 &#x3D; 1$, we get:</p>
<p>$$<br>|R_jf|^2 &#x3D; |R_{j+1}f|^2 +  |\langle R_jf, x_{r_j} \rangle |^2<br>$$</p>
<p>It has been noted that MP algorithm may be derived as a special case of a technique known as Projection Pursuit in the statistics literature.</p>
<h2 id="正交匹配追踪（Orthogonal-Matching-Pursuit）"><a href="#正交匹配追踪（Orthogonal-Matching-Pursuit）" class="headerlink" title="正交匹配追踪（Orthogonal Matching Pursuit）"></a>正交匹配追踪（Orthogonal Matching Pursuit）</h2><h3 id="正交匹配追踪概述"><a href="#正交匹配追踪概述" class="headerlink" title="正交匹配追踪概述"></a>正交匹配追踪概述</h3><p>OMP算法对MP的改进之处在于：在分解的每一步，对所选择的原子全部进行正交化处理，这使得精度要求相同的条件下，OMP算法的收敛速度更快。</p>
<blockquote>
<p>OMP算法分解的每一步，残差与所有选择的原子正交，而MP算法只与最近一次选择的原子正交。</p>
</blockquote>
<p>对于一个长度为$n$的信号来说，OMP的收敛次数一定小于等于$n$次。这一点很好理解，因为OMP是把之前选择的原子进行正交化了，相当于由原来的选择的原子构建了一组正交基，一个有<em>n</em>维的向量，最多也用分解<em>n</em>次。</p>
<blockquote>
<p>最多只需要构建出一个n维的Hilbert空间，这个空间里的所有元素都可以它的一组正交基表示出来。</p>
</blockquote>
<p>对于OMP，关键之处在于理解如何构造出这一组正交基，下面讲述其具体流程。</p>
<h3 id="正交匹配追踪原理"><a href="#正交匹配追踪原理" class="headerlink" title="正交匹配追踪原理"></a>正交匹配追踪原理</h3><p>假定$R_kf$和前面选择的原子都正交，然后推导出来怎么求。</p>
<p>假设$k$阶近似的时候有：</p>
<p>$$<br>f&#x3D;\sum_{n&#x3D;1}^k a_n^k x_n + R_kf, \quad with \quad \langle R_kf,x_n \rangle &#x3D; 0, n&#x3D;{1,\cdots,k} \tag{1}<br>$$</p>
<p>在$k+1$阶近似的时候有：</p>
<p>$$<br>f&#x3D;\sum_{n&#x3D;1}^{k+1} a_n^{k+1} x_n + R_kf, \quad with \quad \langle R_{k+1}f,x_n \rangle &#x3D; 0, n&#x3D;{1,\cdots,k+1} \tag{2}<br>$$</p>
<p>应用$k+1$阶模型减去$k$阶模型，则有：</p>
<p>$$<br>\sum_{n&#x3D;1}^k(a_n^{k+1}-a_n^k)+a_{k+1}^{k+1}x_{k+1}+R_{k+1}f-R_kf&#x3D;0 \tag{3}<br>$$</p>
<p>由于选择的非正交字典矩阵，于是引入一个辅助模型，表示$x_{k+1}$对前$k$项$x_n(n&#x3D;1,\cdots,k)$的依赖：</p>
<p>$$<br>x_{k+1} &#x3D; \sum_{n&#x3D;1}^k b_n^k x_n + r_k \quad with \quad \langle r_k,x_n \rangle &#x3D; 0,n&#x3D;1,\cdots,k \tag{4}<br>$$</p>
<blockquote>
<p>$x_{k+1}$在$span{x_1,\cdots,x_k }$上进行正交投影，后面的项是残差。注意这里的$a和b$表示的是第$k$步。如果$x_{k+1}$和前$k$项线性无关的话，$x_{k+1}&#x3D;r_k$.</p>
<p>$$<br>\sum_{n&#x3D;1}^k b_n^kx_n &#x3D; P_{V_k} x_{k+1} \quad and \quad r_k &#x3D; P_{V_k^+} x_{k+1}<br>$$</p>
</blockquote>
<p>将$(4)$代入$(3)$中，有：</p>
<p>$$<br>\sum_{n&#x3D;1}^k (a_n^{k+1}-a_n^k+a_{k+1}^{k+1} b_n^k)x_n + (a_{k+1}^{k+1} r_k + R_{k+1}f - R_kf) &#x3D; 0 \tag{5}<br>$$</p>
<p>若$(5)$恒成立，则有：</p>
<p>$$<br>a_n^{k+1}-a_n^k+a_{k+1}^{k+1} b_n^k &#x3D; 0 \tag{6}<br>$$</p>
<p>$$<br>a_{k+1}^{k+1} r_k + R_{k+1}f - R_kf &#x3D; 0 \tag{7}<br>$$</p>
<p>令$a_{k+1}^{k+1} &#x3D; \alpha_k$,由$(6)$得：</p>
<p>$$<br>a_n^{k+1} &#x3D; a_n^k - \alpha_k b_n^k<br>$$</p>
<p>其中，</p>
<p>$$<br>\alpha_k &#x3D; \frac{\langle R_kf, x_{k+1} \rangle}{\langle r_k, x_{k+1}\rangle} &#x3D; \frac{\langle R_kf,x_{k+1} \rangle}{|r_k|^2}<br>$$</p>
<blockquote>
<p>由$(7)$可得:</p>
<p>$$<br>\langle  a_{k+1}^{k+1} r_k + R_{k+1}f - R_kf,x_{k+1}\rangle &#x3D; 0<br>$$</p>
<p>于是：</p>
<p>$$<br>\langle  a_{k+1}^{k+1} r_k,x_{k+1} \rangle &#x3D; \langle R_{k+1}f,x_{k+1} \rangle - \langle R_kf,x_{k+1} \rangle<br>$$</p>
<p>则：</p>
<p>$$<br>\alpha_k &#x3D; \frac{\langle R_kf, x_{k+1\rangle}}{\langle r_k, x_{k+1}\rangle}<br>$$</p>
<p>在$(4)$中与$r_k$做内积，可以求得$|r_k|^2$</p>
<p>$$<br>\langle x_{k+1},r_k \rangle &#x3D; \sum_{n&#x3D;1}^k \langle b_n^k x_n,r_k \rangle + \langle r_k,r_k \rangle<br>$$</p>
<p>对于$(4)$，可以求出$b_n^k$.</p>
</blockquote>
<h3 id="正交匹配追踪收敛性证明"><a href="#正交匹配追踪收敛性证明" class="headerlink" title="正交匹配追踪收敛性证明"></a>正交匹配追踪收敛性证明</h3><p>由$(7)$式：$a_{k+1}^{k+1} r_k + R_{k+1}f - R_kf &#x3D; 0$，有</p>
<p>$$<br>\alpha_k r_k + R_{k+1}f &#x3D; R_kf<br>$$</p>
<p>由于$r_k$与$R_{k+1}f$正交，左右同时求$l_2$范数的平方，于是有：</p>
<p>$$<br>\alpha_k^2 r_k^2 + R_{k+1}f^2 + 2 \langle \alpha_k r_k,R_{k+1}f \rangle &#x3D; R_kf^2<br>$$</p>
<p>将$\alpha_k$代入有：</p>
<p>$$<br>|R_{k+1}|^2 &#x3D; |R_k|^2 - \frac{|\langle R_kf,x_{k+1} \rangle |^2}{|r_k|^2}<br>$$</p>
<p>可见随着迭代次数的增加，残差逐渐减小，迭代是收敛的。</p>
<blockquote>
<p>证明$r_k$与$R_{k+1}$正交： $\langle R_{k&#x3D;1}f,x_{k+1} \rangle &#x3D;0$</p>
<p>$$<br>x_{k+1} &#x3D; \sum_{n&#x3D;1}^k b_n^k x_n + r_k\quad with \quad \langle r_k,x_n \rangle &#x3D; 0,n&#x3D;1,\cdots,k<br>$$</p>
<p>$$<br>\langle R_{k+1}, \sum_{n&#x3D;1}^kb_n^k x_n + r_k \rangle &#x3D;0<br>$$</p>
<p>$$<br>\langle R_{k+1}, \sum_{n&#x3D;1}^kb_n^k x_n \rangle + \langle R_{k+1}, r_k \rangle &#x3D;0<br>$$</p>
</blockquote>
<h3 id="算法循环过程说明"><a href="#算法循环过程说明" class="headerlink" title="算法循环过程说明"></a>算法循环过程说明</h3><p><img src="https://raw.githubusercontent.com/latexalpha/image_bed/main/images23/OMP_algo.jpg" alt="OMP_algo.jpg"></p>
<p>算法流程</p>
<ul>
<li>第一步：计算残差与各原子的内积</li>
<li>第二步：寻找最匹配的原子</li>
<li>第三步：是否达到终止条件</li>
<li>第四步：原子重排 $k+0 \leftrightarrow n_{k+1}$，例如找到$\langle R_0f,x_{n_1} \rangle max$，放在第一列</li>
<li>第五步：计算${b_n^k}_{n&#x3D;0}^k$，使其满足期待的正交条件</li>
<li>第六步：令$\alpha_k &#x3D; a_{k+0}^{k+1}$，计算重新分配的系数，更新模型</li>
<li>第七步：循环</li>
</ul>
<p>重新分配系数是为了保证残差和每一个选择的原子正交，加快收敛速度，和MP的差别就在这个$R_{k + 1}f$的更新上。</p>
<h2 id="基追踪（Basic-Pursuit"><a href="#基追踪（Basic-Pursuit" class="headerlink" title="基追踪（Basic Pursuit)"></a>基追踪（Basic Pursuit)</h2><h3 id="基追踪的基本概念"><a href="#基追踪的基本概念" class="headerlink" title="基追踪的基本概念"></a>基追踪的基本概念</h3><p>Basic Pursuit (BP) is a principle (not an algorithm) for decomposing a signal into an ‘optimal’ superposition of dictionary elements, where optimal means having the smallest $l_1$ norm of coefficients among all such decompositions.</p>
<p>$$<br>min | \beta |_1, \quad s.t. \quad D \beta &#x3D; f<br>$$</p>
<p>For dealing with data at noise level $\sigma &gt;0$, they propose approximate decomposition as in:</p>
<p>$$<br>f&#x3D;D \beta + r<br>$$</p>
<p>And solving:</p>
<p>$$<br>min|D \beta - f |_2 ^2 + \lambda_n| \beta |_1<br>$$</p>
<p>with $\lambda_n &#x3D;\sigma \sqrt{2log(#D)}$ depending on the number $#D$ of distinct vectors in the dictionary.<strong>Advantages over MOF(the method of frames), MP, OMP, and BOB(the best orthogonal basis):</strong></p>
<ul>
<li>better sparsity</li>
<li>super-resolution</li>
</ul>
<p>For all those methods mentioned above, nonuniqueness gives the possibility of adaption.</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>匹配追踪（MP）和正交匹配追踪（OMP）都是让 $\beta$（也就是选择的一组参数）的$L_0$-norm最小，BP是让其$L_1$-norm最小，这是这三个方法的区别。</p>
<p>MP和OMP算法：</p>
<p>$$<br>min | \beta | _0, \quad s.t. \quad D \beta &#x3D; f<br>$$</p>
<p>BP方法：</p>
<p>$$<br>min | \beta |_1, \quad s.t. \quad D \beta &#x3D; f<br>$$</p>
<p>稀疏分解方法把信号分解当成一个 ill-posed problem（不适定问题） 进行求解，这其实也是一个反问题，反问题本身大多数都是不适定问题。</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>信号处理-稀疏分解：MP, OMP and BP</p><p><a href="https://latexalpha.github.io/696da30c5fab/">https://latexalpha.github.io/696da30c5fab/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>Shangyu ZHAO</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2024-03-01</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2024-03-01</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/DSP/">DSP</a></div><!--!--></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="https://raw.githubusercontent.com/latexalpha/image_bed/main/images24/202401181822005.jpg" alt="支付宝"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="https://raw.githubusercontent.com/latexalpha/image_bed/main/images24/202401181822198.jpg" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/ecd01a362c8d/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">信号处理基本概念及经典方法</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/a0edf9813915/"><span class="level-item">LabVIEW 基础知识学习记录</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/%E7%9F%A5%E8%AF%86%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">知识学习</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li><li><a class="level is-mobile" href="/categories/%E7%BB%8F%E9%AA%8C%E7%A7%AF%E7%B4%AF/"><span class="level-start"><span class="level-item">经验积累</span></span><span class="level-end"><span class="level-item tag">23</span></span></a></li></ul></div></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="level is-mobile" href="#稀疏分解的基本概念"><span class="level-left"><span class="level-item">稀疏分解的基本概念</span></span></a></li><li><a class="level is-mobile" href="#匹配追踪（Matching-Pursuit）"><span class="level-left"><span class="level-item">匹配追踪（Matching Pursuit）</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#匹配追踪概述"><span class="level-left"><span class="level-item">匹配追踪概述</span></span></a></li><li><a class="level is-mobile" href="#匹配追踪算法（English）"><span class="level-left"><span class="level-item">匹配追踪算法（English）</span></span></a></li><li><a class="level is-mobile" href="#匹配追踪收敛性证明"><span class="level-left"><span class="level-item">匹配追踪收敛性证明</span></span></a></li></ul></li><li><a class="level is-mobile" href="#正交匹配追踪（Orthogonal-Matching-Pursuit）"><span class="level-left"><span class="level-item">正交匹配追踪（Orthogonal Matching Pursuit）</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#正交匹配追踪概述"><span class="level-left"><span class="level-item">正交匹配追踪概述</span></span></a></li><li><a class="level is-mobile" href="#正交匹配追踪原理"><span class="level-left"><span class="level-item">正交匹配追踪原理</span></span></a></li><li><a class="level is-mobile" href="#正交匹配追踪收敛性证明"><span class="level-left"><span class="level-item">正交匹配追踪收敛性证明</span></span></a></li><li><a class="level is-mobile" href="#算法循环过程说明"><span class="level-left"><span class="level-item">算法循环过程说明</span></span></a></li></ul></li><li><a class="level is-mobile" href="#基追踪（Basic-Pursuit"><span class="level-left"><span class="level-item">基追踪（Basic Pursuit)</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#基追踪的基本概念"><span class="level-left"><span class="level-item">基追踪的基本概念</span></span></a></li></ul></li><li><a class="level is-mobile" href="#总结"><span class="level-left"><span class="level-item">总结</span></span></a></li></ul></div></div><script src="/js/toc.js" defer></script></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.png" alt="ZSY&#039;s Blog" height="28"><p class="is-size-7"><span>&copy; 2024 Shangyu ZHAO</span></p></a><p class="is-size-7"></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Hexo documentation" href="https://hexo.io/docs/"><i class="fas fa-book"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Hexo theme icarus" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-right",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/javascript" id="MathJax-script" async>MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      },
      svg: {
        fontCache: 'global'
      },
      chtml: {
        matchFontHeight: false
      }
    };</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js"></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>