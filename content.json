{"posts":[{"title":"编程经验积累","text":"本文主要记录了 Python 和 C++ 编程的一些经验知识。 编程语言List of programming languages TIOBE Index 编程语言 官方文档 C# C++ MS Cpp Docs CSS HTML Markdown Java JAVA Docs JavaScript JavaScript Docs LaTex LaTeX Docs Matlab Matlab Docs Python Python Docs Rust Rust Docs TypeScript C++ 编程经验积累C++ 是一种编译型语言。以下是一些有用的 C++ 学习资源和教程： Standard C++ (isocpp.org) Get Started! : Standard C++ (isocpp.org) cplusplus.com cplusplus.com/doc/tutorial/ C++ Programming Language - GeeksforGeeks Makefile Tutorial By Example Python 编程经验积累本文主要记录了 Python 编程的一些经验知识，包括 Python Style Guide, Python 开发环境及工作流, Python 深度学习项目管理等内容。 Python 简介及官方文档 Python website Python Documentation The Python Tutorial The Python Standard Library The Python Language Reference PyPI · The Python Package Index Python Style Guide PEP 8 – Style Guide for Python Code | peps.python.org PEP 8: The Style Guide for Python Code Google Python Style Guide Python 开发环境及工作流 An Effective Python Environment: Making Yourself at Home - Real Python Python 创建自己的包 Make your own Python package Packaging Python Projects — Python Packaging User Guide 6. Modules Python Modules - GeeksforGeeks Python 深度学习项目管理 Cookiecutter Data Science Organizing machine learning projects How to Organize Deep Learning Projects - Examples of Best Practices - neptune.ai Organizing machine learning projects: project management guidelines.","link":"/09479062e9b3/"},{"title":"Python 开发环境管理","text":"本文主要记录了 Python 开发环境管理的方法，包括 Miniconda 管理 Python 开发环境、Pyenv 和 Pipenv 管理 Python 开发环境等。 Python 开发环境管理分为两部分，一个是 Python 版本管理，一个是虚拟环境管理。 虚拟环境管理存在两种方式，第一种是虚拟环境存放于项目文件夹，第二种情况是虚拟环境存放于系统指定文件夹，这时候不同的项目之间可以复用同一个虚拟环境。 Virtual Environments and Packages 使用 Miniconda 管理 Python 开发环境Miniconda 配置 Tensorflow 的开发环境不需要安装 CUDA 和 cuDNN，只需要安装好驱动就可以了！ 1234567conda create -n environment_name python=X.X # 用 conda 创建 Python 虚拟环境conda activate your_env_name # 激活虚拟环境conda deactivate # 取消激活虚拟环境conda install -n your_env_name [package]conda info -e # 查看虚拟环境conda remove --name your_env_name --all # 删除一个已有的虚拟环境pip list # 查看安装的包 Miniconda 安装 Tensorflow GPU 安装 Miniconda，配置虚拟环境 安装 TensorFlow 12# Current stable release for CPU and GPUpip install tensorflow 验证是否安装成功 123456789101112131415161718import tensorflow as tfprint(tf.__version__)GPU_list = tf.config.list_physical_devices('GPU')print(&quot;Num GPUs Available: &quot;, len(GPU_list))sys_details = tf.sysconfig.get_build_info()cuda_version = sys_details[&quot;cuda_version&quot;]print(&quot;CUDA version: &quot;, cuda_version)cudnn_version = sys_details[&quot;cudnn_version&quot;]print(&quot;cuDNN version: &quot;, cudnn_version)cpu_compiler = sys_details[&quot;cpu_compiler&quot;]print(&quot;CPU Compiler: &quot;, cpu_compiler)cuda_compute_capabilities = sys_details[&quot;cuda_compute_capabilities&quot;]print(&quot;CUDA Compute Capabilities: &quot;, cuda_compute_capabilities) Miniconda 安装 PyTorch GPU 安装 Miniconda，配置虚拟环境 安装 Pytorch：在官网复制命令，pip 安装即可。 1pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116 验证是否安装成功 123456789import torchprint(&quot;PyTorch version: &quot;, torch.__version__)cuda_avai = torch.cuda.is_available()print(&quot;Is CUDA available: &quot;, cuda_avai)if cuda_avai: print (&quot;CUDA version: &quot;, torch.version.cuda) print (&quot;cuDNN version: &quot;, torch.backends.cudnn.version ()) 使用 Pyenv 和 Pipenv 管理 Python 开发环境CUDA 和 cuDNN 安装 查看显卡支持的 CUDA 最高版本 Powershell 查看 1nvidia-smi # 即可以得到显卡支持的 CUDA 的最高版本 NVIDIA 控制面板查看 1帮助(H)-系统信息(I)-组件-NVCUDA64.DLL产品名称即可看到最高支持版本 安装 CUDA CUDA(Compute Unified Device Architecture) 下载 Contents - cuda-installation-guide-microsoft-windows 12.0 documentation 直接安装即可，安装完会自动添加两个系统变量和两个环境变量 12345CUDA_PATH C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.4CUDA_PATH_V11_4 C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.4C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.4\\binC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.4\\libnvvp 安装 cuDNN 并配置环境变量 cuDNN(CUDA Deep Neural Network library) 下载 Installation Guide :: NVIDIA Deep Learning cuDNN Documentation 12345# 配置如下环境变量C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.4\\binC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.4\\extras\\CUPTI\\lib64;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.4\\include;C:\\cudnn\\bin 对于 cuDNN 8.7 须下载 zlibwapi.dll 使用 Pyenv 管理 Python 版本 安装 pyenv for Windows 1Invoke-WebRequest -UseBasicParsing -Uri &quot;https://raw.githubusercontent.com/pyenv-win/pyenv-win/master/pyenv-win/install-pyenv-win.ps1&quot; -OutFile &quot;./install-pyenv-win.ps1&quot;; &amp;&quot;./install-pyenv-win.ps1&quot; 重启电脑，安装管理 Python 12345678pyenv --version # 查看 Pyenv 版本pyenv install -lpyenv install 3.9.13pyenv install 3.11.1pyenv versions # 查看系统已安装 Python 版本pyenv global 3.11.1 # 设置 全局 Pythonpyenv version # 查看系统默认 Python 版本python -c &quot;import sys; print(sys.executable)&quot; 设置了 global Python 之后，添加环境变量，使 pipenv.exe 可以运行。 123C:\\Users\\xxxxx\\AppData\\Roaming\\Python\\Python311\\Scripts# 否则在使用 Pipenv 时会报如下错误：# pipenv : 无法将“pipenv”项识别为 cmdlet、函数、脚本文件或可运行程序的名称。请检查名称的拼写，如果包括路径，请确保路径正确，然后再试一次。 使用 Pipenv 管理虚拟环境 安装 Pipenv 1在 Ubuntu 系统中，需要将 pipenv 的路径加入 path `/home/latex/.local/bin`。 使用 Pipenv 创建虚拟环境 12345678910cd project_dir # 进入项目文件夹pipenv install # 创建虚拟环境pipenv install --python 'C:\\Users\\xxxxx\\.pyenv\\pyenv-win\\versions\\3.9.13\\python39.exe' # 创建虚拟环境时指定 Python 版本pipenv shell # 启用虚拟环境pipenv install package # 安装pipenv uninstall package # 卸载pipenv graph # 查看按照包的依赖关系pipenv --venv # 查看虚拟环境执行文件路径exit # 离开虚拟环境pipenv --rm # 删除虚拟环境 Pipenv 安装 Pytorch在原来的命令前，添加 pipenv run 即可。 1pipenv run pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116 Pipenv 安装 Tensorflow-cpu1pipenv install tensorflow Pipenv 安装 Tensorflow-gpu12pipenv install tensorflow-gpu==2.9.0tf.config.list_physical_devices('GPU') # 查看GPU 在终端使用 Pipenv 创建的虚拟环境 Windows 12345678# 激活虚拟环境cd C:\\Users\\xxxxx\\.virtualenvs\\py39_tf29-pMiOFEDH\\Scripts\\cd ~\\.virtualenvs\\py39_tf29-pMiOFEDH\\Scripts\\activateactivate.bat# 退出虚拟环境exit Ubuntu 12345678910# 激活虚拟环境source /home/xxxxx/.local/share/virtualenvs/py39_torch113-4OsuBQPz/bin/activatesource ~/.local/share/virtualenvs/py39_torch113-4OsuBQPz/bin/activate# 在 .bashrc 里定义了 export pvenvs=/home/xxxxx/.local/share/virtualenvs/$pvenvscd py39_XXsource ./bin/activate# 退出虚拟环境deactivate","link":"/7f9fb4fe22ca/"},{"title":"PyTorch 使用经验积累","text":"本文主要记录了 PyTorch 的使用经验，包括 PyTorch 的基本使用、PyTorch 的高级使用、PyTorch 的实现原理等。 Apply LSTM Using PyTorchPyTorch LSTM: The Definitive Guide | cnvrg.io Convolution Implementation in PyTorchConvolution Fourier Convolutions in PyTorch Pytorch 不同参数设置不同的学习率torch.optim 实现方法一：使用 param_groups 参数 123456789101112131415161718192021import torch.optim as optim# Define your modelmodel = ...# Create parameter groupsparams = [ {'params': model.layer1.parameters(), 'lr': 0.01}, {'params': model.layer2.parameters(), 'lr': 0.001}, {'params': model.bias.parameters(), 'lr': 0.005} # All biases with same lr]# Create optimizer with parameter groupsoptimizer = optim.Adam(params)# train modelfor epoch in range(_epochs): optimizer.zero_grad() output = model(input) loss = loss_fn(output, target) loss.backward() optimizer.step() 1234567for input, target in dataset: optimizer.zero_grad() output = model(input) loss = loss_fn(output, target) loss.backward() model.parameters_group.grad *= 100 # scale the gradient on the model optimizer.step() 实现方法二：使用 torch.optim.lr_scheduler 模块 1234567891011121314151617import torch.optim as optimfrom torch.optim.lr_scheduler import StepLRmodel = TheModelClass(*args, **kwargs)optimizer = optim.SGD([ {'params': model.base.parameters()}, {'params': model.classifier.parameters(), 'lr': 1e-3}], lr=1e-2, momentum=0.9)scheduler = StepLR(optimizer, step_size=30, gamma=0.1)for epoch in range(100): scheduler.step() # train model optimizer.zero_grad() output = model(input) loss = loss_fn(output, target) loss.backward() optimizer.step()","link":"/169300face9f/"},{"title":"Tensorflow 使用经验积累","text":"本文主要记录了 Tensorflow 的使用经验，包括 Tensorflow 的基本使用、Tensorflow 的高级使用、Tensorflow 的实现原理等。 一些基础知识Tensor 的一些实例Specific Instances Of Tensors, each of these examples are specific instances of the more general concept of a tensor and can be categorize into two groups: Let’s organize the above list of example tensors into two groups: 12number, array, 2d-array # 数字，数组，二维数组scalar, vector, matrix # 标量，向量，矩阵 The first group of three terms (number, array, 2 d-array) are terms that are typically used in computer science, while the second group (scalar, vector, matrix) are terms that are typically used in mathematics. Tensor 的乘法$$output[\\cdots,i,j] = {sum-k}(a[\\cdots,i,k]*b[\\cdots, k,j])$$ $$\\begin{matrix} &amp;\\begin{matrix}a:2 \\times 3 \\times 2 \\ b: 2 \\times 2 \\times 3\\end{matrix} &amp; \\Rightarrow \\begin{matrix} ab:2\\times3\\times3 \\ ba:2\\times 2 \\times 2 \\end{matrix}\\end{matrix}$$ 神经网络训练，第一个维度是 batch，是因为第一个维度不参与求和过程（和神经网络框架有关， TensorFlow 是这样的）。 设置 Batch SizeKeras Lambda Layer遇到的问题及解决方案 W tensorflow/core/common_runtime/bfc_allocator. Cc: 360] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you’d like to disable this feature. Solution: define environment variables Tensorflow issues &amp; solution No gradients provided for any variable TensorFlow: ‘ValueError: No gradients provided for any variable’ X and y must have the same dtype, got tf. Float 32 != tf. Int 32 Tensorflow error(二):x and y must have the same dtype, got tf.float32 != tf.int32_源的博客-CSDN 博客 Cannot convert an unknown Dimension to a Tensor: ? 将 tensor.shape[0] 改成 tf.shape(tensor)[0] Tensorflow Debug 指南 将 float 64 张量转换为 float 32 TensorFlow：将 float64 张量转换为 float32 - 问答 - Python 中文网 关于 loss 的写法 写 loss function 的时候，需要使用 tensor 来作比较，这样生成的梯度才能和参数有关，才可以训练。如果把 tensor 转为 numpy，则 loss 和参数无关。 TensorFlow Breaking Changes tf2.10 是最后支持 Windows 原生 GPU 的版本 Announcing TensorFlow Official Build Collaborators — The TensorFlow Blog 2.10 last version to support native Windows GPU - General Discussion - TensorFlow Forum tf2.15 是最后默认安装 keras2 的版本，tf2.16 以后的版本会默认安装 keras3 Keras Newsletter (December 1, 2023) - Keras - TensorFlow Forum","link":"/4c4e6d22c4ab/"},{"title":"LaTeX 使用经验积累","text":"本文主要介绍了 LaTeX 的使用经验。 LaTeX 基础知识希腊字母与数学符号 List of LaTeX mathematical symbols 一定要看|希腊字母到底怎么读？360 度解析希腊字母表 重磅推荐|史上最全面最标准的数学符号、公式的英语读法 Cheat Sheet LaTeX cheat sheet latexsheet Documentation A Guide to the Many Flavours of TeX - Overleaf, Online LaTeX Editor TeX 与 LaTeXTeXTEX is a typesetting program designed for high-quality composition of material that contains a lot of mathematical and technical expressions. It has been adopted by many authors and publishers who generate technical books and papers. It was created by Professor Donald E.­Knuth of Stanford University, originally for preparation of his book series “The Art of Computer Programming”. TEX has been made freely available by Knuth. CTAN: Comprehensive TeX Archive Network CTAN: Package texlive TeX engines The differences between TeX engines LaTeXThe commands in TeX and Plain TeX are still quite basic and it isn’t easy to do complicated things with them. To help with this, Leslie Lamport created LaTeX in the early 1980 s to provide a higher level language to work in than TeX. LaTeX is a set of commands defined in terms of the underlying TeX commands, often at many many layers of abstraction. All of the commands you use in a LaTeX document are actually just complicated sets of TeX commands underneath, unless of course you use a TeX command directly! LaTeX - A document preparation system LaTeX, pdfTeX, XeTeX, LuaTeX and ConTeXt Choosing a LaTeX Compiler LaTeX document class Your Guide to documentclass LaTeX: Types and options | LaTeX-Tutorial.com Introduction to LaTeX Free online introduction to LaTeX (part 1) Free online introduction to LaTeX (part 2) Free online introduction to LaTeX (part 3) LaTeX 使用经验项目结构 Multi-file LaTeX projects Management in a large project 类文件 Writing your own class How to write a LaTeX class file and design your own CV (Part 1) How to write a LaTeX class file and design your own CV (Part 2) LaTeX PackagesOverleaf Learn [Amsmath] [Overleaf Learning] [Graphicx] [Overleaf Learning] [Tabularx] [Overleaf Learning] [Hyperref] [Overleaf Learning] [Geometry] [Overleaf Learning] [Biblatex] [Overleaf Learning] [Beamer] [Overleaf Learning] [CTeX] [Overleaf Learning] [TikZ] [Overleaf Learning]","link":"/9f0b9ac5146d/"},{"title":"Ubuntu 使用经验积累","text":"本文主要记录了 Ubuntu 系统的使用经验，包括 Ubuntu 系统的安装配置、Ubuntu 系统的基础知识、Ubuntu 系统的开发环境配置等。 安装配置 Ubuntu 系统 安装系统，设置用户信息 安装 Oh-my-bash 终端美化软件 安装配置 Neovim Nvim 快捷键映射这里的 lua 文件和 Windows 系统里的文件一样，但是需要更新 neovim 的版本，否则会出 bug。更新的方法为：添加源，然后直接更新即可。 Easiest way to update Neovim on Ubuntu 系统基础知识.bashrc 和 .bash_profile 的区别.bash_profile and .bashrc are files that contain commands, aliases, and functions for Bash, a common shell for Linux and macOS 1,2,3,4. .bash_profile is executed only once when you log in to your machine using a username and password, either via console or remotely 1,2,3,5. .bashrc is executed every time you open a new terminal window or a new Bash instance 1,3,5. Use .bash_profile to set up the environment using variables like $PATH 1,2,4. Use .bashrc to customize the shell for interactive use 3,4. What is the difference: .bashrc and bash_profile? .bashrc vs .bash_profile .bashrc vs .bash_profile Apt 和 Apt-get 的区别APT vs APT-GET: What’s the Difference? APT-GET Command in Linux {Detailed Tutorial With Examples} 文件和文件夹管理1234mkdir dir # 创建文件夹rmdir empty_dir # 删除空文件夹rm file1 file2 # 删除文件rm -rf dir # 删除一个非空文件夹和其中的所有文件 使用经验积累 Windows 远程连接 Ubuntu How to Enable Remote Desktop on Ubuntu Desktop 22.04 LTS and Access it from Windows 添加系统变量 1export PATH=&quot;/home/xxxxx/.local/bin:$PATH$&quot; How to add a directory to the PATH? 桌面恢复默认设置 Reset GNOME Desktop Settings to Factory Default on Ubuntu 22.04 Jammy Jellyfish 切换系统语言为英语 Switch Ubuntu Language 安装字体 How to Install Nerd Fonts on Linux Install fonts 基于 Miniconda 配置开发环境基于 Pyenv 和 Pipenv 配置 Python 开发环境CUDA 和 cuDNN 安装Ubuntu 22.04 安装 Cuda11.7 和 cudnn8.6 How to verify CuDNN installation? 安装 Pyenv 管理 Python 版本安装 Pipenv 管理虚拟环境问题和解决方案远程连接桌面显示不一致 添加配置文件 1nvim ~/.xsessionrc 添加如下内容 123export GNOME_SHELL_SESSION_MODE=ubuntuexport XDG_CURRENT_DESKTOP=ubuntu:GNOMEexport XDG_CONFIG_DIRS=/etc/xdg/xdg-ubuntu:/etc/xdg 重启 xrdp 服务 1sudo systemctl restart xrdp.service Ubuntu 使用 CFW关键在于本机代理设置。 Ubuntu 22.04 LTS 安装并配置 Clash - 掘金","link":"/50d715c0809c/"},{"title":"WSL 使用经验积累","text":"本文主要包含了安装配置 WSL，安装 Oh-my-posh 终端美化，安装配置 Neovim，基于 Miniconda 构建 Python 开发环境、利用 Conda 配置 TensorFlow 虚拟环境、配置 PyTorch 虚拟环境、配置 Flax 虚拟环境，WSL GPU 支持，基于 Pyenv 和 Pipenv 配置 Python 开发环境、使用 Git 和 Github 等内容。 安装配置 WSLWindows Subsystem for Linux Documentation | Microsoft Learn 安装 WSL 2 并配置用户信息默认安装的 Linux 版本为 Ubuntu。Install WSL | Microsoft Learn 123wsl --install # 安装 WSL2wsl -l -v # 检查版本wsl --version # 查看版本信息 How to display $PATH as one directory per line? 12apt list --installed # list all installed packagesecho -e ${PATH//:/\\\\n} Error code: Wsl/Service/CreateInstance/GetDefaultDistro/WSL_E_DEFAULT_DISTRO_NOT_FOUND 12# 管理员权限运行 PowerShellEnable-WindowsOptionalFeature -Online -FeatureName Microsoft-Windows-Subsystem-Linux WSL 配置代理服务1234567891011# 创建 C:\\users\\username\\.wslconfig 文件，添加如下内容[experimental]autoMemoryReclaim=gradualnetworkingMode=mirroreddnsTunneling=truefirewall=trueautoProxy=true# 在 .bashrc 文件中添加如下内容export ALL_PROXY=&quot;http://host_ip:port&quot; # 其中，host_ip 为 Windows的 IP 地址，port 为代理服务器的端口号# host_ip 可以通过在 Windows 的 CMD 中输入 ipconfig 查看# 需要注意的是，需要在代理软件中开启允许局域网访问的选项 安装 Oh-my-posh 终端美化首先需要安装 Oh-my-posh, 因为安装完了之后会生成新的 .bashrc 文件。 123curl -s https://ohmyposh.dev/install.sh | sudo bash -s # 安装 OMP# 将如下内容添加到 .bashrc 文件中eval &quot;$(oh-my-posh init bash --config /root/.cache/oh-my-posh/themes/paradox.omp.json)&quot; # 配置自定义路径的 主题 升级 Node.js123456sudo apt update# install nvmcurl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.35.3/install.sh | bashsource ~/.bashrcnvm install nodenode -v 安装配置 Neovim 安装 Neovim 123sudo add-apt-repository ppa:neovim-ppa/unstable # add the reposudo add-apt-repository --remove ppa:neovim-ppa/stable # remove ppasudo apt update &amp;&amp; sudo apt install neovim # update &amp; install 安装 C++ 编译器 12345sudo apt updatesudo apt install npm # 安装 Node.js 和 npmsudo apt install build-essentialsudo apt-get install manpages-devgcc --version 配置 Neovim 12345678mkdir ~/.config/ # 创建配置文件夹mkdir ~/.config/nvim # 创建 nvim 配置文件夹export nvim_path=/home/latex/.config/nvim/cd $nvim_pathgit initgit branch -M maingit remote add origin https://github.com/Latexalpha/nvimgit pull origin main 安装 tree-sitter 1npm install -g tree-sitter-cli 安装 Python 插件 1pip install pynvim debuypy 安装 ripgrep, fd-find, fswatch 123sudo apt install ripgrepsudo apt install fd-findsudo apt install fswatch 基于 Miniconda 配置 Python 开发环境Set up a WSL development environment | Microsoft Learn 安装 Miniconda1234sudo apt updatesudo apt install wgetwget https://repo.anaconda.com/miniconda/Miniconda3-py311_23.5.2-0-Linux-x86_64.shsh ./Miniconda3-py311_23.5.2-0-Linux-x86_64.sh # 这里的同意需要按很久 &lt;CR&gt; 需要将 Neovim 的全局 Python 设为 conda base 需要为每一个虚拟环境安装 pynvim 和 debugpy 1pip install pynvim debugpy # 安装 pynvim 和 debugpy 配置 TensorFlow 开发环境12conda create -n tf2.15 python=3.11 # 注意这里使用的 Python 版本最好和 Conda base 的版本不一样conda activate tf2.15 安装步骤参考官网，非常简单。 Install TensorFlow with pip Use CuDNNLSTM in TF 2 python - Is there cudnnLSTM or cudNNGRU alternative in tensorflow 2.0 - Stack Overflow 配置 PyTorch 开发环境12conda create -n torch2.1 python=3.11.4 # 注意这里使用的 Python 版本最好和 Conda base 的版本不一样conda activate torch2.1 安装步骤参考官网，非常简单（选择 Linux 系统）。Start Locally | PyTorch 配置 Flax 开发环境 首先安装 JAX GPU 版Installing JAX — JAX documentation 然后安装 FlaxInstallation — Flax documentation WSL GPU 支持WSL 的 GPU 支持由 WIndows 的驱动提供，安装了 WSL 之后无需重新安装驱动。 需要注意的是，所有的操作都需要在激活了 TensorFlow 虚拟环境的条件下进行，否则会报错。 需要在 Windows 安装支持 WSL 的 Nvidia 驱动，只要在 linux 终端输入 nvidia-smi 有输出完整的信息，就代表驱动安装好了。 CUDA Version N/A GitHub issue 1234mkdir -p $CONDA_PREFIX/etc/conda/activate.decho 'CUDNN_PATH=$(dirname $(python -c &quot;import nvidia.cudnn;print(nvidia.cudnn.__file__)&quot;))' &gt;&gt; $CONDA_PREFIX/etc/conda/activate.d/env_vars.shecho 'export LD_LIBRARY_PATH=$CONDA_PREFIX/lib/:$CUDNN_PATH/lib:$LD_LIBRARY_PATH' &gt;&gt; $CONDA_PREFIX/etc/conda/activate.d/env_vars.shsource $CONDA_PREFIX/etc/conda/activate.d/env_vars.sh libcuda.so Stack Overflow 12345cd \\Windows\\System32\\lxss\\libdel libcuda.sodel libcuda.so.1mklink libcuda.so libcuda.so.1.1mklink libcuda.so.1 libcuda.so.1.1 libdevice.10.bc GitHub issue 1234mkdir -p $CONDA_PREFIX/lib/nvvm/libdevice/cp -p $CONDA_PREFIX/lib/libdevice.10.bc $CONDA_PREFIX/lib/nvvm/libdevice/echo 'export XLA_FLAGS=--xla_gpu_cuda_data_dir=$CONDA_PREFIX/lib' &gt;&gt; $CONDA_PREFIX/etc/conda/activate.d/env_vars.shconda install -c nvidia cuda-nvcc --yes could not open file to read NUMA node Stack Overflow 1234import osos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # or any {'0', '1', '2'}# 在代码 import tensorflow 之前加入上面两行import tensorflow as tf Without NUMA support NVIDIA Developer Forums 12import osos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # or any 0 1 2 基于 Pyenv 和 Pipenv 配置 Python 开发环境使用 Pyenv 进行 Python 版本管理 Install pyenv 12345678git clone https://github.com/pyenv/pyenv.git ~/.pyenvecho 'export PYENV_ROOT=&quot;$HOME/.pyenv&quot;' &gt;&gt; ~/.bashrcecho 'export PATH=&quot;$PYENV_ROOT/bin:$PATH&quot;' &gt;&gt; ~/.bashrcecho -e 'if command -v pyenv 1&gt;/dev/null 2&gt;&amp;1; then\\n eval &quot;$(pyenv init -)&quot;\\nfi' &gt;&gt; ~/.bashrcexec &quot;$SHELL&quot;which python3 # show where is python3ls -ls /usr/bin/python* Install Python by pyenv 12345# Installing libraries that need for installing Pythonsudo apt-get install -y make build-essential libssl-dev zlib1g-dev libbz2-dev libreadline-dev libsqlite3-dev wget curl llvm libncurses5-dev libncursesw5-dev xz-utils tk-dev# Installing Pythonpyenv install 3.9.13pyenv global 3.9.13 Installing pyenv, and Python by pyenv on WSL (Ubuntu 18.04 LTS) How to uninstall python3 from Ubuntu How to Install and Manage Multiple Python Versions in WSL2 使用 Pipenv 管理 Python 虚拟环境 Pipenv 安装与配置 123456sudo apt install python3-pip # 安装 pipsudo apt install pippip3 install pipenv # 使用 pip3 安装 pipenvexport PATH=&quot;/home/user/.local/bin:$PATH&quot; # 添加路径到 PATHecho $PATH # show pathecho &quot;${PATH//:/$'\\n'}&quot; # show path one directory per line PyTorch 123cd the_venv_folderpipenv install --python 3.9pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116 TensorFlow: 太 TMD 复杂了，别整了 使用 Git 和 Github 设置配置文件：用户名与邮箱 12git config --global user.name &quot;example-name&quot;git config --global user.email &quot;example@outlook.com&quot; 设置 Credential Manager (GCM) 12git config --global credential.helper &quot;/mnt/c/Program\\ Files/Git/mingw64/bin/git-credential-manager.exe&quot;# 注意仅支持 https 协议","link":"/bcf7c696dfb0/"},{"title":"Command-line Interface (CLI), Terminal, and Shell","text":"本文主要介绍了 Command-line Interface (CLI), Terminal, and Shell 的基本概念和区别。 基本名词解释 名词 翻译 解释 Command-line interface 命令行界面 Command-line interface - Wikipedia Command line 命令行 Command-line interface - Wikipedia Command prompt 命令提示符 Command-line interface - Wikipedia Command-line interpreter 命令行解释器 List of command-line interpreters - Wikipedia Shell Shell (computing) - Wikipedia Shell script Shell 脚本 Shell script - Wikipedia Terminal (emulator) 终端 Terminal emulator - Wikipedia Console 控制台 System console - Wikipedia 逻辑链 User Command-line interfence (Provided by Terminal or Terminal emulator) Command-line interpreter (Linux: sh class like bash, Windows: cmd or powershell or pwsh) Computer systems Command-line Interface (CLI)The command-line interface evolved from a form of communication conducted by people over teleprinter (TTY) machines. Sometimes these involved sending an order or a confirmation using telex. Early computer systems often used teleprinter as the means of interaction with an operator. The mechanical teleprinter was replaced by a “glass tty”, a keyboard and screen emulating the teleprinter. “Smart” terminals permitted additional functions, such as cursor movement over the entire screen, or local editing of data on the terminal for transmission to the computer. As the microcomputer revolution replaced the traditional – minicomputer + terminals – time sharing architecture, hardware terminals were replaced by terminal emulators — PC software that interpreted terminal signals sent through the PC’s serial ports. These were typically used to interface an organization’s new PC’s with their existing minior mainframe computers, or to connect PC to PC. Some of these PCs were running Bulletin Board System software. 来源 Operating system (OS) command-line interfaces are usually distinct programs supplied with the operating system. A program that implements such a text interface is often called a command-line interpreter, command processor or shell. 来源 Command-line InterpreterIn computing, a command-line interpreter, or command language interpreter, is a blanket term for a certain class of programs designed to read lines of text entered by a user, thus implementing a command-line interface. 来源 Terminal (emulator)A terminal emulator, or terminal application, is a computer program that emulates a video terminal within some other display architecture. Though typically synonymous with a shell or text terminal, the term terminal covers all remote terminals, including graphical interfaces. A terminal emulator inside a graphical user interface is often called a terminal window. A terminal window allows the user access to a text terminal and all its applications such as command-line interfaces (CLI) and text user interface (TUI) applications. 来源 Computer terminal - Wikipedia ConsoleOne meaning of system console, computer console, root console, operator’s console, or simply console is the text entry and display device for system administration messages, particularly those from the BIOS or boot loader, the kernel, from the init system and from the system logger. It is a physical device consisting of a keyboard and a screen, and traditionally is a text terminal, but may also be a graphical terminal. System consoles are generalized to computer terminals, which are abstracted respectively by virtual consoles and terminal emulators. 来源 A console is generally a terminal in the physical sense that is by some definition the primary terminal directly connected to a machine. The console appears to the operating system as a (kernel-implemented) terminals. 来源 ShellIn computing, a shell is a computer program that exposes an operating system’s services to a human user or other programs. In general, operating system shells use either a command-line interface (CLI) or graphical user interface (GUI), depending on a computer’s role and particular operation. It is named a shell because it is the outermost layer around the operating system. 来源 The shell is the name of the program that runs in the terminal, giving you a command prompt, popular ones are sh, bash, zsh, fish, ash, csh (all end in sh). The Shell is a program which processes commands and returns output, like Bash in Linux. 来源 综合比较 What is the difference between Terminal, Console, Shell, and Command Line? - Ask Ubuntu Difference between Terminal, Console, Shell, and Command Line - GeeksforGeeks","link":"/555a61b94d9d/"},{"title":"PowerShell 使用经验积累","text":"本文主要介绍了 PowerShell 的使用经验，包括常用命令、终端美化等。 PowerShell Documentation - PowerShell | Microsoft Learn PowerShell 101 - PowerShell | Microsoft Learn PowerShell 常用命令使用 Get-Alias 命令就可以查看所有的命令别名。 about Aliases - PowerShell | Microsoft Learn Microsoft.PowerShell.Core Module - PowerShell | Microsoft Learn Alias Command Function clc Clear-Content clhy Clear-History 从命令历史记录文件中删除命令历史 clear Clear-Host 清除当前 Host 的命令历史展示 copy/cp/cpi Copy-Item 复制文件 gal Get-Alias 查看命令别名 gci/ls/dir Get-ChildItem 获取当前文件夹下文件及子文件夹 gcm Get-Command 查询命令信息 gl/pwd Get-Location 获取当前文件夹 ghy/h/history Get-History 历史命令 man/help Get-Help 帮助 mi/mv/move Move-Item 移动文件 ni/md/mkdir New-Item 创建文件夹 rm/rmdir Remove-Item 删除文件 ren/rni Rename-Item 重命名文件 sl/cd/chdir Set-Location 设置当前工作目录 where/? Where-Object 根据对象的属性值从集合中选择对象 PowerShell 和 Windows PowerShell 的区别Install PowerShell on Windows, Linux, and macOS - PowerShell | Microsoft Learn Differences between Windows PowerShell 5.1 and PowerShell 7.x - PowerShell | Microsoft Learn PowerShell differences on non-Windows platforms - PowerShell | Microsoft Learn 由于 PowerShell 的演进，它从 Windows 专属的工具变成了跨平台的工具，适用于 Windows 系统的 PowerShell 称为 Windows PowerShell。Linux 和 macOS 系统上的 PowerShell 基于 .NET core 开发，而 .NET core 是完全版的 .NET Framework 的子集。由于使用框架的不同，导致有一些在 Windows 系统上可以运行脚本无法在其他的系统上运行。 Windows 用户层面需要注意到的区别有： PowerShell 的可执行文件为 pwsh. Exe, Windows PowerShell 的可执行文件是 powershell. Exe. 安装文件文件夹的区别 123C:\\Program Files\\PowerShell\\7\\pwsh.exe # PowerShellC:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe # Windows PowerShell 配置文件文件夹的区别 1234C:\\Users\\xxxxx\\Documents\\PowerShell\\Microsoft.PowerShell_profile.ps1 # PowerShellC:\\Users\\xxxxx\\Documents\\WindowsPowerShell\\Microsoft.PowerShell_profile.ps1 # Windows PowerShell PowerShell GalleryPowerShell Gallery | Home PowerShellGet and the PowerShell Gallery - PowerShell | Microsoft Learn PowerShell 终端美化Home | Oh My Posh Windows | Oh My Posh Windows Terminal Custom Prompt Setup 下载安装 1winget install JanDeDobbeleer.OhMyPosh -s winget # 安装 Oh My Posh 配置：需要安装 Nerd Fonds 系列字体 Oh My Posh 安装好之后会添加环境变量 POSH_THEMES_PATH，主题就在此文件夹下，可以在 PowerShell 的配置文件中添加如下内容以启用某一主题： 12nvim $profile # 使用 Nvim 编辑 Profile 文件oh-my-posh init pwsh --config &quot;$env:POSH_THEMES_PATH\\jandedobbeleer.omp.json 在 $home 目录显示 Python 虚拟环境，在主题文件里增加如下内容： 12345&quot;properties&quot;: { &quot;fetch_virtual_env&quot;: true, &quot;display_mode&quot;: &quot;environment&quot;, &quot;home_enabled&quot;: true}, Python | Oh My Posh 使用经验更改 Power Shell 的执行策略在计算机上启动 Windows PowerShell 时，执行策略很可能是 Restricted（默认设置）。 PowerShell 提示”无法加载文件，因为在此系统上禁止运行脚本”的解决方法 设定 PowerShell 启动位置Set the position of Powershell window 自定义 Powershell ScriptsHow to Write and Run Scripts in the Windows PowerShell ISE - PowerShell","link":"/7b4baf329a89/"},{"title":"Neovim 使用经验积累","text":"本文主要记录了 Neovim 的使用经验，包括 Vim 使用基础知识，Neovim 基础使用以及 Neovim 配置 Python 开发环境等。 插件 快捷键 功能 Comment gcc 注释当前行 VimTeX &lt;leader&gt;ll 编译与停止编译文档 copilot.vim &lt;C-J&gt; 补全推荐的代码 Help - Neovim docs Vim 使用基础知识 Vim Cheat Sheet Why, oh WHY, do those #?@! nutheads use vi? Vim 的几种模式 Mode 说明 Normal Mode 正常模式 使用 Vim 刚打开文件时一般会处于正常模式 Insert Mode 输入模式 在正常模式的情况下，按下 i, I, a, A, o, O 任意一个键就会进入输入模式，输入内容。 Visual Mode 可视模式 在正常模式下按下 V 或者 v 或者 Ctrl + v 进入可视模式，在这个模式里会有点像是用鼠标操作的感觉，有时候会很方便。 有博客说有四个模式，还包括一个命令模式，但是在 VScode Vim 下没有这个模式，在正常模式下即可以直接输入命令。常用的命令有：:q（退出）、:q!（强制退出）、:w（保存）、:wq（保存并退出）。 CS107 The Vim Editor (stanford.edu) The four things you must be able to do in Vim | Enable Sysadmin (redhat.com) What are Vim Modes? How to Change Them? (linuxhandbook.com) How to use Vim in Linux | TechTarget What are the 7 Vim / Vi Modes? (warp.dev) Vim 移动命令 光标移动到行首：0 光标移动到行尾：$ Vim 查找与替换命令 基本操作命令 注：联想 Y 7000 没有 Home 键和 End 键 命令 操作 J 合并两行 x 删除光标所在处的内容 dw 删除一个词 Vim 命令里 search and replace 内容中有 slash 该怎么办 How to include forward slash in vi search &amp; replace Vim 正则表达式1%s/[0-9]\\./- /c vim 查找替换及正则表达式的使用 - Cooper’s Blog (tanqisen.github.io) 应用实例 ：替换 Markdown 文件里失效的 Gitee 图床链接 命令 %表示对当前文件进行替换 1:%s/gitee.com\\/xxxxx\\/image_bed\\/raw\\/master\\/img/raw.githubusercontent.com\\/xxxxx\\/image_bed\\/main\\/img_gitee/gc 查找 1/\\&lt;gitee.com\\/latexalpha\\/image_bed\\/raw\\/master\\/img\\&gt; Lua 语言基础知识Everything you need to know to configure neovim using lua Neovim 基础使用1234:echo stdpath('config') # 查看 Nvim 的配置文件目录，也就是 init.vim 的路径:h init.vim # 查看初始配置文件的帮助文档:h xdg # 查看基本目录 (base-directories) 的帮助文档vim.keymap.set() # 快捷键映射 123456789101112131415-- 初始 init.lua 备份local options = { noremap = true }vim.keymap.set(&quot;i&quot;, &quot;jk&quot;, &quot;&lt;ESC&gt;&quot;, options)vim.keymap.set(&quot;t&quot;, &quot;jk&quot;, &quot;&lt;C-\\\\&gt;&lt;C-n&gt;&quot;, options)if vim.g.vscode then -- VSCode extensionelse -- ordinary Neovimendlocal set = vim.opt -- set optionsset.tabstop = 4set.softtabstop = 4set.shiftwidth = 4 Neovim 配置前准备工作 安装 Nerd Font, Windows Terminal 最佳字体为 CaskaydiaCove NFM Nerd Fonts - Iconic font aggregator, glyphs/icons collection, &amp; fonts patcher 安装 wget 和 PowerShell 7 Mason Core 插件使用 How to use Wget: Install, Commands and Examples (Mac &amp; Windows) (jcchouinard.com) 在 Windows 上安装 PowerShell - PowerShell | Microsoft Learn 安装 Node. Js 和 npm Mason Languages 插件使用 Install Node.js and NPM on Windows 10 or 11 using command line (how2shout.com) 安装 c++ 编译器 Treesitter 插件使用，， 按照官方指引，安装 LLVM-MinGW 随后添加其 bin 文件夹到 PATH。 Downloads - MinGW-w64 Releases · mstorsjo/llvm-mingw (github.com) 安装 ripgrep 和 fd Telescope 插件使用 GitHub - BurntSushi/ripgrep: ripgrep recursively searches directories for a regex pattern while respecting your gitignore GitHub - sharkdp/fd: A simple, fast and user-friendly alternative to ‘find’ 12winget install BurntSushi.ripgrep.MSVC # ripgrepwinget install sharkdp.fd # fd 导出全部快捷键到文件，需提前创建文件 1nvim --headless '+redir! &gt; ~\\nvim_keymaps.md' '+silent verbose map' '+redir END' +qa Neovim 配置主题ASCII Text Art Generator Neovim 配置 Markdown 编辑器虽然有插件，但是需要借助浏览器渲染，使用起来比较麻烦，还是建议直接使用 Obsidian, 功能强大，有插件社区，可扩展性强。 Neovim 配置 Python 开发环境Neovim Spaghetti - LSP Servers, Linters, Formatters, and Treesitter – roobert Autocomplete and IntelliSenseIntelliSense is a general term for code editing features that relate to code completion. Editing Python Code in Visual Studio Code 利用 nvim-cmp 插件，还需要 Language server 提供支持 。 GitHub - hrsh7th/nvim-cmp: A completion plugin for neovim coded in Lua. Official page for Language Server Protocol (microsoft.github.io) LintingLinting highlights syntactical and stylistic problems in your Python source code, which often helps you identify and correct subtle programming errors or unconventional coding practices that can lead to errors. Linting is distinct from Formatting because linting analyzes how the code runs and detects errors whereas formatting only restructures how code appears. Linting Python in Visual Studio Code 利用 nvim-lspconfig 插件配置，pyright 和ruff-lsp提供支持，ruff-lsp 需要提前 pip install ruff-lsp 安装。 Python FormattingFormatting makes source code easier to read by human beings. By enforcing particular rules and conventions such as line spacing, indents, and spacing around operators, the code becomes more visually organized and comprehensible. Formatting Python in Visual Studio Code 利用null-ls插件配置，black提供支持。 由于pyright 不提供 formatting 功能，所以需要使用 black，black需要通过 Mason 插件安装。 How to setup formatter for Python ??? : r/neovim (reddit.com) formatting - How to configure neovim to properly format python code? - Vi and Vim Stack Exchange DebuggingDebugging configurations for Python apps in Visual Studio Code 利用 nvim-dap 插件配置，debugpy 提供支持。 EnvironmentsAn “environment” in Python is the context in which a Python program runs that consists of an interpreter and any number of installed packages. Using Python Environments in Visual Studio Code 利用 nvim-dap 插件配置，重点是设置 Python 解释器的路径，这里用 Conda 的优势就很明显了。由于 Conda 运行的时候会设置 CONDA_PREFIX 环境变量，因此可以直接利用环境变量设置 Python 解释器的路径。 TestingTesting Python in Visual Studio Code Neovim 配置 LaTeX 编辑器利用 VimTeX 插件 Real-time LaTeX using Vim/Neovim, VimTeX, and snippets | ejmastnak 反向搜索 1cmd /c start /min &quot;&quot; nvim --headless -c &quot;VimtexInverseSearch %l '%f'&quot; LSP利用 nvim-lspconfig 配置，lua_ls 提供支持。 LaTeX Formatting利用 null-ls 配置，latexindent 提供支持。 Neovim Snippets 设置利用 LuaSnip 插件来实现。 LuaSnip Plugin Guide for LaTeX | Vim and LaTeX Series Part 2 | ejmastnak 遇到的问题与解决方案Treesitter and LSP 的差别 Neovim modern features: treesitter and LSP What’s the difference between tree-sitter and LSP[0]? They both seem to provide … | Hacker News https://github.com/williamboman/mason-lspconfig.nvim Trying to Configure pyls through nvim-lspconfig ASDF+Neovim+Pyright Neovim 在 Windows Terminal 上出现白边 需要调两个控制，一个是 padding，一个是 scrollbarState。 1Terminal -&gt; Settings -&gt; Defaults(Profiles) -&gt; Appearance(Additional settings) -&gt; Window 但是调整完了之后在底部还是会有一小部分白边残余，这是因为终端的像素数量不是使用字体的整数倍。 vim/nvim not filling windows terminal - Stack Overflow Empty space below Nvim area : r/neovim (reddit.com)","link":"/4d02fc57ac7e/"},{"title":"VS Code 使用经验积累","text":"本文主要记录了 VS Code 的使用经验，包括 VS Code 的基本使用、VS Code 的插件使用、VS Code 的配置等。 Documentation for Visual Studio Code VS Code Terminal 使用Integrated Terminal in Visual Studio Code 开启/关闭终端快捷键 (Ctrl + `) 切换默认终端为 PowerShell，并设置 Nerd 字体 123&quot;terminal.integrated.defaultProfile.windows&quot;: &quot;PowerShell&quot;, // 设置默认终端为 PowerShell&quot;terminal.integrated.fontFamily&quot;: &quot;CaskaydiaCove Nerd Font Mono&quot;, // 设置终端字体&quot;terminal.integrated.fontSize&quot;: 14, // 设置终端字体大小 VS Code 备份设置使用 Github 备份 VS Code 扩展设置 Settings Sync in Visual Studio Code vscode - 使用 Settings 进行同步扩展以及配置信息等 Enable extension according to file type · Issue #84303 · microsoft/vscode (github.com) VS Code 配置 VimVim - Visual Studio Marketplace 安装 ## VSCodeVim 插件 Esc 键位映射为 jk ：在 settings.json 中添加如下配置： 123456&quot;vim.insertModeKeyBindings&quot;: [ { &quot;before&quot;: [&quot;j&quot;,&quot;k&quot;], &quot;after&quot;: [&quot;&lt;Esc&gt;&quot;] }], VS Code 配置 NeovimGitHub - vscode-neovim/vscode-neovim: Vim-mode for VS Code using embedded Neovim 安装 vscode-neovim 插件 安装 Neovim，在 vscode-neovim 插件中设置 Neovim 的完整路径 1C:\\Program Files\\Neovim\\bin\\nvim.exe 配置 Neovim config 文件，在 init.lua 文件中添加如下内容 12345if vim.g.vscode then -- VSCode extensionelse -- ordinary Neovimend VS Code 中设置 Esc 键位映射为 jk，Open Keyboard Shortcuts JSON, 添加如下内容： 123456789101112{ &quot;command&quot;: &quot;vscode-neovim.compositeEscape1&quot;, &quot;key&quot;: &quot;j&quot;, &quot;when&quot;: &quot;neovim.mode == insert &amp;&amp; editorTextFocus&quot;, &quot;args&quot;: &quot;j&quot;},{ &quot;command&quot;: &quot;vscode-neovim.compositeEscape2&quot;, &quot;key&quot;: &quot;k&quot;, &quot;when&quot;: &quot;neovim.mode == insert &amp;&amp; editorTextFocus&quot;, &quot;args&quot;: &quot;k&quot;} VS Code 配置 Markdown 编辑器安装插件 Markdown Preview Enhanced 使用即可。 关于插件 Markdown Preview Enhanced 的使用技巧 在 VSCode 下用 Markdown Preview Enhanced 愉快地写文档 VS Code 配置 Python 开发环境Get Started Tutorial for Python in Visual Studio Code 将 Conda 路径加入系统环境变量 配置环境变量 Windows + S 高级系统设置 环境变量 系统变量 PATH 下添加 Miniconda/Anaconda 安装路径 重启计算机，使系统变量生效 vscode 调试 python 时提示无法将”conda”项识别为 cmdlet、函数、脚本文件或可运行程序的名称的解决方法_是魏果果呀~-CSDN 博客 安装 Python 插件1Python 插件 使用 Code Runner 运行时自动保存文件修改 VS code 的 settings. Json 文件，添加如下内容： 1234// added by xxxxx&quot;code-runner.executorMap&quot;: { &quot;python&quot;: &quot;$pythonPath -u $fullFileName&quot;,}, VS Code 配置 LaTeX 编辑器安装 TeX Live 发行版安装 TeX live 很简单，直接安装即可。 安装过程中会自动设置 PATH，安装完了就可以直接使用。 删除的时候是把文件夹删了就可以了，如果是更换安装路径，直接把文件夹剪切到目标路径，然后更新 PATH 就可以了，不用卸载重新安装。 插件安装及配置LaTeX Workshop - Visual Studio Marketplace Latexmk (cantab.net) Using Latexmk — homepage (mg.readthedocs.io) 安装 LaTeX Workshop 及一系列插件, 直接安装以下插件： 123LaTeX WorkshopLaTeX language supportUnicode Latex 配置 settings.json 文件 正向搜索是在目标位置使用快捷键 Ctrl+Alt+J 反向搜索是直接双击即可 123456789101112131415161718192021// 设置外部PDF预览器&quot;latex-workshop.view.pdf.viewer&quot;:&quot;external&quot;,&quot;latex-workshop.view.pdf.ref.viewer&quot;:&quot;external&quot;,&quot;latex-workshop.view.pdf.external.viewer.command&quot;: &quot;C:\\\\Users\\\\xxxxx\\\\AppData\\\\Local\\\\SumatraPDF\\\\SumatraPDF.exe&quot;,&quot;latex-workshop.view.pdf.external.viewer.args&quot;: [ &quot;%PDF%&quot;],// 配置Syntex的正向与反向搜索(Latex-&gt;PDF)&quot;latex-workshop.view.pdf.external.synctex.command&quot;: &quot;C:\\\\Users\\\\xxxxx\\\\AppData\\\\Local\\\\SumatraPDF\\\\SumatraPDF.exe&quot;,&quot;latex-workshop.view.pdf.external.synctex.args&quot;: [ &quot;-forward-search&quot;, &quot;%TEX%&quot;, &quot;%LINE%&quot;, &quot;-reuse-instance&quot;, &quot;-inverse-search&quot;, &quot;\\&quot;C:\\\\Users\\\\xxxxx\\\\AppData\\\\Local\\\\Programs\\\\Microsoft VS Code\\\\Code.exe\\&quot; \\&quot;C:\\\\Users\\\\xxxxx\\\\AppData\\\\Local\\\\Programs\\\\Microsoft VS Code\\\\resources\\\\app\\\\out\\\\cli.js\\&quot; -r -g \\&quot;%f:%l\\&quot;&quot;, &quot;%PDF%&quot; // 这里其实就是配置的反向搜索 不用在 Sumatra PDF 里面重新设],&quot;latex-workshop.view.pdf.internal.synctex.keybinding&quot;: &quot;double-click&quot;,// Latex End 注意事项 Json 文件里的路径最好使用转义字符。 LaTeX 文件夹目录开始字符需要是字母，路径可以有空格。 编译时间太长的情况下，删掉文件夹下的除了 .tex 文件的其他文件。 编译时间太长的原因是设置了保存时自动编译，所以会一直不停地编译。 1&quot;latex-workshop.latex.autoBuild.run&quot;: &quot;never&quot; 反向搜索打开的是 cli.js 文件的问题解决方法:要在 Sumatra PDF 设置里设置正确的路径，且还要在预览前先开启 Sumatra PDF. Inverse Search in vscode 1.62.3, windows 11, with Sumatra PDF · Issue #2988 · James-Yu/LaTeX-Workshop VScode+Latex+SumatraPDF 反向搜索失败解决办法（Version 1.63） VS Code 设置 SnippetsSnippets in Visual Studio Code","link":"/ed37cd70b202/"},{"title":"数学-基础知识","text":"本文主要介绍了数学的一些基础知识，包括空间、范数、测度、正问题反问题与适定性等。 数学里空间的概念空间空间 (数学) - 维基百科，自由的百科全书 向量空间/线性空间Vector space, is also called linear space. 向量空间 - 维基百科，自由的百科全书 赋范向量空间/赋范线性空间赋范向量空间 - 维基百科，自由的百科全书 内积空间内积空间 - 维基百科，自由的百科全书 在数学里面，内积空间是增添了一个额外的结构的向量空间。这个额外的结构叫做内积，或标量积，或点积。这个增添的结构允许我们谈论向量的角度和长度。内积空间由欧几里得空间抽象而来，这是泛函分析讨论的课题。 度量空间度量空间 - 维基百科，自由的百科全书 完备度量空间完备空间 - 维基百科，自由的百科全书 完备空间或者完备度量空间是具有下述性质的空间：空间中的任何柯西序列都收敛在该空间之内。以有限维空间来说，向量的范数相当于向量的模的长度。但是在有限维欧式空间中还有一个很重要的概念—向量的夹角，特别是两个向量的正交。内积空间是特殊的线性赋范空间，在这类空间中可以引入正交的概念以及投影的概念，从而在内积空间中建立起相应的几何学。用内积导出的范数来定义距离，Banach 空间就成为了希尔伯特空间。 巴拿赫空间巴拿赫空间 - 维基百科，自由的百科全书 在数学里，尤其是在泛函分析之中，巴拿赫空间是一个完备赋范向量空间。更精确地说，巴拿赫空间是一个具有范数并对此范数完备的向量空间。 希尔伯特空间希尔伯特空间 - 维基百科，自由的百科全书 在数学中，希尔伯特空间是欧几里德空间的一个推广，其不再局限于有限维的情形。与欧几里德空间相仿，希尔伯特空间也是一个内积空间，其上有距离和角的概念（及由此引申而来的正交性与垂直性的概念）。此外，希尔伯特空间还是一个完备的空间，其上所有的柯西序列等价于收敛序列，从而微积分中的大部分概念都可以无障碍地推广到希尔伯特空间中。希尔伯特空间为基于任意正交系上的多项式表示的傅立叶级数和傅立叶变换提供了一种有效的表述方式，而这也是泛函分析的核心概念之一。希尔伯特空间是公式化数学和量子力学的关键性概念之一。 拓扑空间拓扑空间 - 维基百科，自由的百科全书 再生希尔伯特空间 再生核希尔伯特空间(RKHS)介绍 希尔伯特空间 数学里范数的概念向量的范数向量的 0 范数向量中非零元素的个数。 1 范数，为绝对值之和。 2 范数，就是通常意义上的模。 无穷范数，就是取向量的最大值。 首先定义一个向量为：a = [ − 5，6，8, − 10] 向量的 1 范数向量的 1 范数即：向量的各个元素的绝对值之和。 &gt;上述向量 a 的 1 范数结果就是：29，MATLAB 代码实现为：norm（a，1）； 向量的 2 范数向量的 2 范数即：向量的每个元素的平方和再开平方根。 &gt;上述 a 的 2 范数结果就是：15，MATLAB 代码实现为：norm（a，2）； 向量的无穷范数 向量的负无穷范数即：向量的所有元素的绝对值中最小的。 &gt;上述向量 a 的负无穷范数结果就是：5，MATLAB 代码实现为：norm（a，-inf）； 向量的正无穷范数即：向量的所有元素的绝对值中最大的。 &gt;上述向量 a 的负无穷范数结果就是：10，MATLAB 代码实现为：norm（a，inf）； 矩阵的范数首先我们将介绍数学中矩阵的范数的情况，也就是无论哪个学科都统一的一种规定。例如矩阵A = [ − 1 2 − 3；4 − 6 6] 矩阵的 1 范数矩阵的 1 范数即：矩阵的每一列上的元素绝对值先求和，再从中取个最大的，（列和最大）。 &gt;上述矩阵 A 的 1 范数先得到[5,8,9]，再取最大的最终结果就是：9，MATLAB 代码实现为：norm（A，1）； 矩阵的 2 范数矩阵的 2 范数即：矩阵 ATAATA 的最大特征值开平方根。 &gt;上述矩阵 A 的 2 范数得到的最终结果是：10.0623，MATLAB 代码实现为：norm（A，2）； 矩阵的无穷范数矩阵的 1 范数即：矩阵的每一行上的元素绝对值先求和，再从中取个最大的，（行和最大）。 &gt;上述矩阵 A 的 1 范数先得到[6；16]，再取最大的最终结果就是：16，MATLAB 代码实现为：norm（A，inf）； 接下来我们要介绍机器学习的低秩，稀疏等一些地方用到的范数，一般有核范数，L0 范数，L1 范数（有时很多人也叫 1 范数，这就让初学者很容易混淆），L21 范数（有时也叫 2 范数），F 范数 ⋯ 上述范数都是为了解决实际问题中的困难而提出的新的范数定义，不同于前面的矩阵范数。 矩阵的核范数矩阵的核范数即：矩阵的奇异值（将矩阵 svd 分解）之和，这个范数可以用来低秩表示（因为最小化核范数，相当于最小化矩阵的秩——低秩）。 &gt;上述矩阵 A 最终结果就是：10.9287， MATLAB 代码实现为：sum(svd(A)) 矩阵的 L0 范数矩阵的 L0 范数即：矩阵的非 0 元素的个数，通常用它来表示稀疏，L0 范数越小 0 元素越多，也就越稀疏。 &gt;上述矩阵 A 最终结果就是：6 矩阵的 L1 范数矩阵的 L1 范数即：矩阵中的每个元素绝对值之和，它是 L0 范数的最优凸近似，因此它也可以表示稀疏。 &gt;上述矩阵 A 最终结果就是：22，MATLAB 代码实现为：sum(sum(abs(A))) 矩阵的 F 范数矩阵的 F 范数即：矩阵的各个元素平方之和再开平方根，它通常也叫做矩阵的 L2 范数，它的优点在它是一个凸函数，可以求导求解，易于计算。 &gt;上述矩阵 A 最终结果就是：10.0995，MATLAB 代码实现为：norm（A，‘fro’） 矩阵的 L21 范数矩阵的 L21 范数即：矩阵先以每一列为单位，求每一列的 F 范数（也可认为是向量的 2 范数），然后再将得到的结果求 L1 范数（也可认为是向量的 1 范数），很容易看出它是介于 L1 和 L2 之间的一种范数。 &gt;上述矩阵 A 最终结果就是：17.1559，MATLAB 代码实现为： norm(A(:,1),2) + norm(A(:,2),2) + norm(A(:,3),2) 数学里测度的概念测度（英语：Measure）在数学分析里是指一个函数，它对一个给定集合的某些子集指定一个数。感官上，测度的概念相当于长度、面积、体积等。一个特别重要的例子是欧氏空间上的勒贝格测度，它把欧氏几何上传统的诸如长度、面积和体积等概念赋予 n 维欧式空间 Rn 。例如，实数区间 [0, 1] 上的勒贝格测度就是它显而易见的长度，即 1。 传统的积分是在区间上进行的，后来人们希望把积分推广到任意的集合上，就发展出测度的概念，它在数学分析和概率论有重要的地位。 测度论是实分析的一个分支，研究对象有 σ 代数、测度、可测函数和积分，其重要性在概率论和统计学中都有所体现。 测度 - 维基百科，自由的百科全书 Measure (mathematics) - Wikipedia 勒贝格测度勒贝格测度 在测度论中，勒贝格测度Lebesgue measure是欧几里得空间上的标准测度。对维数为 1，2，3 的情况，勒贝格测度就是通常的长度、面积、体积。它广泛应用于实分析，特别是用于定义勒贝格积分。可以赋予勒贝格测度的集合称为勒贝格可测集；勒贝格可测集 A 的测度记作 λ (A) 。一般来说，我们允许一个集合的勒贝格测度为 ∞ ，但是即使如此，在假设选择公理成立时，Rn 仍有勒贝格不可测的子集。不可测集的“奇特”行为导致了巴拿赫-塔斯基悖论这样的命题，它是选择公理的一个结果。 数学里正问题反问题与适定性正问题和反问题Forward problems are usually well-posed, i.e., they have a unique solution which is insensitive to small changes of the initial values. Inverse problems are the opposite to forward problems, meaning that one is given the effect and the task is to recover the cause. Direct problem and Inverse problem https://link.springer.com/chapter/10.1007/978-3-319-27836-0_12#:~:text=Forward problems are usually well,is to recover the cause. Regularization theory of the analytic deep prior approach Inverse problem - Wikipedia [[Lecture_11_Param_Est_class_notes.pdf]] 适定性 Well-posedness适定问题和不适定问题(Well-posed and Ill-posed Problem) Inverse problems and ill-posed problems are very hot in mathematics nowadays. The well-posed problems are that the solution of problems is existent, unique, and stable, if there is one or more to be dissatisfied , it is ill-posed. 适定问题 Well-posed ProblemThe mathematical term well-posed problem stems from a definition given by 20th-century French mathematician Jacques Hadamard. He believed that mathematical models of physical phenomena should have the properties that: a solution exists, the solution is unique, the solution’s behavior changes continuously with the initial conditions. Examples of archetypal well-posed problems include the Dirichlet problem for Laplace’s equation, and the heat equation with specified initial conditions. These might be regarded as ‘natural’ problems in that there are physical processes modelled by these problems. 不适定问题 Ill-posed ProblemProblems that are not well-posed in the sense of Hadamard are termed ill-posed. Inverse problems are often ill-posed. For example, the inverse heat equation, deducing a previous distribution of temperature from final data, is not well-posed in that the solution is highly sensitive to changes in the final data. 讨论Continuum models must often be discretized in order to obtain a numerical solution. While solutions may be continuous with respect to the initial conditions, they may suffer from numerical instability when solved with finite precision, or with errors in the data. Even if a problem is well-posed, it may still be ill-conditioned, meaning that a small error in the initial data can result in much larger errors in the answers. Problems in nonlinear complex systems (so-called chaotic systems) provide well-known examples of instability. An ill-conditioned problem is indicated by a large condition number. If the problem is well-posed, then it stands a good chance of solution on a computer using a stable algorithm. If it is not well-posed, it needs to be re-formulated for numerical treatment. Typically this involves including additional assumptions, such as smoothness of solution. This process is known as regularization. Tikhonov regularization is one of the most commonly used for regularization of linear ill-posed problems. 数学里的优化问题与正则化最优化最优化涉及到目标函数和约束条件。 目标函数：J(x) = f(x) 等式约束：gi(x) = 0, i = 1, 2, ⋯, m 不等式约束：hj(x) ≤ 0, j = 1, 2, ⋯, l 最优化的任务，是在约束条件下寻找 x，使得目标函数取得最优值（最大值或最小值）。 • 静态最优化：变量 x 与时间无关，或在所讨论的时间区间内是常量。 • 动态最优化：变量 x 是时间的函数，目标函数不再是普通函数，而是时间函数的函数，称为泛函数，简称为泛函。 求解动态最优化问题的方法主要有：古典变分法、极小（大）值原理及动态规划等 &gt; 在动态最优控制中，目标函数是一个泛函数，因此求解动态最优化问题可以归结为求解泛函数极值的问题。变分法要解决的问题：求解无限个变量的函数极值。 把最优化方法和正则化方法相结合，应用于求解反问题。 P versus NP ProblemP versus NP problem - Wikipedia NP-hardness - Wikipedia P Problem The general class of questions for which some algorithm can provide an answer in polynomial time is called “class P” or just “P”. NP Problem For some questions, there is no known way to find an answer quickly, but if one is provided with information showing what the answer is, it is possible to verify the answer quickly. The class of questions for which an answer can be verified in polynomial time is called NP, which stands for “nondeterministic polynomial time” NP-complete Problem 正则化在数学与计算机科学中，尤其是在机器学习和逆问题领域中，正则化（英语：regularization）是指为解决适定性问题或过拟合而加入额外信息的过程。 Regularization (mathematics) - Wikipedia 正则化 (数学) - 维基百科，自由的百科全书 Tikhonov regularization - Wikipedia 吉洪诺夫正则化 - 维基百科，自由的百科全书 可分离非线性最小二乘法Separable nonlinear least squares (SNLS) problem is a special class of nonlinear least squares (NLS) problems, whose objective function is a mixture of linear and nonlinear functions. It has many applications in many different areas, especially in Operations Research and Computer Sciences. They are difficult to solve with the infinite-norm metric. In this paper, we give a short note on the separable nonlinear least squares problem, unseparated scheme for NLS, and propose an algorithm for solving mixed linear-nonlinear minimization problem, method of which results in solving a series of least squares separable problems. W. Gharibi and O. S. Al-Mushayt, “A Note on Separable Nonlinear Least Squares Problem,” 2011 International Conference on Future Computer Sciences and Application, Hong Kong, China, 2011, pp. 54-56, doi: 10.1109/ICFCSA.2011.19. 基本概念与定理矩阵求逆引理矩阵求逆引理是信号处理中常用到的定理。这一公式的目的是将矩阵的逆用它的一个可加分量的逆来表示，从而为矩阵求逆提供有效的计算方法。 在递推最小二乘法估计问题中，因为每次推导运算时必须计算矩阵和的逆，这样做工作量非常大，为了简化，通常使用矩阵求逆引理来简化计算量。 矩阵求逆要解决的问题是： 已知一个高维矩阵 A 的逆矩阵，当矩阵 A 产生了一个非常小的变化（维数远低于 A 或低于 A）时，能不能根据已知的 A 的逆矩阵，求产生微小变化后的矩阵的逆。 Woodbury matrix identity - Wikipedia 置信区间置信区间是指由样本统计量所构造的总体参数的估计区间。在统计学中，一个概率样本的置信区间（Confidence interval）是对这个样本的某个总体参数的区间估计。置信区间展现的是这个参数的真实值有一定概率落在测量结果的周围的程度，其给出的是被测量参数的测量值的可信程度，即前面所要求的“一个概率”。 二次型二次型（quadratic form）：n 个变量的二次多项式称为二次型，即在一个多项式中，未知数的个数为任意多个，但每一项的次数都为 2 的多项式。线性代数的重要内容之一，它起源于几何学中二次曲线方程和二次曲面方程化为标准形问题的研究。二次型理论与域的特征有关。 KL 散度及其用处 KL Divergence 变分推断–深度学习第十九章 变分推断之傻瓜式推导 ELBO 压缩感知[[Compressed Sensing (Compressed Sampling).pdf]]","link":"/fae28b820a97/"},{"title":"最小二乘法、拉格朗日乘子法与正则化","text":"本文主要介绍了最小二乘法、拉格朗日乘子法与正则化的一些基础知识。 最小二乘法 Least Squares简介[[最小二乘法.pdf]] 最小二乘法的参数解析解求解过程假设我们现在有 m 个 n 维的样本，我们可以将所有的样本组成一个样本矩阵 Xm × (n + 1)，X的每一行代表一个样本，每一列代表样本的一个特征，为了表达方便，我们设有一个额外的一维常数项，全为 1，也就是最后一列。 目标函数为： $$\\begin{aligned} J(\\theta) &amp;= \\frac{1}{2} \\sum_1^m (h_{\\theta}(x^{(i)})-y^{(i)})^2 \\ &amp;= \\frac{1}{2} (X \\theta -Y)^T(X \\theta -Y) \\ &amp;= \\frac{1}{2}(\\theta^TX^T - Y^T)(X \\theta - Y) \\ &amp;= \\frac{1}{2}(\\theta^T X^T X \\theta - \\theta^T X^TY - Y^T X \\theta - Y^T Y)\\end{aligned}$$ 此时我们对于J(θ)求导数并且令导数等于零 $$\\frac{\\delta J(\\theta)}{\\delta \\theta} = \\frac{1}{2}(2X^T X \\theta - X^T Y - X^T Y) = 0$$ 于是有：XTXθ − XTY = 0，即为XTXθ = XTY. 注意到XTX其实是一个方阵，如果这个方阵是可逆的话，就可以直接得到θ的解析式： θ = (XTX) − 1XTY 通常为了防止过拟合，或者当XTX不可逆的时候，添加一个λ扰动，则有： θ = (XTX + λI) − 1XTY 可分离最小二乘法交替乘子法[[ADMM Alternating Direction Method of Multipliers.pdf]] 拉格朗日乘子法与正则化Depends where did you use these terminologies. Roughly Lagrange multiplier is kind of regularization parameter. Regularization parameter tries to regularize the ill posed problem to well posed problem. 拉格朗日乘子，是为了解决约束优化问题，将其变为无约束优化问题的一个方法。从编程角度，拉格朗日乘子很可能是一个向量。 正则化参数，是为了解决反问题不适定性的一种方法。从编程角度，正则化参数往往只是一个数，而不是向量。通常可用 L 曲线或者 GCV 法来确定一个大概值。 参考内容 最小二乘法和岭回归 [优化]Levenberg-Marquardt 最小二乘优化 机器学习笔记之(五)最小二乘法中参数解析解的求解过程 深入理解拉格朗日乘子法（Lagrange Multiplier) 和 KKT 条件 矩阵最小二乘与 Tikhonov 正则化 LASSOLasso MethodGroup LassoAdaptive Lasso","link":"/53a2917035e8/"},{"title":"论文投稿注意事项","text":"本文主要记录一些论文投稿的相关信息，包括期刊的缩写检查，期刊的投稿指南等。 投稿流程 选择期刊 下载期刊的投稿模板 查询期刊的投稿指南 撰写论文 检查论文格式 投稿 Journal abbreviations checkList of Title Word Abbreviations Web of Science Journal Title Abbreviations Elsevier for authors Publish with Elsevier Author policies and guidelines LaTeX instructions Author tools &amp; resources Elsevier Policies Artwork and media instructions Artwork formats checklist Artwork sizing Elsevier Journal GuidelinesInternational Journal of Mechanical Sciences Journal of Sound and Vibration","link":"/21f1078282f3/"},{"title":"信号处理-稀疏分解：MP, OMP and BP","text":"本文主要介绍了稀疏分解的基本概念，匹配追踪（MP），正交匹配追踪（OMP）和基追踪（BP）的原理和算法流程。 [[2021-03-19稀疏分解.pdf]] 稀疏分解的基本概念稀疏分解，又称为稀疏近似、稀疏表示（Sparse Decomposition / Sparse Approximation / Sparse Representation of Signals） 假定信号为$f$，其长度为$n$，Hilbert空间记为$H$，在希尔伯特空间$H$里，由一组向量${x_1, x_2, ⋯, x_m}$构成字典矩阵$D$，其中每个列向量为一个原子，其长度与被表示的信号$f$的长度相同，并且这些向量已经经过归一化处理，即每一个列向量都是单位向量，其模长为 1. 如果字典的原子张成了整个信号空间，那么字典就是完全的。如果有原子之间线性相关，那么字典就是冗余的。在大多数稀疏分解的应用中，字典都是完全且冗余的。 用数学语言表示为：$|x_i| = 1, 1 ≤ i ≤ m$， 信号可以被表示成为这些原子的稀疏表示，也就是信号 f 可以被表示为$f = Dβ$，或者是$f ≈ Dβ, ∥f − Dβ∥p ≤ ε$。 字典矩阵中所谓的过完备性（有时也称作冗余，over-complete/redundant），指的是原子的个数远远大于信号的长度，即为：$n ≪ m$. 信号的稀疏分解，也就是需要求出$β$。由于字典矩阵是冗余的，原子之间存在相关关系，所以信号的稀疏表示不唯一，问题的关键在于如何找到一个最优表示（Optimal Representation）。最直观的方式就是找到一个内积最大的表示，这也就是后面说到的匹配追踪的思想。 匹配追踪（Matching Pursuit）匹配追踪概述匹配追踪是对信号进行稀疏分解的经典方法，它将信号在完备字典库上进行分解。 MP 算法的基本思想是：从字典矩阵$D$（也称为过完备字典库）里选择一个与信号$f$最为匹配的原子，也就是选择某一个列向量，构建一个稀疏近似，并求出信号的残差，然后继续选择与信号残差最匹配的原子，反复迭代该过程，直至达到终止条件。最终信号$f$便可以由选择的这些原子表示出来(由于选择的字典矩阵是完备的，其中的某一个原子可能可以由其他的原子线性表示出来，所以这个表示不一定的线性的。)有以下几个问题需要回答： （1）如何选择与信号$f$最为匹配的原子呢？ （2）如何构建稀疏近似并求出残差呢？ （3）如何进行迭代呢？ （1）计算信号f与字典矩阵$D$里的每一个原子的内积（也就是和字典矩阵的每一列作内积），内积绝对值最大的一个原子即为本次迭代中与信号$f$最为匹配的原子。 用数学语言描述就是： $$f ∈ H, R_0f = f |⟨f, x_{r_0}⟩| = sup_{i ∈ {1, ⋯, k}}|⟨f, x_{r_i}⟩|$$ $r_i$表示字典矩阵$D$的列索引。 (2) 这样，信号$f$就可以被分解为在最匹配原子$x_{r_0}$的投影分量和残差两部分： $$R_nf=\\langle R_jf,x_{r_j} \\rangle x_{r_j} + R_{j+1}f \\tag{1}$$ 在这里的残差和投影分量之间是正交的：$⟨R_{j + 1}f, x_{r_j}⟩ = 0$（类似于欧几里得空间的垂直投影的效果，Hilbert空间是欧氏空间的推广）。 (3) 对残差$R_1f$进行上述分解，经过$j$次迭代之后，信号可以表示为: $$f=\\sum_{n=0}^{j-1}\\langle R_nf,x_{r_n} \\rangle x_{r_n} + R_jf \\tag{2}$$ 匹配追踪算法（English）Matching pursuit is a greedy algorithm that computes the best nonlinear approximation to a signal in a complete, redundant dictionary. Matching pursuit builds a sequence of sparse approximations to the signal stepwise. Let $D = {x_{r_i}}_{i = 1}^m$ denote a dictionary of unit-norm atoms. Let $f$be your signal. Start by defining $R_0f = f$ Begin the matching pursuit by selecting the atom from the dictionary that maximizes the absolute value of the inner product with $R_0f = f$. Denote that atom by $x_{r_0}$. Form the residual $R_1f$ by subtracting the orthogonal projection of R0f onto the space spanned by $x_{r_0}$. $$R_1f = R_0f − ⟨R_0f, x_{r_0}⟩x_{r_0}$$ Iterate by repeating steps 2 and 3 on the residual. $$R_{j+1}f=R_jf−\\langle R_jf,x_{r_j} \\rangle x_{r_j}$$ Stop the algorithm when you reach some specified stopping criterion. In nonorthogonal (or basic) matching pursuit, the dictionary atoms are not mutually orthogonal vectors. Therefore, subtracting subsequent residuals from the previous one can introduce components that are not orthogonal to the span of previously included atoms. 匹配追踪收敛性证明The proof of convergence of MP relies essentially on the fact that: $$\\langle R_{j+1}f,x_{r_j} \\rangle = 0$$ Together with $(2)$, this orthogonality of the residual to the last vector selected leads to the following “energy conservation” equation: $$|R_jf|^2 = |R_{j+1}f|^2 + 2\\langle R_jf, x_{r_j} \\rangle \\langle R_{j+1}f, x_{r_j} \\rangle + |\\langle R_jf, x_{r_j} \\rangle |^2 |x_{r_j}|^2$$ And with $|x_{r_j}|^2 = 1$, we get: $$|R_jf|^2 = |R_{j+1}f|^2 + |\\langle R_jf, x_{r_j} \\rangle |^2$$ It has been noted that MP algorithm may be derived as a special case of a technique known as Projection Pursuit in the statistics literature. 正交匹配追踪（Orthogonal Matching Pursuit）正交匹配追踪概述OMP 算法对 MP 的改进之处在于：在分解的每一步，对所选择的原子全部进行正交化处理，这使得精度要求相同的条件下，OMP 算法的收敛速度更快。 OMP 算法分解的每一步，残差与所有选择的原子正交，而 MP 算法只与最近一次选择的原子正交。 对于一个长度为$n$的信号来说，OMP 的收敛次数一定小于等于$n$次。这一点很好理解，因为 OMP 是把之前选择的原子进行正交化了，相当于由原来的选择的原子构建了一组正交基，一个有n维的向量，最多也用分解n次。 最多只需要构建出一个 n 维的 Hilbert 空间，这个空间里的所有元素都可以它的一组正交基表示出来。 对于 OMP，关键之处在于理解如何构造出这一组正交基，下面讲述其具体流程。 正交匹配追踪原理假定$R_kf$和前面选择的原子都正交，然后推导出来怎么求。 假设$k$阶近似的时候有： $$f=\\sum_{n=1}^k a_n^k x_n + R_kf, \\quad with \\quad \\langle R_kf,x_n \\rangle = 0, n={1,\\cdots,k} \\tag{1}$$ 在$k+1$阶近似的时候有： $$f=\\sum_{n=1}^{k+1} a_n^{k+1} x_n + R_kf, \\quad with \\quad \\langle R_{k+1}f,x_n \\rangle = 0, n={1,\\cdots,k+1} \\tag{2}$$ 应用$k+1$阶模型减去$k$阶模型，则有： $$\\sum_{n=1}^k(a_n^{k+1}-a_n^k)+a_{k+1}^{k+1}x_{k+1}+R_{k+1}f-R_kf=0 \\tag{3}$$ 由于选择的非正交字典矩阵，于是引入一个辅助模型，表示$x_{k+1}$对前$k$项$x_n(n=1,\\cdots,k)$的依赖： $$x_{k+1} = \\sum_{n=1}^k b_n^k x_n + r_k \\quad with \\quad \\langle r_k,x_n \\rangle = 0,n=1,\\cdots,k \\tag{4}$$ $x_{k+1}$在$span{x_1,\\cdots,x_k }$上进行正交投影，后面的项是残差。注意这里的$a和b$表示的是第$k$步。如果$x_{k+1}$和前$k$项线性无关的话，$x_{k+1}=r_k$. $$\\sum_{n=1}^k b_n^kx_n = P_{V_k} x_{k+1} \\quad and \\quad r_k = P_{V_k^+} x_{k+1}$$ 将$(4)$代入$(3)$中，有： $$\\sum_{n=1}^k (a_n^{k+1}-a_n^k+a_{k+1}^{k+1} b_n^k)x_n + (a_{k+1}^{k+1} r_k + R_{k+1}f - R_kf) = 0 \\tag{5}$$ 若$(5)$恒成立，则有： $$a_n^{k+1}-a_n^k+a_{k+1}^{k+1} b_n^k = 0 \\tag{6}$$ $$a_{k+1}^{k+1} r_k + R_{k+1}f - R_kf = 0 \\tag{7}$$ 令$a_{k+1}^{k+1} = \\alpha_k$,由$(6)$得： $$a_n^{k+1} = a_n^k - \\alpha_k b_n^k$$ 其中， $$\\alpha_k = \\frac{\\langle R_kf, x_{k+1} \\rangle}{\\langle r_k, x_{k+1}\\rangle} = \\frac{\\langle R_kf,x_{k+1} \\rangle}{|r_k|^2}$$ 由$(7)$可得: $$\\langle a_{k+1}^{k+1} r_k + R_{k+1}f - R_kf,x_{k+1}\\rangle = 0$$ 于是： $$\\langle a_{k+1}^{k+1} r_k,x_{k+1} \\rangle = \\langle R_{k+1}f,x_{k+1} \\rangle - \\langle R_kf,x_{k+1} \\rangle$$ 则： $$\\alpha_k = \\frac{\\langle R_kf, x_{k+1\\rangle}}{\\langle r_k, x_{k+1}\\rangle}$$ 在$(4)$中与$r_k$做内积，可以求得$|r_k|^2$ $$\\langle x_{k+1},r_k \\rangle = \\sum_{n=1}^k \\langle b_n^k x_n,r_k \\rangle + \\langle r_k,r_k \\rangle$$ 对于$(4)$，可以求出$b_n^k$. 正交匹配追踪收敛性证明由$(7)$式：$a_{k+1}^{k+1} r_k + R_{k+1}f - R_kf = 0$，有 $$\\alpha_k r_k + R_{k+1}f = R_kf$$ 由于$r_k$与$R_{k+1}f$正交，左右同时求$l_2$范数的平方，于是有： $$\\alpha_k^2 r_k^2 + R_{k+1}f^2 + 2 \\langle \\alpha_k r_k,R_{k+1}f \\rangle = R_kf^2$$ 将$\\alpha_k$代入有： $$|R_{k+1}|^2 = |R_k|^2 - \\frac{|\\langle R_kf,x_{k+1} \\rangle |^2}{|r_k|^2}$$ 可见随着迭代次数的增加，残差逐渐减小，迭代是收敛的。 证明$r_k$与$R_{k+1}$正交： $\\langle R_{k=1}f,x_{k+1} \\rangle =0$ $$x_{k+1} = \\sum_{n=1}^k b_n^k x_n + r_k\\quad with \\quad \\langle r_k,x_n \\rangle = 0,n=1,\\cdots,k$$ $$\\langle R_{k+1}, \\sum_{n=1}^kb_n^k x_n + r_k \\rangle =0$$ $$\\langle R_{k+1}, \\sum_{n=1}^kb_n^k x_n \\rangle + \\langle R_{k+1}, r_k \\rangle =0$$ 算法循环过程说明 算法流程 第一步：计算残差与各原子的内积 第二步：寻找最匹配的原子 第三步：是否达到终止条件 第四步：原子重排 $k+0 \\leftrightarrow n_{k+1}$，例如找到$\\langle R_0f,x_{n_1} \\rangle max$，放在第一列 第五步：计算${b_n^k}_{n=0}^k$，使其满足期待的正交条件 第六步：令$\\alpha_k = a_{k+0}^{k+1}$，计算重新分配的系数，更新模型 第七步：循环 重新分配系数是为了保证残差和每一个选择的原子正交，加快收敛速度，和 MP 的差别就在这个$R_{k + 1}f$的更新上。 基追踪（Basic Pursuit)基追踪的基本概念Basic Pursuit (BP) is a principle (not an algorithm) for decomposing a signal into an ‘optimal’ superposition of dictionary elements, where optimal means having the smallest $l_1$ norm of coefficients among all such decompositions. $$min | \\beta |_1, \\quad s.t. \\quad D \\beta = f$$ For dealing with data at noise level $\\sigma &gt;0$, they propose approximate decomposition as in: $$f=D \\beta + r$$ And solving: $$min|D \\beta - f |_2 ^2 + \\lambda_n| \\beta |_1$$ with $\\lambda_n =\\sigma \\sqrt{2log(#D)}$ depending on the number $#D$ of distinct vectors in the dictionary.Advantages over MOF(the method of frames), MP, OMP, and BOB(the best orthogonal basis): better sparsity super-resolution For all those methods mentioned above, nonuniqueness gives the possibility of adaption. 总结匹配追踪（MP）和正交匹配追踪（OMP）都是让 $\\beta$（也就是选择的一组参数）的$L_0$-norm 最小，BP 是让其$L_1$-norm 最小，这是这三个方法的区别。 MP 和 OMP 算法： $$min | \\beta | _0, \\quad s.t. \\quad D \\beta = f$$ BP 方法： $$min | \\beta |_1, \\quad s.t. \\quad D \\beta = f$$ 稀疏分解方法把信号分解当成一个 ill-posed problem（不适定问题） 进行求解，这其实也是一个反问题，反问题本身大多数都是不适定问题。","link":"/1ac0e2cfbd9f/"},{"title":"信号处理基本概念及经典方法","text":"本文主要介绍了信号处理的一些基本概念，包括信号处理领域的缩写词一览表、信号处理领域一些常见概念、经典信号处理方法等。 信号处理领域缩写词一览表 缩写词 全拼 中文译名 缩写词 全拼 中文译名 FT Fourier Transform 傅里叶变换 IFD Iterative Filtering Decomposition 迭代滤波分解 DTFT Discrete-time Fourier Transform 离散时间傅里叶变换 IO Index of Orthogonality 正交性指标 DFT Discrete Fourier Transform 离散傅里叶变换 ITD Intrinsic Time-Scale Decomposition 本征时间尺度分解 FFT fast Fourier transform 快速傅里叶变换 LMD Local Mean Decomposition 局部均值分解 STFT Short-time Fourier Transform 短时傅里叶变换 MP Matching Pursuit 匹配追踪 WT Wavelet Transform 小波变换 NMD Nonlinear Mode Decomposition 非线性模式分解 HT Hilbert Transform 希尔伯特变换 NFM Nonlinear Frequency Modulation 非线性调频 HHT Hilbert-Huang Transform 希尔伯特黄变换 NFMC Nonlinear Frequency Modulated Component 非线性调频分量 EMD Empirical Mode Decomposition 经验模态分解 PNFMCD Parameterized Nonlinear Frequency Modulated Component Decomposition 非线性调频分量参数化分解 IMF Intrinsic Mode Function 固有模态函数 RE Relative Error 相对误差 ADMM Alternating Direction Method of Multipliers 交替方向乘子法 SI Separation Index 分离指标 AM Amplitude Modulation 幅值调制（调幅） SM S Method S 方法 ANFMCP Adaptive Nonlinear Frequency Modulated Component Pursuit 自适应非线性调频分量追踪 SNR Signal-to-Noise Ratio 信噪比 BP Basis Pursuit 基追踪 SST Synchrosqueezing Transform 同步压缩变换 BT Block Thresholding 分块阈值法 SST 2 Second-Order Synchrosqueezing Transform 二阶同步压缩变换 De-SST 2 Demodulated Second-Order Synchrosqueezing Transform 解调二阶同步压缩变换 SVD Singular Value Decomposition 奇异值分解 DWT Discrete Wavelet Transform 离散小波变换 TVF-EMD Time-Varying Filtering Based Empirical Mode Decomposition 基于时变滤波的经验模式分解 ECG Electrocardiogram 心电图 VMD Variational Mode Decomposition 变分模式分解 EEMD Ensemble Empirical Mode Decomposition 总体经验模式分解 VNFMCD Variational Nonlinear Frequency Modulated Component Decomposition 变分非线性调频分量分解 EMG Electromyogram 肌电图 WPT Wavelet Packet Transform 小波包变换 EVD Eigenvalue Decomposition 特征值分解 WD Wigner Distribution 魏格纳分布 EWT Empirical Wavelet Transform 经验小波变换 DWT Discrete Wavelet Transform 离散小波分析 FM Empirical Wavelet Transform 频率调制（调频） TFR Time-Frequency Representation 时频表示 HVD Hilbert Vibration Decomposition 希尔伯特振动分解 m-D Micro Doppler 微多普勒 IMF Intrinsic Mode Function 本征模态分解 LFM Linear Frequency Modulation 线性调频信号 信号处理领域一些常见概念信噪比（Signal-to-noise ratio）Signal-to-noise ratio-Wikipedia Lamb 波考虑地球旋转作用，在静力平衡大气中还可以产生一种只沿水平方向传播的特殊声波，称为兰姆波。其特点是：空气微团只做水平运动，静力平衡成立，水平尺度较大。兰姆波的相速大于绝热声速，是快波型波动。它与纯水平声波不同的是，它是频散波。 频散波 若相速不仅依赖于介质的物理性质，还依赖于波数，这种波称为频散波。若相速仅依赖于介质的物理性质，不依赖于波数，这种波称为非频散波，并称介质为非频散介质。如果相速度 c 和波数 k 无关，dc/dk=0，则群速度 Cg=c, 说明在波的传播过程中, 能量始终聚集在波内而不被分散；反之, 如果 c 和 k 有关, dc/dk≠0，则 cg≠c，说明能量随波的传播而被分散，这种现象称为能量频散，并称这种波为频散波（色散波）。 导波 有一个或两个方向的尺寸比较小的弹性体 (如长杆、薄板、薄壳等)内的行波。这类弹性体称为波导。在波导中导波受波导侧表面制约, 被引导沿着波导伸展的方向传播。导波一般为频散波, 可以具有多种模式, 每种模式的振幅在波面上有特定的分布形式, 波数与频率之间有特定的函数关系。 线性调频信号线性调频（LFM：Linear Frequency Modulation）信号是指瞬时频率随时间成线性变化的信号。（设振幅归一化，初始相位为零）。线性调频信号也称为鸟声（Chirp）信号，因为其频谱带宽落于可听范围，听着像鸟声，所以又称 Chirp 扩展频谱（CSS）技术。LFM 技术在雷达、声纳技术中有广泛应用，例如，在雷达定位技术中，它可用来增大射频脉冲宽度、加大通信距离、提高平均发射功率，同时又保持足够的信号频谱宽度，不降低雷达的距离分辨率。 平稳信号与非平稳信号The difference between stationary and non-stationary signals: The difficulties encountered when analyzing non-stationary signals: 非平稳信号 信号的统计特征随时间变化的信号，非平稳信号的瞬时频率常常随时间变化。 脊线由于信号是由几个主要的分量叠加而成的，一般来说每个信号分量都对应着一条比较突出的脊线，各个信号分量频率的主要参数均可以从各自对应的脊线信息中提取出来。 引用自文献：柏林, 刘小峰, 秦树人. 基于时频脊线的瞬时频率特征提取[J]. 机械工程学报, 2008, 44 (10): 222-227. 这篇文章里的第一篇参考文献有必要去看一遍：Carmona, Rene, A, et al. Multiridge Detection and Time-Frequency Reconstruction.[J]. IEEE Transactions on Signal Processing, 1999, 47 (2): 480-480. 功率谱功率谱的概念是建立在过程平稳性的基础上, 当过程失去平稳性时, 功率谱也就失去了意义。 随机振动Random Vibration，确定系统在随机激励下的响应问题。 振动研究总是在模型化的基础上进行的 → 随机微分方程的求解 平稳随机过程 X 的统计特性中最重要的是相关函数 Rx(τ)与功率谱密度 Sx(ω)，二者的关系如下： $$R_x (\\tau)=\\int_{-\\infty}^{\\infty} e^{j \\omega \\tau} d \\omega$$ $$S_x (\\omega) = \\frac{1}{2 \\pi}\\int_{-\\infty}^{\\infty}e^{-j \\omega \\tau}d \\tau$$ 功率谱的概念是建立在过程平稳性的基础上的，当过程失去平稳性时，功率谱也就失去了意义。 线性系统与非线性系统如果从系统状态空间表达式来观察，线性系统和非线性系统最明显的区别方式就是线性系统符合叠加原理，而非线性系统不然。换句话说线性系统只有状态变量的一次项。高次、三角函数以及常数项都没有，只要有任意一个非线性环节就是非线性系统。 幅值调制、频率调制和相位调制Message signal is used to modulating the carrier. 信号的调制可以分为： 幅值调制 角调制 频率调制 相位调制 幅值调制：振幅调变也可简称为调幅，AM（AmplitudeModulation），通过改变输出信号的振幅，来实现传送信息的目的。一般在调制端输出的高频信号的幅度变化与原始信号成一定的函数关系，在解调端进行解调并输出原始信号。 频率调制：频率调制是一种以载波的瞬时频率变化来表示信息的调制方式，通过利用载波的不同频率来表达不同的信息。所谓频率调制，顾名思义，就是对无线电进行信息加载，得到调制波。但是，随着无线电技术的另一个领域，既雷达设备，由于对目标测绘的需要，和电子信息对抗的必要。现代先进雷达已经能通过这种技术来减少杂波，抑或通过将一个集中的雷达脉冲波束散射，达到不被发现的功能，成为低截获概率技术（电子侦察系统会查找狭小波段范围内的电磁波，如果不这样，将会被无穷的背景电磁辐射扰乱）。 相位调制：相位调制或称调制：载波的相位对其参考相位的偏离值随调制信号的瞬时值成比例变化的调制方式相。调相和调频有密切的关系。调相时，同时有调频伴随发生；调频时，也同时有调相伴随发生，不过两者的变化规律不同。实际使用时很少采用调相制，它主要是用来作为得到调频的一种方法。 信号调制的三种方法 Wikipedia: Amplitude modulation Wikipedia: Frequency modulation Wikipedia: Phase modulation 由频率调制和相位调制的原理对比可知，在考虑瞬时频率的时候，二者之间是没有区别的，都可以表示为：$\\phi (t) = \\phi_0 + 2 \\pi \\int_{0}^{t} f(\\tau) d \\tau$ 边带边带 在无线电通信中，边带 sideband 是比载波频率更高或更低的频率带，所含功率为调制的结果。边带由载波外的调制信号的所有傅里叶分析组成。所有形式的调制都产生边带。 经典信号处理方法傅里叶变换 Fourier Transform建立了时域信号及其频域表示之间的桥梁，从而反映了信号时域和频域的全局特征，但是无法反映信号的局部特征。 短时傅里叶变换 Short Time Fourier Transform本质上是对信号进行加窗傅里叶变换，但是由于采用的是固定窗，所以时频分辨率固定不变，高频段和低频段的分辨率相同。 从傅里叶变换到短时傅里叶变换 小波变换 Wavelet Transform对信号进行加窗傅里叶变换，采用可变窗，分析低频分量时，窗口较宽，而分析高频分量时，窗口较窄。对低频分量，可取得较好的频域分辨率和较差的时域分辨率；但对高频分量，则恰好相反。小波变换分成两个大类：离散小波变换 (DWT) 和连续小波转换 (CWT)。两者的主要区别在于，连续变换在所有可能的缩放和平移上操作，而离散变换采用所有缩放和平移值的特定子集。 小波变换的定义： $$W_x(a,b) = \\langle x(t),\\psi_{a,b}(t) \\rangle = \\int_{-\\infty}^{\\infty}x(t)\\psi_{a,b}^\\star (t) dt$$ with $a&gt;0, \\psi_{a,b}(t)=a^{-1/2}\\psi(\\frac{t-b}{a}), \\psi(t)$ 称为母小波。$\\int_{-\\infty}^{\\infty} \\psi(t)dt =0$. 小波容许条件，小波紧支撑性。 连续小波变换 变分辨率带通滤波，适用于分析局部奇异性信号。 离散小波变换 线性调频小波变换是典型的参数化时频方法，其本质是在时频面上用一条任意斜率的直线表示任意一条能量曲线，故它适合分析线性调频单/多分量信号，但由于采用线性变换核，线性调频小波变换不适合分析非线性调频信号。 Wigner-Ville 分布 Wigner-Ville DistributionWigner-Ville 分布（WVD）：是典型的二次型变换，它定义为信号瞬时相关函数的傅立叶变换。由于在计算中不加窗操作，它避免了时域分辨率和频域分辨率之间的相互牵制。对于多分量信号会带来交叉项，因此适于分析单分量信号。 经验模态分解 Empirical Mode Decomposition, EMD提出者和提出时间：Norden E. Huang，1998 年 特点：是一种新的信号时频分析方法，非常适合处理非线性、非平稳信号，它基于信号的局部特征时间尺度，将复杂的信号分解为有限的本征模函数（IMF）之和，每一个 IMF 所包含的频率成分不仅与分析频率有关，而且随信号本身的变化而变化，具有自适应的特点，具有很高的信噪比。Hilbert 变换可以求出每一个 IMF 随时间变化的瞬时频率和瞬时幅值，揭示信号的内在特征。Hilbert 谱表示信号完整的时频分布，使得信号的瞬时频率具有了物理意义。 Ensemble Empirical Mode Decomposition (EEMD)中文名称：集合经验模态分解方法 提出者和提出时间：Wu Zhaohua and Norden E. Huang 特点：EEMD 方法的主要思想是统计学中对某个分量多次测量求取平均值可以提高测量的准确性。EEMD 通过在原信号中多次加入足够多组不同的白噪声后再进行 EMD 分解，得到一组 IMF 分量，再利用白噪声均值为零的随机特性，对全部 EMD 分解得到的各组 IMF 分量求总体平均作为 EEMD 分解 IMF 分量，以消除白噪声的影响。白噪声的加入可以为 EMD 提供一个相对一致的参照尺度分布，保证每个模态函数的时域连续性来减少模态混叠。 备注 EMD 的模态混叠问题：模态混叠包含两种类型：一种是不同特征尺度出现在单个 IMF 分量中；另一种是相近的特征尺度存在于不同的 IMF 分量中。 EEMD 分解具有不完备性：EEMD 分解方法是在原信号中多次加入不同的白噪声后再进行 EMD 分解，但是由于信号加入白噪声后分解的 IMF 的数量每次可能不一致，影响最终计算平均 IMF 分量。因此，实际 EEMD 算法并没有严格执行 IMF 的两个判据条件，而是在单次的 IMF 分解循环中只作了 M 次包络均值相减，便将结果作为 EEMD 的一个 IMF 分量。因此，EEMD 算法不一定满足 EMD 分解中的 IMF 条件，分解具有不完备性。 变分模态分解 Variational Mode Decomposition, VMDVariational mode decomposition is a completely non-recursive decomposition model, where all the modes are extracted concurrently. However, the model requires a preset mode number, which limits the adaptability of the method since a large deviation in the number of mode set will cause the discard or mixing of the mode. Variational Mode Decomposition (变分模态分解) - 知乎 (zhihu.com) 同步压缩变换 Synchrosqueezing Transform, SST包络分析 Envelope Analysis阶次分析 Order Analysis 阶次分析简介 阶次分析方法的本质是将时域里的非稳态信号通过恒定的角增量重采样变为角域伪稳态信号，使其能更好地反映与转速相关的振动信息，再采用传统的信号分析方法对其进行处理。阶次分析方法是针对转频不稳定的机械的一种专门的振动测量技术，它可将机械变负载过程中产生的与转速有关的振动信号有效分离出来，同时对与转速无关的信息起到一定的抑制作用，对于转速变化的机械，该方法的优点是十分明显的。由于该方法是按照转角位置分配采样间隔的，所以剔除了转速变化对频谱图的影响。另外，其随转速升高而提高采样频率的特性也保证了对振动幅值测量的精确性。因为转速越高，振动波形的变化越剧烈，这时提高采样频率就加密了采样点，从而避免了振动过程中一些特征点的丢失。精确地阶次分析方法要求对振动信号进行同步采样，检测系统的精确度和可靠性取决于同步采样的质量。 常用的阶次分析方法有以下几种： 硬件阶次分析法计算阶次分析法基于瞬时频率估计的阶次分析法。 任国全等著. 旋转机械非平稳故障诊断[M]. 北京：科学出版社, 2018 第四章 P 76 经过角域重采样技术，可以将非平稳时域振动信号转化为“平稳”的角域振动信号，但是由于信号本身是非平稳的，转换后的角域信号被称为角域伪稳态振动信号。 谱峭度与快速谱峭度 Spectrum Kurtosis谱峭度（Spectrum kurtosis, SK）的概念最先由 Dwyer 在 1983 年提出，其本质是计算每根谱线峭度值的高阶统计量。谱峭度对信号中的瞬态冲击成分十分敏感，能有效的从含有背景噪声信号中识别瞬态冲击及其在频带中的分布。 知乎：轴承故障诊断之谱峭度法的一些总结","link":"/97db69ab70d2/"},{"title":"滤波器学习","text":"本文主要介绍滤波器的基本概念和常见的滤波器类型。 数字滤波器数字滤波器是对数字信号进行滤波处理以得到期望的响应特性的离散时间系统。作为一种电子滤波器，数字滤波器与完全工作在模拟信号域的模拟滤波器不同。数字滤波器工作在数字信号域，它处理的对象是经由采样器件将模拟信号转换而得到的数字信号。数字滤波器的工作方式与模拟滤波器也完全不同：后者完全依靠电阻器、电容器、晶体管等电子元件组成的物理网络实现滤波功能；而前者是通过数字运算器件对输入的数字信号进行运算和处理，从而实现设计要求的特性。 数字滤波器设计实践介绍 - MATLAB &amp; Simulink Example - MathWorks 中国 数字滤波器的特性 数字滤波器具有比模拟滤波器更高的精度，甚至能够实现后者在理论上也无法达到的性能。例如，对于数字滤波器来说很容易就能够做到一个 1000 Hz 的低通滤波器允许 999 Hz 信号通过并且完全阻止 1001 Hz 的信号，模拟滤波器无法区分如此接近的信号。 数字滤波器相比模拟滤波器有更高的信噪比。这主要是因为数字滤波器是以数字器件执行运算，从而避免了模拟电路中噪声（如电阻热噪声）的影响。数字滤波器中主要的噪声源是在数字系统之前的模拟电路引入的电路噪声以及在数字系统输入端的模数转换 (A/D)过程中产生的量化噪声。这些噪声在数字系统的运算中可能会被放大，因此在设计数字滤波器时需要采用合适的结构，以降低输入噪声对系统性能的影响。 数字滤波器还具有模拟滤波器不能比拟的可靠性。组成模拟滤波器的电子元件的电路特性会随着时间、温度、电压的变化而漂移，而数字电路就没有这种问题。只要在数字电路的工作环境下，数字滤波器就能够稳定可靠的工作。 由于奈奎斯特采样定理（Nyquist sampling theorem），数字滤波器的处理能力受到系统采样频率的限制。如果输入信号的频率分量包含超过滤波器 $1/2$ 采样频率的分量时，数字滤波器因为数字系统的“混叠”而不能正常工作。如果超出 $1/2$ 采样频率的频率分量不占主要地位，通常的解决办法是在模数转换电路之前放置一个低通滤波器（即抗混叠滤波器）将超过的高频成分滤除。否则就必须用模拟滤波器实现要求的功能。 这里说的滤波器的采样频率，也就是说信号的采样频率是依据滤波器的采样频率确定的？ 数字滤波器的类型IIR 滤波器与 FIR 滤波器线性非时变的数字滤波器包括无限长脉冲响应滤波器（IIR 滤波器）和有限长脉冲响应滤波器（FIR 滤波器）两种。这两种滤波器的系统函数可以统一以 Z 变换表示为： $$H(z) = \\frac{B(z)}{A(z)} = \\frac{b_{0}+b_{1}z^{-1}+b_{2}z^{-2} + \\cdots + b_{N}z^{-N}} {1+a_{1}z^{-1}+a_{2}z^{-2} + \\cdots +a_{M}z^{-M}}.$$ 当 $M ≥ 0$ 时，$M$ 就是 IIR 滤波器的阶数，表示系统中反馈环的个数。由于反馈的存在，IIR 滤波器的脉冲响应为无限长，因此得名。若 $A(z) = 1$，则系统的脉冲响应的长度为 $N + 1$，故而被称作 FIR 滤波器。 IIR 滤波器的优缺点IIR 滤波器的优点在于，其设计可以直接利用模拟滤波器设计的成果，因为模拟滤波器本身就是无限长脉冲响应的。换句话说，若是有一个模拟滤波器，可以很直接地设计出 IIR 滤波器。 通常 IIR 滤波器设计的过程如下：首先根据滤波器参数要求设计对应的模拟滤波器（如巴特沃斯滤波器、切比雪夫滤波器等等），然后通过映射（如脉冲响应不变法、双线性映射等等）将模拟滤波器变换为数字滤波器，从而决定 IIR 滤波器的参数。 IIR 滤波器的重大缺点在于，由于存在反馈，所以稳定性不能得到保证。另外，反馈还使 IIR 滤波器的数字运算可能溢出，即 Z 转换后极点有可能超出单位圆之外。 FIR 滤波器的优缺点FIR 滤波器最重要的优点就是由于其脉冲响应之长度有限，输入有限长度信号输出的也会是有限长度，Z 转换后全部极点都在单位圆内，相较于 IIR 是一个稳定的系统。 FIR 滤波器还确保了线性相位，这在信号处理中也非常重要。 此外，由于不需要反馈，在 FIR 滤波器中要做最优化 (optimize)也比 IIR 滤波器简单。 FIR 滤波器的缺点在于相较于可以直接采样模拟滤波器设计的 IIR 滤波器来说设计较为不易。 此外它的性能不如同样阶数的 IIR 滤波器，不过由于数字计算硬件的飞速发展，这一点已经不成为问题。再加上引入计算机辅助设计，FIR 滤波器的设计也得到极大的简化。基于上述原因，FIR 滤波器比 IIR 滤波器的应用更广。 状态空间滤波器数字滤波器的另外一种形式是状态空间模型。状态空间滤波器的一个典型例子是 Rudolf Kalman 在 1959 年提出的卡尔曼滤波器[4]。 数字滤波器-维基百科 无限冲激响应滤波器(Infinite impulse response filter) 有限冲激响应滤波器(Finite impulse response filter) 维纳滤波器描述从连续的 (或离散的)输入数据中滤除噪声和干扰以提取有用信息的过程称为滤波，而相应的装置称为滤波器。根据滤波器的输出是否为输入的线性函数，可将它分为线性滤波器和非线性滤波器两种。 滤波器研究的一个基本课题就是：如何设计和制造最佳的或最优的滤波器。所谓最佳滤波器是指能够根据某一最佳准则进行滤波的滤波器。 19 世纪 40 年代，维纳奠定了关于最佳滤波器研究的基础： 即假定线性滤波器的输入为有用信号和噪声之和，两者均为广义平稳过程且知它们的二阶统计特性。 维纳根据最小均方误差准则(滤波器的输出信号与需要信号之差的均方值最小)，求得了最佳线性滤波器的参数，这种滤波器被称为维纳滤波器。 在维纳研究的基础上，人们还根据最大输出信噪比准则、统计检测准则以及其他最佳准则求得的最佳线性滤波器。实际上，在一定条件下，这些最佳滤波器与维纳滤波器是等价的。因而，讨论线性滤波器时，一般均以维纳滤波器作为参考。 这是信号处理中经常采用的主要方法之一，具有十分重要的应用价值。常用的滤波器是采用电感、电容等分立元件构成，如 RC 低通滤波器、LC 谐振回路等。但对于混在随机信号中的噪声进行滤波处理，这些简单的电路就不是最佳滤波器，这是因为信号与噪声均可能具有连续的功率谱。不管滤波器具有什么样的频率响应，均不可能做到噪声完全滤掉，信号波形的不失真。因此，需要寻找一种使误差最小的滤波方法，又称为最佳滤波准则。 从噪声中提取信号波形的各种估计方法中，维纳（Wiener）滤波是一种最基本的方法，适用于需要从噪声中分离出的有用信号是整个信号（波形），而不只是它的几个参量。其基本依据就是最小均方误差准则。 设维纳滤波器的输入为含噪声的随机信号。期望输出与实际输出之间的差值为误差，对该误差求均方，即为均方误差。因此均方误差越小，噪声滤除效果就越好。 为使均方误差最小，关键在于求冲激响应。如果能够满足维纳－霍夫方程，就可使维纳滤波器达到最佳。根据维纳－霍夫方程，最佳维纳滤波器的冲激响应，完全由输入自相关函数以及输入与期望输出的互相关函数所决定。 与设计一个特定频率响应所用的通常滤波器设计理论不同，维纳滤波器从另外一个不同的角度实现滤波器。仅仅在频域进行滤波的滤波器，仍然会有噪声通过滤波器。维纳设计方法需要额外的关于原始信号所包含频谱以及噪声的信息，维纳滤波器具有以下一些特点： 假设：信号以及附加噪声都是已知频谱特性或者自相关和互相关的随机过程; 性能标准：最小均方差; 能够用标量的方法找到最优滤波器. 维纳滤波器的设计目的是就是滤除按照统计方式干扰信号的噪声。 模型/问题的建立假设维纳滤波器的输入信号是s(t)，叠加噪声n(t)。输出信号x(t)通过滤波器g(t)，使用下面的卷积运算得到： $$x(t)=g(t)*(s(t)+n(t)).$$ 其中 $s(t)$ 是需要估计的原始信号 $n(t)$ 是噪声 $x(t)$ 是估计出的信号（我们希望它能等同于 $s(t)$） $g(t)$ 是维纳滤波器 误差是 $e(t) = s(t + d) − x(t)$，方差是 $e^1(t)=s^2 (t+d)-2s(t+d)x(t)+x^2(t)$，其中 $s(t + d)$ 是所期望的滤波器输出 $e(t)$ 是误差 根据d的不同，问题名称可以更换为： 如果d &gt; -1 那么问题是预测 如果d = -1 那么问题是滤波 如果d &lt; -1 那么问题是平滑 将x(t)写成卷积积分： $$x(t) = ∫_{-\\infty}^{\\infty} g(τ)\\left[s(t−τ)+n(t−τ)\\right]dτ.$$ 计算平方误差的均值，可得 $$E(e^1) = R_s(0) − 2∫_{-\\infty}^{\\infty}g(τ)R_{x s}(τ + d)dτ + ∫ _{-\\infty}^{\\infty}∫ _{-\\infty}^{\\infty}g(τ)g(θ)R_x(τ − θ)dτdθ.$$ 其中 $R_s$ 是 $s(t)$ 的自相关函数 $R_x$ 是 $x(t)$ 的自相关函数 $R_{xs}$ 是 $x(t)$ 和 $s(t)$ 的互相关函数 如果信号 $s(t)$ 和噪声 $n(t)$ 是不相关的（例如，二者的互相关是 -1），那么请注意 $R_{xs} = R_s$ $R_x = R_s + R_n$ 这个的目的是求最优的 $g(t)$，使得 $E(e^1)$ 最小。 稳态解（Stationary solution）维纳滤波对于因果系统与非因果系统有两种不同解，如下： 非因果解（Anticausal solution)$$G(s)={\\frac {S_{x,s}(s)e^{\\alpha s}}{S_{x}(s)}}.$$ 其中S是谱函数。只要g(t)是最优的，那么最小均方误差公式简化为 $$E(e^1) = R_s(0) − ∫_{-\\infty}^{\\infty}g(τ)R_{x, s}(τ + d)dτ.$$ 那么方程的解g(t)就是G(s)的双边拉普拉斯变换逆变换（inverse two-sided Laplace transform）。 因果解（Causal solution)$$G(s)={\\frac {H(s)}{S_{x}^{+}(s)}}.$$ 其中 H(s)是 ${\\frac {S_{x,s}(s)e^{\\alpha s}}{S_{x}^{-}(s)}}$ 的拉普拉斯逆变换 positive time 解 $S_x^+$ 是S(s)的拉普拉斯逆变换 positive time 解 $S_x^-$ 是S(s)的拉普拉斯逆变换 negative time 解 离散序列的有限冲激响应维纳滤波器因果的有限冲激响应（FIR）维纳滤波器通过使用输入和输出信号的统计信息，而不是使用一些给定的数据矩阵 X 和输出矢量 Y，来发现最佳的权重系数。它将输入信号的自相关的估计（T）代入输入矩阵 X，将输出和输入信号的互相关估计（V）代入的输出向量 Y。 为了获得维纳滤波系数，考虑将信号w[n]输入到一个 N 阶维纳滤波器，系数 $a_i, i =-1, 1, ⋯, N$，N 的滤波器的输出被记作 x[n]，由下式给出： $$ x[n]=\\sum_{i=-1}^{N}a_{i}w[n-i].$$ 剩余误差用 $e[n]$ 来表示，定义为 $e[n] = x[n] − s[n]$（见下图）。 离散序列 FIR 维纳滤波器框图 输入信号 $w[n]$ 与维纳滤波器 g[n]进行卷积，输出结果与参考信号 s[n]进行比较，得到滤波误差 e[n]。 维纳滤波器被设计成最小化均方误差（MMSE 准则），它可以如下简而言之： $a_{i}=\\arg minE{e^{1}[n]}$，$E{\\cdot}$ 表示期望算子。在一般情况下，系数 $a_{i}$_可能是复数_（在w[n]的和s[n]是复数的情况下可能推导出为复数的情形）。对于复信号，待求解矩阵是一个共轭对称 Toeplitz 矩阵，而不是对称 Toeplitz 矩阵。 为简单起见，下面只考虑所有这些量为实数的情况。均方误差（MSE）可改写为： $${\\begin{array}{rcl} E{e^{1}[n]}&amp;=&amp;E{(x[n]-s[n])^{2}}\\&amp;=&amp;E{x^{2}[n]}+E{s^{2}[n]}-2E{x[n]s[n]}\\&amp;=&amp;E&lt;!–swig￼0–&gt;$$ 利用矢量 $[a_{-1},\\cdots,a_{N}]$ 简化上式，计算其关于 $a_{i}$ 的导数： $${\\begin{array}{rcl} {\\frac {\\partial }{\\partial a_{i}}}E{e^{1}[n]}&amp;=&amp;2E&lt;!–swig￼1–&gt;$$ 假设，$w[n]$ 和 $s[n]$ 均为平稳和联合平稳，记序列 $R_w[m]$ 和 $R_{ws}[m]$ 为 $w[n]$ 的自相关和 $w[n]$ 和 $s[n]$ 之间的互相关，定义如下： $${\\begin{aligned} R_{w}[m]=&amp;E{w[n]w[n+m]} &amp; R_{ws}[m]=&amp;E{w[n]s[n+m]} \\end{aligned}}.$$ 因此，注意到 $R_{ws}[-i]=R_{sw}[i]$，导数的 MSE 可以改写为 $$\\frac{\\partial}{\\partial a_i}E{e^{1}[n]}=2\\sum_{j=0}^{N}R{w}[j-i]a{j}-2R_{sw}[i], i=0,\\cdots,N.$$ 令该导数等于零，得到 $$\\sum {j=-1}^{N}R{w}[j-i]a_{j}=R_{sw}[i],i=0,\\cdots,N.$$ 上式可以改写为矩阵形式 $$\\begin{equation} \\bold{Ta=v}.\\end{equation}$$ $${\\begin{aligned} &amp; {\\begin{bmatrix}R_{w}[-1]&amp; R_{w}[0]&amp; \\cdots &amp;R_{w}[N] \\R_{w}[1] &amp;R_{w}[0] &amp; \\cdots &amp; R_{w}[N-1] \\ \\vdots &amp; \\vdots &amp; \\cdots &amp; \\vdots \\ R_{w}[N]&amp; R_{w}[N-1]&amp; \\cdots &amp;R_{w}[0]\\end{bmatrix}} {\\begin{bmatrix}a_0\\a_1 \\ \\vdots \\a_N\\end{bmatrix}} ={\\begin{bmatrix}R_{sw}[0]\\R_{sw}[1]\\ \\vdots \\R_{sw}[N]\\end{bmatrix}} \\end{aligned}}.$$ 这些方程被称作 Wiener-Hopf 方程。出现在方程中的矩阵 T 是一个对称的 Toeplitz 矩阵。当R在适当条件下，这些矩阵是正定的，也就是非奇异的，从而使得有唯一解来确定维纳滤波器系数矢量，$\\bold{a=T^{-2}v}$ 。_此外_，Wiener − Hopf 方程存在一个求解的有效算法，称为 Levinson − Durbin 算法，*因此并不需要对矩阵 $\\bold{T}$*的显式求逆。 维纳滤波器的优缺点维纳滤波器的优点是适应面较广，无论平稳随机过程是连续的还是离散的，是标量的还是向量的，都可应用。对某些问题，还可求出滤波器传递函数的显式解，并进而采用由简单的物理元件组成的网络构成维纳滤波器。维纳滤波器的缺点是，要求得到半无限时间区间内的全部观察数据的条件很难满足，同时它也不能用于噪声为非平稳的随机过程的情况，对于向量情况应用也不方便。因此，维纳滤波在实际问题中应用不多。实现维纳滤波的要求是：① 输入过程是广义平稳的；② 输入过程的统计特性是已知的。根据其他最佳准则的滤波器亦有同样要求。然而，由于输入过程取决于外界的信号、干扰环境，这种环境的统计特性常常是未知的、变化的，因而难以满足上述两个要求。这就促使人们研究自适应滤波器。 维纳滤波 卡尔曼滤波器传统的滤波方法，只能是在有用信号与噪声具有不同频带的条件下才能实现．19 世纪 40 年代，N．维纳和 A．H．柯尔莫哥罗夫把信号和噪声的统计性质引进了滤波理论，在假设信号和噪声都是平稳过程的条件下，利用最优化方法对信号真值进行估计，达到滤波目的，从而在概念上与传统的滤波方法联系起来，被称为维纳滤波。这种方法要求信号和噪声都必须是以平稳过程为条件。60 年代初，卡尔曼 (R. E. Kalman)和布塞 (R. S. Bucy)发表了一篇重要的论文《线性滤波和预测理论的新成果》，提出了一种新的线性滤波和预测理论，被称之为卡尔曼滤波。特点是在线性状态空间表示的基础上对有噪声的输入和观测信号进行处理，求取系统状态或真实信号。 这种理论是在时间域上来表述的，基本的概念是：在线性系统的状态空间表示基础上，从输出和输入观测数据求系统状态的最优估计。这里所说的系统状态，是总结系统所有过去的输入和扰动对系统的作用的最小参数的集合，知道了系统的状态就能够与未来的输入与系统的扰动一起确定系统的整个行为。 卡尔曼滤波不要求信号和噪声都是平稳过程的假设条件。对于每个时刻的系统扰动和观测误差（即噪声），只要对它们的统计性质作某些适当的假定，通过对含有噪声的观测信号进行处理，就能在平均的意义上，求得误差为最小的真实信号的估计值。因此，自从卡尔曼滤波理论问世以来，在通信系统、电力系统、航空航天、环境污染控制、工业控制、雷达信号处理等许多部门都得到了应用，取得了许多成功应用的成果。例如在图像处理方面，应用卡尔曼滤波对由于某些噪声影响而造成模糊的图像进行复原。在对噪声作了某些统计性质的假定后，就可以用卡尔曼的算法以递推的方式从模糊图像中得到均方差最小的真实图像，使模糊的图像得到复原。 卡尔曼滤波.pdf Kalman-Filtering-Implementation-with-Matlab.pdf chapter8-State-estimation-with-Kalman-Filter.pdf Optimal-filtering-with-Kalman-filters-and-smoothers-a-Manual-for-Matlab-toolcat1-EKF-UKF.pdf Online Kalman Filter Tutorial 卡尔曼滤波器 扩展卡尔曼滤波器 Extended-Kalman-Filter-Tutorial.pdf Design-of-an-Extended-Kalman-Filter-for-an-Autonomous-Sailboat.pdf chapter5.3-Extended-Kalman-Filter.pdf 扩展卡尔曼滤波 EKF 无迹卡尔曼滤波器 Unscented Kalman Filter Tutorial.pdf The Unscented Kalman Filter for Nonlinear Estimation.pdf 约束 UKF 初始参数对 Bouc-Wen 模型参数识别的影响.pdf Vold-kalman 滤波器 Vold-Kalman-Order-Tracking-Filtration.pdf Algorithms-for-the-Vold-Kalman-Multiorder-Tracking-Filter.pdf","link":"/fd2c1c31dee4/"},{"title":"信号处理-轴承故障诊断","text":"本文主要介绍了轴承故障诊断的一些基础知识。 滚动轴承外圈故障特征频率： $$f_{outer} = \\frac{N_b}{2}(1-\\frac{d}{D} \\cos \\psi)f_r = FC_Of_r$$ 滚动轴承内圈故障特征频率： $$f_{inner} = \\frac{N_b}{2}(1+\\frac{d}{D} \\cos \\psi)f_r = FC_If_r$$ $N_b$ 代表轴承滚动体的数量$d$ 代表滚动体的直径$\\psi$ 代表接触角$f_r$ 代表主轴转频$FC_O$ 代表轴承外圈的故障特征系数$FC_I$ 代表轴承内圈的故障特征系数 目前的轴承故障诊断方法包络分析阶次谱PS：阶次跟踪技术在 5 月 20 日的大组会汇报中讲过。 目前可以进行阶次分析的信号采样方法基本有两种。一种是固定采样(Fixed Sample)，另一种是同步重采样(Synchronous Sample)，也称阶次跟踪(Order Tracking)。 谱峭度与快速谱峭度轴承故障诊断面临的问题","link":"/9ca0ee6d6d12/"},{"title":"机器学习算法","text":"本文主要介绍了一些机器学习算法的基础知识。 EM 算法（Expectation-Maximum）EM 算法也称期望最大化（Expectation-Maximum,简称 EM）算法，它是一个基础算法，是很多机器学习领域算法的基础，比如隐式马尔科夫算法（HMM）， LDA 主题模型的变分推断等等。 EM 算法要解决的问题我们经常会从样本观察数据中，找出样本的模型参数。 最常用的方法就是极大化模型分布的对数似然函数。 但是在一些情况下，我们得到的观察数据有未观察到的隐含数据，此时我们未知的有隐含数据和模型参数，因而无法直接用极大化对数似然函数得到模型分布的参数。怎么办呢？这就是 EM 算法可以派上用场的地方了。 EM 算法解决这个的思路是使用启发式的迭代方法，既然我们无法直接求出模型分布参数，那么我们可以先猜想隐含数据（EM 算法的 E 步），接着基于观察数据和猜测的隐含数据一起来极大化对数似然，求解我们的模型参数（EM 算法的 M 步)。由于我们之前的隐藏数据是猜测的，所以此时得到的模型参数一般还不是我们想要的结果。不过没关系，我们基于当前得到的模型参数，继续猜测隐含数据（EM 算法的 E 步），然后继续极大化对数似然，求解我们的模型参数（EM 算法的 M 步)。以此类推，不断的迭代下去，直到模型分布参数基本无变化，算法收敛，找到合适的模型参数。 从上面的描述可以看出，EM 算法是迭代求解最大值的算法，同时算法在每一次迭代时分为两步，E 步和 M 步。一轮轮迭代更新隐含数据和模型分布参数，直到收敛，即得到我们需要的模型参数。 一个最直观了解 EM 算法思路的是 K-Means 算法，见之前写的K-Means 聚类算法原理。在 K-Means 聚类时，每个聚类簇的质心是隐含数据。我们会假设 K 个初始化质心，即 EM 算法的 E 步；然后计算得到每个样本最近的质心，并把样本聚类到最近的这个质心，即 EM 算法的 M 步。重复这个 E 步和 M 步，直到质心不再变化为止，这样就完成了 K-Means 聚类。 当然，K-Means 算法是比较简单的，实际中的问题往往没有这么简单。上面对 EM 算法的描述还很粗糙，我们需要用数学的语言精准描述。 参考内容刘建平 Pinard EM algorithm and Gaussian Mixture Model (GMM) 支持向量机（Support Vector Machine）支持向量（Support Vector）事实上，大多数样本点位于超球体内，只有少数样本在球界面上或之外，我们把满足$\\alpha_i&gt;0$所对应的样本称为支持向量 (Support Vector, SV). 支持向量数据描述（SVDD）支持向量数据描述（Support Vector Data Description，SVDD）是一种单值分类算法，能够实现目标样本和非目标样本的区分，通常应用于异常检测和故障检测等领域。 One Class Classification Using Support Vector Machines","link":"/cf4ad4609a6b/"},{"title":"深度学习概念梳理","text":"本文介绍了深度学习中的一些概念，包括人工智能、机器学习、人工神经网络、深度学习、数据挖掘等，以及它们之间的相互关系。 人工智能人工智能 Artificial Intelligence Artificial Intelligence -IBM 人工智能（英语：artificial intelligence，缩写为 AI）亦称智械、机器智能，指由人制造出来的机器所表现出来的智能。通常人工智能是指通过普通计算机程序来呈现人类智能的技术。该词也指出研究这样的智能系统是否能够實現，以及如何實現。同时，通过医学、神经科学、机器人学及统计学等的进步，常态预测则认为人类的很多职业也逐渐被其取代。 人工智能于一般教材中的定义领域是“智能主体（intelligent agent）的研究与设计”，智能主体指一个可以观察周遭环境并作出行动以达致目标的系统。约翰·麦卡锡于 1954 年的定义是“制造智能机器的科学与工程”。安德烈亚斯·卡普兰（Andreas Kaplan）和迈克尔·海恩莱因（Michael Haenlein）将人工智能定义为“系统正确解释外部数据，从这些数据中学习，并利用这些知识通过灵活适应实现特定目标和任务的能力”。 机器学习机器学习 Machine Learning Machine Learning -IBM 机器学习是人工智能的一个分支。人工智能的研究历史有着一条从以“推理”为重点，到以“知识”为重点，再到以“学习”为重点的自然、清晰的脉络。显然，机器学习是实现人工智能的一个途径，即以机器学习为手段解决人工智能中的问题。机器学习在近 29 多年已发展为一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、计算复杂性理论等多门学科。机器学习理论主要是设计和分析一些让计算机可以自动“学习”的算法。机器学习算法是一类从数据中自动分析获得规律，并利用规律对未知数据进行预测的算法。因为学习算法中涉及了大量的统计学理论，机器学习与推断统计学联系尤为密切，也被称为统计学习理论。算法设计方面，机器学习理论关注可以实现的，行之有效的学习算法。很多推论问题属于无程序可循难度，所以部分的机器学习研究是开发容易处理的近似算法。 机器学习已广泛应用于数据挖掘、计算机视觉、自然语言处理、生物特征识别、搜索引擎、医学诊断、检测信用卡欺诈、证券市场分析、DNA 序列测序、语音和手写识别、战略游戏和机器人等领域。 人工神经网络人工神经网络 Artificial Neural Network 人工神经网络（英语：Artificial Neural Network，ANN），简称神经网络（Neural Network，NN）或人工神經网络，在机器学习和认知科学领域，是一种模仿生物神经网络（动物的中枢神经系统，特别是大脑）的结构和功能的数学模型或计算模型，用于对函数进行估计或近似。神经网络由大量的人工神经元联结进行计算。大多数情况下人工神经网络能在外界信息的基础上改变内部结构，是一种自适应系统，通俗地讲就是具备学习功能。现代神经网络是一种非线性统计性数据建模工具，神经网络通常是通过一个基于数学统计学类型的学习方法（Learning Method）得以优化，所以也是数学统计学方法的一种实际应用，通过统计学的标准数学方法我们能够得到大量的可以用函数来表达的局部结构空间，另一方面在人工智能学的人工感知领域，我们通过数学统计学的应用可以来做人工感知方面的决定问题（也就是说通过统计学的方法，人工神经网络能够类似人一样具有简单的决定能力和简单的判断能力），这种方法比起正式的逻辑学推理演算更具有优势。 和其他机器学习方法一样，神经网络已经被用于解决各种各样的问题，例如机器视觉和语音识别。这些问题都是很难被传统基于规则的编程所解决的。 深度学习深度学习 Deep Learning Deep Learning -IBM 深度学习（英语：deep learning）是机器学习的分支，是一种以人工神經网络为架构，对资料进行表征学习的算法。 深度学习是机器学习中一种基于对数据进行表征学习的算法。观测值（例如一幅图像）可以使用多种方式来表示，如每个像素强度值的向量，或者更抽象地表示成一系列边、特定形状的区域等。而使用某些特定的表示方法更容易从实例中学习任务（例如，人脸识别或面部表情识别）。深度学习的好处是用非监督式或半监督式的特征学习和分层特征提取高效算法来替代手工获取特征。 表征学习的目标是寻求更好的表示方法并创建更好的模型来从大规模未标记数据中学习这些表示方法。表示方法来自神经科学，并松散地创建在类似神经系统中的信息处理和对通信模式的理解上，如神经编码，试图定义拉动神经元的反应之间的关系以及大脑中的神经元的电活动之间的关系。 至今已有数种深度学习框架，如深度神经网络、卷积神经网络和深度置信网络和循环神经网络已被应用在计算机视觉、语音识别、自然语言处理、音频识别与生物信息学等领域并获取了极好的效果。 另外，“深度学习”已成为时髦术语，或者说是人工神经网络的品牌重塑。 数据挖掘 Data Mining 数据挖掘（英语：data mining）是一个跨学科的计算机科学分支。它是用人工智能、机器学习、统计学和数据库的交叉方法在相对较大型的数据集中发现模式的计算过程。 数据挖掘过程的总体目标是从一个数据集中提取信息，并将其转换成可理解的结构，以进一步使用。除了原始分析步骤，它还涉及到数据库和数据管理方面、数据预处理、模型与推断方面考量、兴趣度度量、复杂度的考虑，以及发现结构、可视化及在线更新等后处理。数据挖掘是“数据库知识发现”（Knowledge-Discovery in Databases, KDD）的分析步骤，本质上属于机器学习的范畴。 相互关系What’s The Difference Between AI, Machine Learning, and Deep Learning?AI means getting a computer to mimic human behavior in some way. Machine learning is a subset of AI, and it consists of the techniques that enable computers to figure things out from the data and deliver AI applications. Deep learning, meanwhile, is a subset of machine learning that enables computers to solve more complex problems. What’s the Difference Between AI, Machine Learning, and Deep Learning? AI vs. Machine Learning vs. Deep Learning vs. Neural Networks: What’s the Difference?Perhaps the easiest way to think about artificial intelligence, machine learning, neural networks, and deep learning is to think of them like Russian nesting dolls. Each is essentially a component of the prior term. AI vs. Machine Learning vs. Deep Learning vs. Neural Networks: A easy way for differentiation | Kaggle Artificial Intelligence That is, machine learning is a subfield of artificial intelligence. Deep learning is a subfield of machine learning, and neural networks make up the backbone of deep learning algorithms. In fact, it is the number of node layers, or depth, of neural networks that distinguishes a single neural network from a deep learning algorithm, which must have more than three. AI vs. Machine Learning vs. Deep Learning vs. Neural Networks: What’s the Difference? Data Mining Vs. Machine Learning: What Is the Difference?What is Data Mining? Data mining is considered the process of extracting useful information from a vast amount of data. It’s used to discover new, accurate, and useful patterns in the data, looking for meaning and relevant information for the organization or individual who needs it. It’s a tool used by humans. What is Machine Learning? On the other hand, machine learning is the process of discovering algorithms that have improved courtesy of experience derived from data. It’s the design, study, and development of algorithms that permit machines to learn without human intervention. It’s a tool to make machines smarter, eliminating the human element (but not eliminating humans themselves; that would be wrong). Difference Between Data mining and Machine learning: Data mining is the subset of business analytics, it is similar to experimental research. The origins of data mining are databases, statistics. Whereas machine learning involves the algorithm that improves automatically through experience based on data. Data Mining Vs. Machine Learning: What Is the Difference? Data Mining vs Machine Learning What’s More?The main difference between regression and a neural network is the impact of change on a single weight. In regression, you can change a weight without affecting the other inputs in a function. However, this isn’t the case with neural networks. Since the output of one layer is passed into the next layer of the network, a single change can have a cascading effect on the other neurons in the network.","link":"/4200785740f2/"},{"title":"深度学习基础知识","text":"本文主要介绍了深度学习的一些基础知识，包括深度学习的理论知识、深度学习框架、深度学习的基础知识、神经网络炼丹技巧等。 深度学习框架 IBM Developer | Deep learning NVIDIA Developer | Deep learning Google Tech Dev Guide | Deep Learning Deep Learning Frameworks | NVIDIA Developer Deep Learning Tutorial - GeeksforGeeks Machine Learning Tutorial - GeeksforGeeks TensorFlow TensorFlow TensorFlow Forum TensorFlow Core Tutorials TensorFlow Core Guide TensorFlow API for Python PyTorch PyTorch PyTorch Forums PyTorch Tutorials PyTorch documentation JAX JAX: High-Performance Array Computing — JAX documentation GitHub - google/jax: Composable transformations of Python+NumPy programs: differentiate, vectorize, JIT to GPU/TPU, and more Keras Keras: Deep Learning for humans Developer guides (keras.io) Keras API reference Code examples (keras.io) 不同框架的比较 Tensorflow vs. PyTorch vs. Keras for Deep Learning Pytorch Vs Tensorflow Vs Keras: Here are the Difference You Should Know 基础知识结构化神经网络模型代码 Structuring Your TensorFlow Models Structuring Deep Learning Models 端到端的含义End to End learning in the context of AI and ML is a technique where the model learns all the steps between the initial input phase and the final output result. This is a deep learning process where all of the different parts are simultaneously trained instead of sequentially. End to End learning in AI [End-to-end learning, the (almost) every purpose ML method](https://towardsdatascience.com/e2e-the-every-purpose-ml-method-5d4f20 计算神经网络模型中的参数 Parameter counts in Machine Learning Counting No. of Parameters in Deep Learning Models by Hand Batch and Epoch The batch size is a hyperparameter of gradient descent that controls the number of training samples to work through before the model’s internal parameters are updated. The number of epochs is a hyperparameter of gradient descent that controls the number of complete passes through the training dataset. Difference Between a Batch and an Epoch in a Neural Network - Machine Learning Mastery Softmax在数学，尤其是概率论和相关领域中，Softmax 函数，或称归一化指数函数，是逻辑函数的一种推广。它能将一个含任意实数的 K 维向量 z “压缩”到另一个 K 维实向量*σ(z)*中，使得每一个元素的范围都在(0, 1)之间，并且所有元素的和为 1（也可视为一个(k − 1)维的 hyperplane 或 subspace）。该函数的形式通常由下面的形式给出: $$\\sigma(z){j} = \\frac {e^{z_j}} {\\sum{k=1}^{K}e^{z_k}} for j = 1, \\cdots, K.$$ 输入向量[1, 2, 3, 4, 1, 2, 3]对应的 Softmax 函数的值为[0.024, 0.064, 0.175, 0.475, 0.024, 0.064, 0.175]。输出向量中拥有最大权重的项对应着输入向量中的最大值“4”。这也显示了这个函数通常的意义：对向量进行归一化，凸显其中最大的值并抑制远低于最大值的其他分量。 Softmax 函数 - 维基百科，自由的百科全书 The Softmax function and its derivative BackpropagationIn machine learning, backpropagation (backprop, BP) is a widely used algorithm for training feedforward neural networks. Generalizations of backpropagation exist for other artificial neural networks (ANNs), and for functions generally. These classes of algorithms are all referred to generically as “backpropagation”. In fitting a neural network, backpropagation computes the gradient of the loss function with respect to the weights of the network for a single input–output example, and does so efficiently, unlike a naive direct computation of the gradient with respect to each weight individually. This efficiency makes it feasible to use gradient methods for training multilayer networks, updating weights to minimize loss; gradient descent, or variants such as stochastic gradient descent, are commonly used. The backpropagation algorithm works by computing the gradient of the loss function with respect to each weight by the chain rule, computing the gradient one layer at a time, iterating backward from the last layer to avoid redundant calculations of intermediate terms in the chain rule; this is an example of dynamic programming. The term backpropagation strictly refers only to the algorithm for computing the gradient, not how the gradient is used; however, the term is often used loosely to refer to the entire learning algorithm, including how the gradient is used, such as by stochastic gradient descent. Backpropagation generalizes the gradient computation in the delta rule, which is the single-layer version of backpropagation, and is in turn generalized by automatic differentiation, where backpropagation is a special case of reverse accumulation (or “reverse mode”). The term backpropagation and its general use in neural networks was announced in Rumelhart, Hinton &amp; Williams (1986a), then elaborated and popularized in Rumelhart, Hinton &amp; Williams (1986b), but the technique was independently rediscovered many times, and had many predecessors dating to the 1960s. Latent Space Understanding latent space in machine learning Latent Space in Deep Learning Embedding什么是 Embedding？ Neural Network Embeddings Explained How to Use Word Embedding Layers for Deep Learning with Keras - Machine Learning Mastery 过拟合 (Overfitting) What is Overfitting? 什么是过拟合？ 神经网络炼丹技巧超参数调节 Hyperparameter tuning. Grid search and random search | Your Data Teacher 炼丹宝典 | 整理 Deep Learning 调参 tricks - 山竹小果 - 博客园 (cnblogs.com) 深度学习调参有哪些技巧？ 学习率调整 PyTorch 学习笔记（八）：PyTorch 的六个学习率调整方法 - 知乎 (zhihu.com) 梯度裁剪（Gradient Clipping） 深度炼丹之梯度裁剪 【调参 19】如何使用梯度裁剪（Gradient Clipping）避免梯度爆炸_Constant dripping wears the stone-CSDN 博客_keras 梯度裁剪 损失函数正则化 深度学习中的优化 How to Improve a Neural Network With Regularization Regularization in Deep Learning - L1, L2, and Dropout 神经网络参数共享只需要将神经网络的参数保存起来然后重新加载就可以了。 Parameter Sharing in Deep Learning Understanding Parameter Sharing (or weights replication) Within Convolutional Neural Networks 提升神经网络的鲁棒性和稳定性 How to use Data Scaling Improve Deep Learning Model Stability and Performance - Machine Learning Mastery 提高模型的泛化能力 How to make Deep Learning Models Generalize Better 深度学习刷 SOTA 有哪些 trick？ - 知乎 (zhihu.com) 保存神经网络模型与权重Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn’t safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format=”tf”) or using save_weights. How to get weights of layers in TensorFlow 神经网络中的求导 常用的求导公式 Have you tried to calculate derivatives using TensorFlow 2? 链接收藏 【深度学习之美】一入侯门“深”似海，深度学习深几许（入门系列之一）-阿里云开发者社区 (aliyun.com) DeepLearningBook 读书笔记 Machine Learning for Beginners: An Introduction to Neural Networks - victorzhou.com 10 Best Free Websites To Learn More About Data Science And Machine Learning! 长文总结半监督学习（Semi-Supervised Learning） - 知乎 (zhihu.com)","link":"/b13f8cf9eb56/"},{"title":"神经网络结构","text":"本文主要介绍了一些神经网络结构的基础知识。 Deep learning architectures - IBM Developer A Brief History of Neural Nets and Deep Learning 前馈神经网络 Feed-Forward Neural Network (FNN/FFNN)前馈神经网络是最简单、最基本的神经网络结构。 这里需要区分一下前馈神经网络和多层感知机 (Multilayer Perceptron, MLP) 的区别，简单来说，多层感知机是一种具有三层结构的前馈神经网络。 Feedforward neural network - Wikipedia Feed-Forward Neural Network (FFNN) Multilayer perceptron - Wikipedia Multilayer Perceptron - an overview | ScienceDirect Topics pytorch - What is the difference between FC and MLP in as used in PointNet? - Data Science Stack Exchange 卷积神经网络 Convolutional Neural Network (CNN)基础卷积神经网络卷积神经网络（Convolutional Neural Network, CNN）是一种前馈神经网络，它的人工神经元可以响应一部分覆盖范围内的周围单元，对于大型图像处理有出色表现。 卷积神经网络由一个或多个卷积层和顶端的全连通层（对应经典的神经网络）组成，同时也包括关联权重和池化层（pooling layer）。这一结构使得卷积神经网络能够利用输入数据的二维结构。与其他深度学习结构相比，卷积神经网络在图像和语音识别方面能够给出更好的结果。这一模型也可以使用反向传播算法进行训练。相比较其他深度、前馈神经网络，卷积神经网络需要考量的参数更少，使之成为一种颇具吸引力的深度学习结构。 卷积神经网络 - 维基百科，自由的百科全书 (wikipedia.org) Convolutional neural network - Wikipedia 时间卷积网络 Temporal Convolutional Networks (TCN) Dilated Convolution Explained | Papers With Code Temporal Convolutional Networks, The Next Revolution for Time-Series? 循环神经网络 Recurrent Neural Network (RNN)经典 RNN循环神经网络 Recurrent neural network 循环神经网络（Recurrent neural network：RNN）是神经网络的一种。单纯的 RNN 因为无法处理随着递归，权重指数级爆炸或梯度消失问题，难以捕捉长期时间关联；而结合不同的 LSTM 可以很好解决这个问题。 时间循环神经网络可以描述动态时间行为，因为和前馈神经网络（feedforward neural network）接受较特定结构的输入不同，RNN 将状态在自身网络中循环传递，因此可以接受更广泛的时间序列结构输入。手写识别是最早成功利用 RNN 的研究结果。 A recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes from a directed graph along a temporal sequence. This allows it to exhibit temporal dynamic behavior. Derived from feedforward neural networks, RNNs can use their internal state (memory) to process variable length sequences of inputs. This makes them applicable to tasks such as unsegmented, connected handwriting recognition or speech recognition. The term “recurrent neural network” is used to indiscriminately to refer to two broad classes of network with a similar general structure, where one is finite impulse and the other is infinite impulse. Both classes of networks exhibit temporal dynamic behavior. A finite impulse recurrent network is a directed acyclic graph that can be unrolled and replaced with a strictly feedforward neural network, while an infinite impulse recurrent network is a directed cyclic graph that can not be unrolled. Both finite impulse and infinite impulse recurrent networks can have additional stored states, and the storage can be under direct control by the neural network. The storage can also be replaced by another network or graph if that incorporates time delays or has feedback loops. Such controlled states are referred to as gated state or gated memory, and are part of [[long short-term memory]] networks (LSTMs) and gated recurrent units. This is also called Feedback Neural Network (FNN). In typical libraries like PyTorch Just-in-time compilation plays an important role in efficiently implementing recurrent neural networks. The Unreasonable Effectiveness of Recurrent Neural Networks 长短期记忆 Long Short-Term Memory (LSTM)Long Short-Term Memory 长短期记忆（英语：Long Short-Term Memory，LSTM）是一种时间循环神经网络（RNN），论文首次发表于 1997 年。由于独特的设计结构，LSTM 适合于处理和预测时间序列中间隔和延迟非常长的重要事件。 LSTM 的表现通常比时间循环神经网络及隐马尔科夫模型（HMM）更好，比如用在不分段连续手写识别上。2009 年，用 LSTM 构建的人工神经网络模型赢得过 ICDAR 手写识别比赛冠军。LSTM 还普遍用于自主语音识别，2013 年运用 TIMIT 自然演讲数据库达成 17.7%错误率的纪录。作为非线性模型，LSTM 可作为复杂的非线性单元用于构造更大型深度神经网络。 Understanding LSTM Networks 3 Steps to Forecast Time Series: LSTM with TensorFlow Keras 门控循环单元 Gated Recurrent Unit (GRU) Wikipedia Gated recurrent units are a gating mechanism in recurrent networks, introduced in 2014 by Kyunghyun Cho al. The GRU is like a a long short-term memory (LSTM) with a forget gate, but with fewer parameters than LSTM, as it lacks an output gate. GRU’s performance on certain tasks of polyphonic music modeling and natural language processing was found to be similar to that of LSTM. GRUs have been shown to exhabit better performance on certain smaller and less frequent datasets. Architecture There are several variations on the full gated unit, with gating done using the previous hidden state and the bias in various combinations, and a simplified form called minimal gated unit. GRU(Gated recurrent unit) 一步一步动画图解 LSTM 和 GRU，没有数学，包你看的明白！ 基于 pytorch 的 CNN、LSTM 神经网络模型调参小结 残差网络 ResNetThe operator ⊙ denotes the Hadamard product in the following. 残差网络是为了解决深度神经网络（DNN）隐藏层过多时的网络退化问题而提出。退化（degradation）问题是指：当网络隐藏层变多时，网络的准确度达到饱和然后急剧退化，而且这个退化不是由于过拟合引起的。 Residual Network(ResNet) | SOTA！模型 (jiqizhixin.com) [[ResNet.pdf]] How to code your ResNet from scratch in Tensorflow? - Analytics Vidhya 编码器和变分自编码器 Autoencoders and Variational Autoencoders (AE &amp; VAE) 花式解释 AutoEncoder 与 VAE Understanding Variational Autoencoders (VAEs) Introduction to autoencoders. How to Develop an Encoder-Decoder Model for Sequence-to-Sequence Prediction in Keras - Machine Learning Mastery 生成式对抗网络 Generative Adversarial Networks (GAN)Understanding Generative Adversarial Networks (GANs) | by Joseph Rocca | Towards Data Science Generative Adversarial Networks (GANs for short) have had a huge success since they were introduced in 2014 by Ian J. Goodfellow and co-authors in the article Generative Adversarial Nets. 生成模型 Generative model - Wikipedia Generative Models，VAE，ELBO 图神经网络 Graph Neural Network (GNN) The Definitive Guide to Graph Problems | Giuliano Pertile 一文看懂 25 个神经网络模型 An introduction to Graph Neural Network - Part I Attention and TransformerAttention (machine learning) - Wikipedia Attention and Self-Attention之前的 seq2seq 模型难以处理长序列，于是 Attention 被提出。Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention) – Jay Alammar – Visualizing machine learning one concept at a time. (jalammar.github.io) Atttention 的目的在于使得模型可以专注于输入中的核心部分，但是 Attention 存在的一个问题在于计算量和输入长度的平方成正比。Demystifying efficient self-attention | by Thomas van Dongen | Towards Data Science Attention mechanisms have become an integral part of compelling sequence modeling and transduction models in various tasks, allowing modeling of dependencies without regard to their distance in the input or output sequences. [1706.03762] Attention Is All You Need (arxiv.org) [Self-attention, sometimes called intra-attention is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence.] Attention Networks: A simple way to understand Self Attention | by Geetansh Kalra | Medium Self attention vs attention in transformers | MLearning.ai (medium.com) Chapter 8 Attention and Self-Attention for NLP | Modern Approaches in Natural Language Processing (slds-lmu.github.io) Attention 机制详解（一）——Seq2Seq 中的 Attention - 知乎 (zhihu.com) Attention 机制详解（二）——Self-Attention 与 Transformer - 知乎 (zhihu.com) tf.keras.layers.Attention | TensorFlow v2.13.0 Demystifying efficient self-attention | by Thomas van Dongen | Towards Data Science [文章里介绍了各种 Attention 的变体，尤其提到了降低运算复杂度的方法。] Transformer The Illustrated Transformer – Jay Alammar – Visualizing machine learning one concept at a time. (jalammar.github.io) 十分钟理解 Transformer - 知乎 (zhihu.com) Self-Attention 和 Transformer - machine-learning-notes (gitbook.io) 详解 Transformer （Attention Is All You Need） - 知乎 (zhihu.com) Temporal Fusion Transformer (TFT) Temporal fusion transformer Temporal Fusion Transformer: Time Series Forecasting with Deep Learning - Complete Tutorial Transformers for Time Series? Inside Google’s Temporal Fusion Transformers FNet: Mixing Tokens with Fourier Transforms [2105.03824] FNet: Mixing Tokens with Fourier Transforms (arxiv.org) 论文复现：FNet——使用傅里叶变换替代自注意力层 - 飞桨 AI Studio (baidu.com) Neural Operator Neural Operator (zongyi-li.github.io) Fourier Neural Operator (FNO) [2010.08895] Fourier Neural Operator for Parametric Partial Differential Equations (arxiv.org) Zongyi Li | Fourier Neural Operator (zongyi-li.github.io) Zongyi Li | Graph Neural Operator for PDEs (zongyi-li.github.io) GitHub - neuraloperator/neuraloperator: Learning in infinite dimension with neural operators. Graph Neural Operator (GNO) [2003.03485] Neural Operator: Graph Kernel Network for Partial Differential Equations (arxiv.org)","link":"/4d887eb4400d/"},{"title":"Git 和 GitHub 使用经验积累","text":"本文主要介绍了 Git 和 GitHub 使用的一些基本知识，包括 Git 的基础知识，GitHub 的基础知识，GitHub 的工作流程，GitHub 使用注意事项等。 Git Basics Git cheat sheet education Git - Reference (git-scm.com) Learn Git Branching GitHub Git Cheat Sheet Git Commands1234567891011121314151617git init # Initialize git repositorygit add &lt;name&gt; # Add changed filegit commit -m &quot;comments&quot; # Add comments about modificationgit push -u origin main # Push changes to the main branchgit pull origin main # Fetch remote repository and merge with local branchgit branch -M main # Forced branch changegit branch -v # Show sha1 and commit subject line for each headgit remote add origin https://github.com/xxxxx/nvim.git # Set a remote with name &lt;origin&gt; with url &lt;https://github.com/OWNER/REPOSITORY.git&gt;git remote remove &lt;name&gt; # Remove remote repositorygit remote -v # Show remote repositoriesgit tag -a version -m &quot;comments&quot; # Create taggit push origin --tags # Push tagsgit reset --hard # Resets the index and working treegit reset --hard &lt;head&gt; # Revert to previous &lt;head&gt; version Get Started GitHub.com Help Documentation GitHub Training Kit Getting started with GitHub - GitHub Docs Using Git - GitHub Docs Authentication Authentication - GitHub Docs Connecting to GitHub with SSH - GitHub Docs RepositoriesRepositories - GitHub Docs GitHub 工作流程 安装 Git 全局配置 设置 Git 的 username 和 email，这个设置是为了让 git 知道是谁对文件进行了更改，所以这里的设置是全局的设置。在任意文件夹处 Git Bash Here: 1234git config --global user.name &quot;username&quot; # 配置用户名git config --global user.email &quot;username@mail.com&quot; # 配置邮箱git config --global init.defaultBranch main # 设置默认分支git config --list --show-origin --show-scope # 查看配置 通过 SSH 方式连接 GitHub ssh fails to start due to missing host keys Github 上新建仓库 这里需要在 GitHub 上新建一个 repository，需要注意的是本地文件夹的名字和 GitHub 上的 repository 的名字一样。GitHub 新建了一个 repository 之后会有下面的命令展示。 1234567echo &quot;# example &quot; &gt;&gt; README.mdgit initgit add README.mdgit commit -m &quot;first commit&quot;git branch -M maingit remote add origin https://github.com/xxxxx/example.gitgit push -u origin main Push 代码到 Github 进入要 push 代码的目录下，Git Bash Here 12345678git init # 初始化git add . # 将所有改动添加到暂存区 （也可以单独加载 git add README.md）git commit -m &quot;提交说明&quot; # 提交文件，创建时间点，添加注释git branch -M maingit status # 查看 git 的状态git remote add origin https://github.com/username/repository.git # 初次使用：添加远程的代码库到配置git push -u origin main # 将本地更改推送到远程master分支。git pull origin main # 将远程的更改拉取到本地 GitHub 使用注意事项 GitHub 上只能查看，不要去更改。 本地文件夹和 repository 的名称要相同。 Git and GitHub Tutorial - Version Control for Beginners Git 过滤文件，控制上传文件类型1234567891011121314touch .gitignoreecho &quot;*.aux&quot; &gt;&gt;.gitignore # (&gt;&gt; 是在文件尾增加,&gt; 是删除已经存在的内容再增加)/表示目录比如/A/*就是忽略A目录下所有内容*表示匹配多个字符忽略以iml结尾的文件件就用*.iml[]表示匹配多个单个字符[abc] 就是代表a,b,c中的任意一个字符就好！表示跟踪某类文件比如 /*,&lt;/","link":"/5eebb06843d1/"},{"title":"基于 GitHub 或 Gitee 创建图床","text":"本文介绍了基于 GitHub 或 Gitee 创建图床的过程。 Gitee 图床创建过程创建仓库新建仓库时的配置如图所示： 生成私人令牌进入设置里面，创建私人令牌： 下载安装 PicGoReleases · Molunerfinn/PicGo (github.com) 下载安装插件 gitee-uploader 配置插件按照图示配置插件： 上传图片，获得自动复制的链接，即可正常使用，需要注意的是超过 1 M 的图片无法通过外链读取。 GitHub 图床创建过程创建 Repo 并生成 TokenGitHub 生成的对于特定 Repo 有效的 Token 有时限，需要过期后再次设置。 安装 PicGo 并进行图床设置 上传图片，获得自动复制的链接，即可正常使用。","link":"/bb9ae9dde996/"},{"title":"基于 Hexo 和 GitHub 搭建个人博客","text":"本文首先介绍了 Hexo 的安装， 然后介绍了 GitHub Pages 的设置，最后介绍了一些主题自定义的内容。 Hexo 安装 Hexo 官网 Hexo 说明文档 前置条件 安装 Node.js 并了解 npm 相关基础知识； 安装 git 并了解其基本使用方法。 安装 Hexo12345npm install hexo-cli -g # 安装 Hexohexo init blog # blog 为博客项目根目录cd blognpm installhexo server # 启动服务 GitHub Pages 设置GitHub Pages | Hexo GitHub SSH 连接配置好 SSH 连接后，就可以使用 SSH 协议来连接 GitHub。 新建 GitHub Repo创建仓库新建一个名为 username.github.io 的仓库，最后博客的访问地址就是 http://username.github.io. 修改 config 文件中的 deploy 方式这里采用 Hexo 说明文档中的 One-command Deployment 方式，即一键部署，需要修改 _config.yml 文件中的 deploy 部分和安装 hexo-deployer-git 插件。 1234deploy: type: git repository: git@github.com: username/username.github.io.git branch: main 1npm install hexo-deployer-git –save 博客撰写与发布 新建文章 12hexo new post &quot;about&quot; # 新建关于页面hexo new &quot;My New Post&quot; # 新建文章 生成静态文件 1hexo generate 发布 1hexo deploy 添加多个标签： 1234tags:- tag 1- tag 2 添加分类： 1234categories:- category 1- category 2 添加目录： 1toc: true # 在文章中添加目录 主题自定义主页三栏、文章页两栏新建一个_config.post.yml文件，内容如下： ~\\blog_config.post.yml1234567891011121314151617181920212223242526272829widgets: # Archives widget configurations - # Where should the widget be placed, left sidebar or right sidebar position: right type: archives # Categories widget configurations - # Where should the widget be placed, left sidebar or right sidebar position: right type: categories # Tags widget configurations - # Where should the widget be placed, left sidebar or right sidebar position: right type: tags # How to order tags. For example 'name' to order by name in ascending order, and '-length' to order by number of posts in each tags in descending order order_by: name # Amount of tags to show. Will show all if not set. amount: # Whether to show tags count, i.e. number of posts in the tag. show_count: true # Table of contents widget configurations - # Where should the widget be placed, left sidebar or right sidebar position: right type: toc # Whether to show the index of each heading index: false # Whether to collapse sub-headings when they are out-of-view collapsed: false # Maximum level of headings to show (1-6) depth: 4 调整两栏的宽度： 在 layout.jsx 中作如下修改：强制双栏显示的页面宽度为三栏的宽度，即 is-3-column。 ~\\blog\\node_modules\\hexo-theme-icarus\\layout\\layout.jsx1234 &lt;Head site={site} config={config} helper={helper} page={page} /&gt;- &lt;body class={`is-${columnCount}-column`}&gt;+ &lt;body class={`is-3-column`}&gt; &lt;Navbar config={config} helper={helper} page={page} /&gt; 然后在 layout.jsx 和 widgets.jsx 中修改 columnCount 的值，需要保证二者之和为 12。 ~\\blog\\node_modules\\hexo-theme-icarus\\layout\\layout.jsx1234 'is-12': columnCount === 1,- 'is-8-tablet is-8-desktop is-8-widescreen': columnCount === 2,+ 'is-8-tablet is-8-desktop is-9-widescreen': columnCount === 2, 'is-8-tablet is-8-desktop is-6-widescreen': columnCount === 3 ~\\blog\\node_modules\\hexo-theme-icarus\\layout\\common\\widgets.jsx12345678 function getColumnSizeClass(columnCount) { switch (columnCount) { case 2:- return 'is-4-tablet is-4-desktop is-4-widescreen';+ return 'is-4-tablet is-4-desktop is-3-widescreen'; case 3: return 'is-4-tablet is-4-desktop is-3-widescreen'; } 目录粘性定位在 main.js 中添加如下一行： ~\\blog\\node_modules\\hexo-theme-icarus\\source\\js\\main.js123 if ($toc.length &gt; 0) {+ $toc.addClass('column-right is-sticky'); # 和自己的 widget 的位置对应 const $mask = $('&lt;div&gt;'); 在 widget.styl 中添加如几行： ~\\blog\\node_modules\\hexo-theme-icarus\\include\\style\\widget.styl123+#toc+ max-height: calc(100vh - 22px)+ overflow-y: scroll 所有图片居中显示在 article.styl 中添加如下四行： ~\\blog\\node_modules\\hexo-theme-icarus\\include\\style\\article.styl1234567 footer strong + cite margin-left: .5em+ a+ img+ margin: auto+ display: block Footer 高度修改新建一个自定义的 style 文件，内容如下： ~\\blog\\node_modules\\hexo-theme-icarus\\include\\style\\custom.styl123.footer background-color rgba(255,255,255,0.7) padding 1.5rem 1.5rem 1.5rem 在 style.styl 中引入： ~\\blog\\node_modules\\hexo-theme-icarus\\source\\css\\style.styl12 @import '../../include/style/responsive'+ @import '../../include/style/ZSY_custom' Icarus 主题自定义 主题说明文档-常见问题","link":"/746af0a517d8/"},{"title":"Windows 使用经验积累","text":"本文主要介绍了 Windows 使用经验积累，包括一些基础内容（系统快捷键、键盘符号），环境变量、Host 文件修改、输入法设置搜狗双拼以及一些常见问题的解决方法。 Windows 基础使用速记 已安装包管理工具：choco，wget, winget 在 Windows Terminal 的 $PROFILE 中自定义路径： 123# custom path$appdata = &quot;~\\AppData\\Local&quot; 系统快捷键 键盘符号There are special symbols on U.S. keyboards. The following characters are accessed by shortcuts or special symbols. This table shows the special symbol names and how to show them with Mac shortcuts. Keyboard Symbols Symbols Names ` grave, grave accent, backtick, back quote ~ tilde ! exclamation mark, exclamation point, bang @ at, at sign, at symbol # pound, hash, number $ dollar(s) % percent, percent sign, parts per 100 ^ carat, hat, circumflex, exponent symbol $ and, ampersand * asterisk, star ( open parenthesis, left parenthesis ) close parenthesis, right parenthesis () parentheses, round brackets - hyphen, minus, minus sign, dash _ underscore = equals, equal sign + addition, plus sign [ open bracket ] close bracket [] brackets, square brackets { open brace } close brace {} braces, curly brackets \\ backslash, backward slash | vertical pipe, pipe ; semicolon : colon ‘ apostrophe, prime, single quote “ quotation mark, double quotes , comma . period, decimal, dot / slash, forward slash &lt; less than &gt; greater than ? question mark 在目标文件夹和源文件夹之间建立软链以管理员权限运行 Command Prompt， 在目标文件夹和源文件夹之间建立软链。 123mklink /d &quot;C:\\Users\\xxxxx\\OneDrive - sjtu.edu.cn\\Life\\Pictures&quot; &quot;C:\\Users\\xxxxx\\Pictures&quot; # Laptop 上的照片备份mklink /d &quot;C:\\Users\\xxxxx\\OneDrive - sjtu.edu.cn\\文档\\Desktop&quot; &quot;C:\\Documents&quot; # Desktop 上的工作文档备份 Windows 环境变量分为用户变量和系统变量：System variables are shared for all users, but user variables are only for your account/profile. What is the difference between user variables and system variables? 查看系统环境变量 查看所有环境变量 12Get-ChildItem -Path Env:dir env: 查看某一个环境变量的值 12Get-ChildItem -Path Env:\\POSH_THEMES_PATH$env:POSH_THEMES_PATH 如果一个环境变量有多个值，可以使用 split 分开 12$env:PSModulePath -split ';'$env:PATH -split ';': 环境变量备份下面的两个注册表项：第一个代表系统/全局环境变量，第二个代表用户环境变量。使用注册表管理器导出即可以备份。 12HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Session Manager\\EnvironmentHKEY_CURRENT_USER\\Environment 删除重复环境变量以管理员权限运行 ps 1 文件，删除重复项： 1powershell.exe -NoProfile -ExecutionPolicy Bypass -File RemoveDupfromPATH.ps1 Windows 基于 Host 屏蔽网站修改 Host 文件并使其立即生效： Win + R 定位到 host 文件 更改并保存 Win + R Cmd Ipconfig /flushdns Windows 输入法设置搜狗双拼 搜狗双拼键位 添加双拼方案 编辑方案 (更新之后的模板需要选择 微软双拼) Windows 移除右键已卸载项How to Remove Apps from the “Open With” List in Windows - Make Tech Easier PowerToys Run Open PowerShell当使用 PowerToys Run 开启 PowerShell 的时候，启动的路径是继承的 PowerToys 的目录，所以找不到很多系统的组件。 Powershell $env:path changing depending on how it is opened (PowerToys Run)? Windows 常见问题与解决方案Windows 扩展卷无法使用用扩展卷的方式给 C 盘增加空间—扩展卷无法使用，这是由于需要扩展的空间和 C 盘未直接相邻。 打开 cmd，输入 diskpart 并回车。 输入 list disk 并回车查看磁盘。 输入 select disk n 选择 C 盘所在磁盘。 输入 list partition 并回车查看分区。 输入 select partition n 选择中间的恢复分区。 输入 delete partition override 删除分区，扩展卷功能可正常使用。 Windows Process Exited with Code 1 已退出进程代码为 1 Press Win+R to open the Run prompt. Type regedit &gt; press the Enter button &gt; click the Yes button. Navigate to this path: 1HKEY_CURRENT_USER\\Software\\Microsoft\\Command Processor Right-click on the Autorun String value and select Delete. Click on the Yes button. Restart your computer and enter the same command. Fix Process exited with code 1 error in Windows Terminal, PowerShell or CMD Windows 个人文件夹路径混乱修复和恢复默认设置 Win+R Regedit Find User Shell Folders Edit the wrong items win10 中个人文件夹路径混乱修复和恢复默认设置 Windows 10 错误的设置了用户文件夹位置怎么恢复","link":"/07035776a388/"},{"title":"Windows 系统闹钟铃声更改","text":"本文主要介绍了 Windows 系统闹钟铃声更改的方法。 更改 Windows 系统默认铃声进入 Media 文件夹Windows 系统闹钟应用铃声固定只有十个，只能在十个铃声之间选择，十个铃声和铃声名称之间有唯一的映射关系。铃声文件存储的路径位于 C:\\Windows\\Media 可以通过更改默认铃声文件的方式实现自定义铃声，但系统闹钟应用中的铃声名称无法更改。 更改原文件权限 右键进入属性 进入安全高级 所有者更改 选择用户或组高级 (A) 授权完毕，将 Alarm 01. Wav 文件重命名为 Alarm 01. Wav. Bak. 对 Alarm 02. Wav 文件进行同样操作。 将上课铃声重命名为 Alarm 01. Wav，下课铃声重命名为 Alarm 02. Wav ，将文件移入 C:\\Windows\\Media 文件夹，则系统闹钟铃声的前两个被替换为上课铃声和下课铃声。 系统闹钟应用设置定时闹钟 进入系统闹钟应用，添加闹钟。 上课闹钟选择第一个铃声编钟，下课闹钟选择第二个铃声 铃声播放完毕后消除即可。","link":"/8b839dcda589/"},{"title":"Zotero6 使用经验积累","text":"本文主要记录了 Zotero6 的使用经验， 包括软件的使用、插件的使用、Citation Style Language 等。 Zotero 软件使用 注意需要知道的是，很多批准的数据是存在于 Zotero 的数据库里面的，这个时候如果通过其他的 PDF 阅读器打开 PDF 是看不到那些批注的。只有对 PDF 进行的修改才可以在所有的地方都看到。 Zotero 的附件类型Zotero 附件类型包括： 文件: 图标为系统默认图标或者 adobe 红，是 Zotero 默认的附件格式，存放在 &lt;Data Directory Location&gt;/storage 内一个 8 位数字和字母的子目录中。 文件链接: 图标为白色加小铁链，通常由 ZotFile 生成，实际保存在 &lt;Linked Attachment Base Directory&gt; 下。 url 链接: 图标为蓝色加小铁链，实际为文件的网址，联网时才能打开。 Zotero vs Mendeley Comparison - York University Libraries 插件 ZotFile 的使用 功能 可以实现文件的批量重命名和格式化命名 可以实现附件的跨设备同步 可以使用 ZotFile 曲线救国的方式来达到查找库里删除的文件，但是本地还有的文件，方法就是修改重命名规则，进行重命名，然后看修改时间。 使用 使用 subfolder 重命名规则保持一致 ZotFile 配合同步盘实现附件跨平台、跨设备同步 配置附件链接的根目录 配置附件链接根目录 &lt;Linked Attachment Base Directory&gt; 是 文件链接 附件的实际位置。 当 Zotero 访问 文件链接 附件时，会访问此目录下的相对路径。 为了达到同步附件的目的，需要将 &lt;Linked Attachment Base Directory&gt; 设置为同步盘的子目录。 下载安装 ZotFile 配置 ZotFile 打开 ZotFile Preferences 下的 General Settings 标签页。 Source Folder for Attaching new Files 设置为 Data Directory Location 下的 storage Location of Files 设置为 Linked Attachment Base Directory Zotero 跨平台同步附件的实现 Zotero 5.0 使用教程/坚果云同步盘和 Zotero 的配置过程详解 插件 DOI Manager插件 Better BibTeX for Zotero这个插件可以实现参考文献库自动更新，但是取消的时候也需要进入相对应的位置进行查看。 插件 QuicklookZotero | 这款插件让 Zotero 具备文献预览功能！ Citation Style Language首页 - CSL 中文文档 Citation Styles WebsiteAbout CSL Search by Name Visual CSL Editor “等” 和‘et al’[Zotero]直接同时生成”等”和”et al” 1234567891011121314zoteroPane = Zotero.getActiveZoteroPane();items = zoteroPane.getSelectedItems();var rn = 0; //计数替换条目个数var lan = &quot;en-US&quot;; //替换的语言for (item of items) { var la = item.getField(&quot;language&quot;); if (la == &quot;en&quot;) { //如果为空则替换 item.setField(&quot;language&quot;, lan); rn += 1; await item.saveTx(); }}return rn + &quot;个条目语言被替换为&quot; + lan + &quot;。&quot;; Zotero-journalabbr-pulgin这里使用的格式，只有语言的字段是 en-US 的时候， et al 和期刊缩写才会生效，所以需要手动更改语言字段（可以使用 json 语言，很快的），也需要补全缺失的 journal abbreviation。 参考内容Problems with CSL 1.0.1 citation-style specifications Zotero + CSL 编辑器，自定义文献引用格式，创建 PPT 中的短文献引用 如何在 Zotero 中设置中文参考文献格式？ 几个 GB/T7714 相关的 csl 文件 GitHub - redleafnew/Chinese-STD-GB-T-7714-related-csl: GB/T 7714 相关的 csl 以及 Zotero 使用技巧及教程。","link":"/26791113112c/"},{"title":"MATLAB 使用经验积累","text":"本文介绍了 MATLAB 的使用经验，包括软件设置、软件功能等。 Documentation - MATLAB &amp; Simulink (mathworks.com) MATLAB 软件设置更换默认字体 下载安装字体 YaHei Consolas Hybrid 字体（英文字体：Consolas，最好的 coding；中文字体：YaHei） 重启 MATLAB，主页-&gt;预设-&gt;字体，选择 YaHei Consolas Hybrid，如图 修改起始文件夹与语言 123% 修改起始文件夹edit matlabrc.madd &quot;cd 'your start path'&quot; 软件功能读取文件夹下所有文件 使用dir函数： 123dir('.') % 列出当前目录下所有子文件夹和文件dir('G:\\Matlab') % 列出指定目录下所有子文件夹和文件dir('*.m') % 列出当前目录下符合正则表达式的文件夹和文件 代码示例： 12345678910111213namelist = dir('F:\\File\\*.txt');% 读取后 namelist 的格式为% name -- filename% date -- modification date% bytes -- number of bytes allocated to the file% isdir -- 1 if name is a directory and 0 if notlen = length(namelist);for i = 1:lenfile_name{i}=namelist(i).name;x= load(file_name{i});end 批量保存 .mat 文件 使用 save命令，可以批量保存文件。 例如，已知矩阵 A，将 A 矩阵的每一列进行拆分，分别保存在 1-points.mat, 2-points.mat, 3-points.mat 中，代码如下： 1234567A=[0.7329 -0.0000 19.2805;-0.0000 0.7329 25.0947]for i=1:3 chr=[num2str(i),'-points.mat'] b=A(:,i) save(chr,'b')end 遍历结构体成员12345678910data.name1 = 1;data.name2 = 2;data.name1 % 方式一data.name2field = fieldnames(data); % cellfor i = 1:length(field) name_i = field{i}; % 这里需要注意，用的是{}，不是() value_i = getfield(data, name_i) % 方式二 value_i = data.(name_i) % 方式三end matlab 遍历结构体 struc 的成员 - 那抹阳光 1994 - 博客园 (cnblogs.com) 使用函数作为参数使用函数作为参数","link":"/ee86b7cd0583/"},{"title":"Jupyter Notebook 使用经验积累","text":"本文主要介绍了 Jupyter Notebook 的使用经验。 安装与启动12pip install jupyterlab #安装jupyter-lab #启动 指定端口启动与启动服务器但不打开浏览器参考 Reference： Jupyter Notebook 介绍、安装及使用教程 设置 Jupyter Notebook 文件存放位置 创建文件夹，复制文件夹路径 配置文件夹路径，一个便捷获取配置文件所在路径的命令 Jupyter notebook --generate-config 注意： 这条命令虽然可以用于查看配置文件所在的路径，但主要用途是是否将这个路径下的配置文件替换为默认配置文件。 如果是第一次查询，那么或许不会出现下图的提示；若文件已经存在或被修改，使用这个命令之后会出现询问“Overwrite /Users/raxxie/. Jupyter/jupyter_notebook_config. Py with default config? [y/N]”，即“用默认配置文件覆盖此路径下的文件吗？”，如果按“y”，则完成覆盖，那么之前所做的修改都将失效；如果只是为了查询路径，那么一定要输入“N”。 Windows 系统的配置文件路径：C:\\xxxxx\\.jupyter 修改文件 使用文档编辑工具或 IDE 打开“jupyter_notebook_config. Py”文件并进行编辑。 查找关键词“c.NotebookApp. Notebook_dir”，取消注释该行，把“第一步：创建文件夹/目录”步骤中复制的路径粘贴在此处。 修改 Jupyter 的默认目录 打开终端 输入命令 jupyter notebook –generate-config 找到 # c.NotebookApp. Notebook_dir = ‘’，取消注释并更改目录","link":"/e0f15432da34/"},{"title":"Obsidian 使用经验积累","text":"本文主要介绍了 Obsidian 软件的使用经验，包括 Obsidian 基本介绍，Obsidian 核心插件，Obsidian 社区插件等。 Home - Obsidian Help Obsidian 基本介绍软件使用哲学使用 Obsidian 记录的原则在于：一切的笔记文件都存储于自己的设备之上，以 Markdown 文件的形式。 所以需要熟练掌握 Markdown 笔记的书写规范，以及形成自己的笔记整理的工作流。 软件功能 Settings 里的 Auto convert HTML 可以在粘贴的时候将链接自动转换为 Markdown 格式的链接。 软件快捷键由于是在 Obsidian 中，所以快捷键不区分大小写，这里为了可读性，直接用大写字母代替。 快捷键 功能 Ctrl + E 切换阅读模式与编辑模型 Ctrl + L 新建代办事项 Obsidian 核心插件Core plugins - Obsidian Help Backlinks - Obsidian Help File explorer - Obsidian Help Properties view - Obsidian Help","link":"/cf5c5898a0fe/"},{"title":"ANSYS 有限元仿真学习","text":"本文首先介绍了 ANSYS 产品组件，然后介绍了 Workbench 和 APDL 仿真流程，最后列举了一些 APDL 仿真经验积累。 ANSYS 产品组件介绍Ansys Gets Into Open Source With GitHub | Ansys PyAnsys — PyAnsys Ansys MechanicalAnsys Mechanical enables you to solve complex structural engineering problems and make better, faster design decisions. With the finite element analysis (FEA) solvers available in the suite, you can customize and automate solutions for your structural mechanics problems and parameterize them to analyze multiple design scenarios. Ansys Mechanical is a **dynamic tool that has a complete range of analysis tools. Ansys Mechanical | Structural FEA Analysis Software Ansys Parametric Design Language (APDL)Ansys Parametric Design Language (APDL) is a powerful structured scripting language used to interact with the Ansys Mechanical solver. Mechanical APDL (MAPDL), a finite element analysis program, is driven by APDL. APDL and MAPDL can be used for many tasks, ranging from creating geometries for analysis to setting up sophisticated solver settings for highly complex analyses. Ansys was the first commercial simulation tool provider to offer users a versatile programming language to create parametric models for systemic analyses. What is APDL? Ansys Parametric Design Language Ansys LS-DYNAAnsys LS-DYNA is the most used explicit simulation program in the world and is capable of simulating the response of materials to short periods of severe loading. Its many elements, contact formulations, material models and other controls can be used to simulate complex models with control over all the details of the problem. Ansys LS-DYNA | Crash Simulation Software Workbench Tutorials Pre-analysis: before we start the simulation Analysis Post-analysis: before we leave the tool 接触面类型：Target169(硬)/contact171(软) Workbench 分析流程 分析类型选取 材料选择和添加 模型建立及导入 网格划分 边界条件的设定 载荷施加 求解及后处理 Basic Procedure for Finite Element Analysis /PREP7 Define the solid model geometry Select the element types Define the material properties Mesh /SOLU Define the boundary conditions Define the loads Set the solution options Solve /POST1 Plot, view, and export the results Compare and verify the results Ansys Mechanical Courses Ansys Academic Support | Tutorials &amp; Training Materials Ansys Mechanical Getting Started | Ansys Training Ansys Mechanical Linear and Nonlinear Dynamics | Ansys Training APDL Tutorials Introduction to Ansys Mechanical APDL | Ansys Training Introduction to Ansys Mechanical APDL Scripting | Ansys Training Ansys Mechanical Advanced - Use of MAPDL in Mechanical | Ansys Training Manipulating Text Strings in ANSYS Mechanical APDL - PADT ANSYS 有限元分析 接触分析_Hulunbuir 的博客-CSDN 博客_hulunbuir ansys 13.174. CONTA174 - 3-D 8-Node Surface-to-Surface Contact APDL 仿真经验积累 Mechanical APDL Command Reference (bme.hu) Mapped Meshing (adina.com) ANSYS APDL Warning: r/ANSYS (reddit.com) Ansys Warning: Both solid model and finite element model boundary conditions have been applied to this model ? - FAQS.TIPS Having trouble using the *VWRITE command in APDL. Can someone help me? | ResearchGate","link":"/9a4280b0fd34/"},{"title":"LabVIEW 基础知识学习记录","text":"本文主要记录 LabVIEW 的基础知识学习记录，包括 LabVIEW 的基础知识、NI-DAQmx 的基础知识、Simcenter Testlab 的基础知识等。 关于 Siemens Simcenter Testlab SoftwareSiemens Simcenter Testlab software 的前身是 LMS Test.Lab 软件。LMS Test. Lab 是由 LMS International 公司开发的一整套震动噪声试验解决方案，后来 Siemens 收购了 LMS International 公司。 Siemens Simcenter Testlab 树形目录： Siemens Digital Industries Software | Siemens Software Simcenter simulation software | Siemens Software Simcenter physical testing | Siemens Software Simcenter Testlab | Siemens Software Simcenter SCADAS | Siemens Software 要点记录甲方要求最后达到的水准，也就是编写的 VI 程序需要实现的功能： 信号的采集：每间隔多长时间采集一次数据； 数据存储：数据存储需要遵守的规则，文件的命名方式； 数据的处理：对采集到的数据进行处理，如求得振动烈度、均方根、峭度、傅里叶变换等； 给定阈值，超出之后报警，报警之后的两件事，也就是响应： 控制器闪烁 记录 采集数据时使用的通道。 基础知识 LabVIEW - NI NI-DAQmx 帮助 - NI Measurement &amp; Automation Explorer (MAX) - NI Package Manager - NI NI 公司National Instruments （美国国家仪器有限公司，简称 NI）创立于- 76 年，总部设于德克萨斯州首府奥斯汀，是一家测量行业的上市公司。 LabVIEW 简介LabVIEW (Laboratory Virtual Instrument Engineering Workbench) 是一种用图标代替文本行创建应用程序的图形化编程语言。传统文本编程语言根据语句和指令的先后顺序决定程序执行顺序，而 LabVIEW 则采用数据流编程方式。在数据流编程方式下，数据在程序框图节点中的流动决定了 VI 和函数的执行顺序。VI (virtual instruments) 指虚拟仪器，是可模拟物理仪器的 LabVIEW 程序模块。 LabVIEW 提供很多外观与传统仪器（如示波器、万用表）类似的控件，可用来方便地创建用户界面。用户界面在 LabVIEW 中称为前面板。前面板创建完毕后，可使用图形化的函数添加源代码来控制前面板上的对象。图形化代码，即 G 代码或程序框图代码，是添加在程序框图上的代码。程序框图在某种程度上与流程图类似。程序框图、前面板和图形化代码共同构成一个完整 VI。 目前最新的版本是 LabVIEW - 20 和 LabVIEW NXG，其中 2020 可以说是经典产品的延续，各功能块都很丰富，但是 NI 也感受到了来自竞争对手以及物联网发展的压力，尝试做了新的改变，NXG 就应运而生，可以说不同于以往的经典产品，NXG (next generation) 是在新的开发平台上尝试，主要区别是开发语言 G 语言，当然由于是新平台开发的产品，功能结构和经典款有较大区别，甚至说有些缺失，不过目前还算是过渡阶段，后续 NXG 产品功能会不断丰富，不久的将来将全面取代经典产品。NXG 的最大亮点是要拓展工业物联网方面的应用，这也是传统自动化仪器仪表行业所欠缺的，相信随着其不断开发和技术成熟，NXG 能在工业物联网领域有所发展。 LabVIEW 也是一种编程语言，只不过是基于图形编程实现的，类似于 G 语言，所以需要学习基本的编程语法。LabVIEW 软件需要配合 NI-DAQmx 驱动来使用，而 NI-DAQmx 驱动基于的对象是 NI 的 DAQ 设备。LabVIEW 作为一个软件，还需要熟悉软件的布局以及快捷键这类知识，基础的知识学会了之后就需要结合实际的项目学习编写大型的程序了。 重点是，所有的语言类学习，基于项目的学习的速度都是最快的。所以一定要结合项目一起学习。在学习的过程中一定要善于利用 LabVIEW 和 DAQmx 提供的帮助文档，里面有详细的内容，虽然不一定易于理解。 首先需要弄清楚 LabVIEW 创建的 project 和 .vi 程序之间的关系，也就是说一个项目的结构是什么样的。LabVIEW 里面开发的程序单元被称作 VI（Virtual Instruments，虚拟仪器），文件的扩展名是 .vi ，就像是用 c 语言开发的 .c 文件或 C++开发的 .cpp 文件等。当然，现在 LabVIEW 开发环境下还包括其它的程序组织类型，如工程（. Lvproj）、类（. Lvclass）、模板（. Vit）、库（. Llb）等。这些类型有的是为了更好地组织开发工作，有的是为了获得更高效、复用性更好的程序。 . Vi 文件是整个 LabVIEW 开发的核心。 NI-DAQmx 简介NI-DAQmx 入门指南 - NI DAQ (Data Acquisition)：DAQ 是英文 Data Acquisition （数据采集）的缩写。数据采集（DAQ）是指测量：电压、电流、温度、压力、声音、编码数据等电气或物理现象的过程。 NI-DAQmx 是用于与 NI 数据采集 (DAQ)设备通信并控制设备的驱动程序软件。它包含一个用途广泛的函数和 VI 库，可从 LabVIEW 或 LabWindows/CVI 中调用库函数，对 NI 设备进行编程。 NI-DAQmx 是一款 NI 仪器驱动程序，可控制 DAQ 系统的各个方面，包括信号调理，从配置到 LabVIEW 编程，再到低级操作系统和设备控制。您可以使用特定于测量的 VI，功能，数据类型和分析集成来构建应用程序，并通过优化的 DMA 数据传输和单点 I / O 可靠地进行更快速的测量。 通过将 NI DAQ 设备和第三方仪器组合到 LabVIEW NXG 应用程序中，了解如何自动化和自定义测量。使用随仪器驱动程序提供的示例，使用台式仪器重复采集或生成信号。使用仪器示例作为起点，构建一个使用 NI DAQ 设备采集数据并使用台式仪器生成信号的自动化应用程序。 NI MAX 简介NI Measurement＆Automation Explorer (NI MAX) 是随 NI-DAQmx 自动安装的应用程序。 NI MAX 可告知其他程序系统中现有的设备及其配置。通过 NI MAX，可： 配置 NI 硬件和软件 创建和编辑通道、任务、接口、换算和虚拟仪器 进行系统诊断 查看与系统连接的设备和仪器 更新 NI 软件 DAQ 助手简介DAQ 助手是随 NI-DAQmx 自动安装的应用程序，可在在 MAX 或 LabVIEW、SignalExpress、LabWindows/CVI、Measurement Studio 等 NI 应用软件中打开 DAQ 助手。通过 DAQ 助手，可︰ 创建和编辑任务及虚拟通道 向任务添加虚拟通道 创建和编辑换算 测试自定义配置 保存自定义配置 在 NI 应用软件中生成代码以用于自定义应用程序 查看传感器的连线图 关于软件的安装利用 LabVIEW 搭建开发环境，整个安装过程包括： 安装 LabVIEW 开发平台、模块和工具包； 安装 NI 设备驱动程序； 安装硬件。 说明： LabVIEW 的安装，建议不要修改安装目录，否则会导致安装失败。 NI-DAQmx 的安装，安装过程中会出现多次失败，可以多次重复，如果重复无法解决问题，只需要重启之后继续安装即可。 整个安装过程会花费较长的时间，保持耐心即可。 VI Package Manager 和 NI Package Manager 的区别 VI 程序包管理器，就是安装第三方工具包，包括 NI 官网和论坛下载到的第三方工具包所用的，安装之后就可以使用第三方的一些工具包，比如前面板的一些按钮控件，程序框图中的一些函数等。 JKI VI Package Manager ​ 可 ​ 识别、​ 创建 ​ 和 ​ 安装 ​ LabVIEW​ 附加 ​ 工具。 JKI VI Package Manager​ 是 ​ 一个 ​ 附加 ​ 软件 ​ 工具，​ 用于 ​ 查找 ​ 并 ​ 安装 ​ NI Tools Network​ 上 ​ 的 ​LabVIEW​ 附加 ​ 工具。​ 您 ​ 可以 ​ 使用 ​ JKI VI Package Manager​ 为 ​ 开发 ​ 人员 ​ 和 ​ 客户 ​ 构 ​ 建 ​ 可 ​ 复 ​ 用 ​ 的 ​ 代码 ​ 库 ​ 和 ​ 工具，​ 以及 ​ 在 ​LabVIEW​ 中 ​ 管理 ​ 和 ​ 维护 ​ 程序 ​ 包。 NI Package Manager​ 是 ​ 安装、​ 升级 ​ 和 ​ 管理 ​NI​ 软件 ​ 的 ​ 中心。 LabVIEW 编程经验积累LabVIEW 软件快捷键 Ctrl + B 删除断线 Ctrl + E 切换面板 Ctrl + R 立即运行 Ctrl + S 及时保存 Ctrl + T 左右两栏显示 其他功能即时帮助 错误处理 整理程序 高亮显示执行过程（调试过程中显示数据流） 其他BNC 接头，是一种用于同轴电缆的连接器，全称是 Bayonet Nut Connector（刺刀螺母连接器，这个名称形象地描述了这种接头外形），又称为 British Naval Connector（英国海军连接器，可能是英国海军最早使用这种接头）或 Bayonet Neill Conselman（Neill Conselman 刺刀，这种接头是一个名叫 Neill Conselman 的人发明的）。","link":"/e33e40915968/"},{"title":"LabVIEW 使用经验积累","text":"本文介绍了 LabVIEW 生成独立可执行程序和安装程序的方法。 LavVIEW 基础功能的实现LabVIEW 格式化字符串数据库中时间的格式为 Datetime 格式但 LabVIEW 自带的时间获取函数格式与 DateTime 格式不对应。转换方法为使用格式化日期/时间字符串. Vi 格式化字符为%Y-%m-%d%H:%M:%S%3 u 格式化后输出 2016-08-2914:28:19.080 参考 LabVIEW 实现串口通信LabVIEW 实现串口通信 DAQ 助手多通道操作DAQ 助手多通道 输出部分 字符串日期转换为时间标识字符串日期转换为时间标识 LabVIEW 的 TDMS 格式文件存储与读取 TDMS 文件格式简介 我们用 Labview 编写上位机的过程中，一般都会遇到文件存储的问题，例如接收到下位机上传的数据，这些实时数据需要保存起来，方便以后进行数据分析。大部人的第一反应是用数据库，如果数据量不大的话，是可以用 Access 数据库存储数据的，但是如果存储的数据量过大，且需要实时存储，此时用 Access 数据库的话可能会导致计算机内存占用过大进而导致计算机卡顿；但是，使用 TDMS 方式存储实时数据就不会出现这个问题。 TDMS 全称 Technical Document Management System，最早是机务工程维修中高效管理技术资料等数据的计算机管理系统。TDMS 文件是 NI 公司推出的数据管理系统，以二进制方式存储数据，文件很小，速度很快，可以很好的解决实时数据的存储问题。TDMS 文件分为文件、通道组和通道三个部分。 简单文件读/写 波形数据读/写 二维数组读/写 TDMS 可以存储二维数组或者字符串二维数组，数组的每一列作为一个通道。 TDMS 文件存储与读取 LabVIEW 程序要点现有的问题： 写文件的时候不能显示，数据线程冲突 写入的文件：每一个文件 LabVIEW 队列的使用 队列数据的传输，只能有一个入队列一个出队列，如果需要多输出的话，需要创建多个队列。 队列的写入需要放在循环里面。 队列的大小控制需要谨慎，一不小心就会出问题。 找一个别人的振动测试软件，学习一下界面的设置，美化一下自己的界面。 数据分析的结果保存到数据库，数据还是以文件的形式保存。这个需要和客户商量。 数据库操作创建数据库 create table test(time timestamp, freq float[], amp float[]); 写入数据库 insert into test(time,freq, amp) values(‘2021-7-18:13:47:45’,‘{1,2,3}’, ‘{10,8,9}’); 查询数据库 select * from test PgAdmin III PostgreSQL 清空表并保留表结构、清空数据库还原数据库为新建时的状态的方法一般情况下，我们使用 delete 删除表中数据，但是 delete 是一条数据一条数据来删除表中的数据，直至表清空（保留表结构），但是当数据量很大时，它耗时较久。 其实，删除表数据但保留表结构使用 truncate 更快速安全，使用方法为： 当表没有其他关系时 TRUNCATE TABLE tablename; 当表中有外键时，要用级联方式删所有关联的数据 TRUNCATE TABLE tablename CASCADE; 清空数据库还原数据库为新建时的状态，在 postgreSQL 中，创建数据库时会自动创建 public 模式，一般我们把表都保存在该模式中，因此直接删除该模式再重新创建该模式。若数据在其他模式中，则把 public 换为数据表所在模式即可。 删除 public 模式以及模式里面所有的对象 DROP SCHEMA public CASCADE; 创建 public 模式 CREATE SCHEMA public; LabVIEW 项目软件开发待开发功能列表 两个板卡共用一套软件 BID 拨码 报警的功能：连续几个周期出现问题，就报警 现有数据采用什么特征处理？数据的均方差 数据的最大值 振动烈度 如何进行状态监测？每隔一段时间，读取 TDMS 文件 软件分为哪些模块？数据处理模块 历史数据分析 数据回放 开发过程经验记录 如何实现数据的拼接？ LabVIEW 每通道采样数=采样率 采样率和采样数的设置 数据 $\\rightarrow$ 数据拼接 $\\rightarrow$ 数据处理 生产者、消费者模式 LabVIEW 项目软件生成我的安装程序和我的应用程序关于 LabVIEW 运行引擎任何电脑，只要你想在上面运行 LabVIEW 生成的独立可执行程序（exe），你都需要在目标电脑上安装 LabVIEW 运行引擎。LabVIEW 运行引擎包含了： 运行 LabVIEW 生成的可执行程序所需要的库和文件 使用浏览器远程访问前面板所需的浏览器插件 应用程序中生成 LabVIEW 报表所需要的一些组件 一些 3 D 图表的支持等 运行引擎本身就是支持多语言的，不需要安装特定语言版本的运行引擎。 另外需要确保目标电脑上安装的运行引擎版本与开发应用程序时使用的 LabVIEW 版本一致。 如果你想在一台电脑上运行多个版本的 LabVIEW 生成的可执行程序，那你的电脑必须安装与这些 LabVIEW 版本一一对应的多个版本的运行引擎。 不同版本的 LabVIEW 运行引擎可以在 NI 官方网站上免费下载到。 关于硬件驱动如果您的程序使用了 NI 硬件的驱动，那么在目标电脑上就需要安装对应版本的驱动程序。 以 DAQmx 为例，比方说您在实现一个数据采集任务时用到了某个版本的 DAQmx 驱动，将来在目标电脑上就需要安装对应版本的 DAQmx 驱动。 综上所述，目标电脑上安装 LabVIEW 运行引擎是必须的，而硬件驱动的安装则取决于您的程序是否有使用该硬件驱动。 准备工作生成 独立可执行程序 和 安装程序 需要用到应用程序生成器，LabVIEW 专业开发版包含有应用程序生成器，基础版和完全开发版则需要单独购买。 在生成独立可执行应用程序之前需要做一些检查工作，LabVIEW 帮助文档中列出了一个检查列表：http://zone.ni.com/reference/en-XX/help/371361J-01/lvconcepts/build_checklist/ 生成我的应用程序 新建一个 LabVIEW 项目，或者打开一个已经建好的项目，项目中包含了您的 vi，确保 vi 运行正常。一些通过文件路径来使用文件的代码在编译成 exe 之后可能会出现文件找不到的错误，对于此类错误，可以参考 KB：5SD4CE7K, 3HKEK93U, 2T6GI6BH, 18RDJ60O。新建的项目如图： 在项目浏览器的程序生成规范处右键单击新建 $\\rightarrow$应用程序（EXE） 设置目标文件名和目标目录。目标文件名是您将来生成的 exe 文件名，该文件位于目标目录中，默认的目标目录会在项目所在目录的上一级目录中新建一个 builds 文件夹，生成的 exe 文件保存到这个目录中。如图 选择源文件，选中顶层 vi 单击“添加项”箭头将顶层 vi 添加到启动 vi 栏中，其他用到的子 vi 和文件可以添加到始终包括栏中，如图 可以使用 LabVIEW 默认图标作为应用程序图标，也可以选择自己设计一个图标：使用图标编辑器编辑并保存自己设计的图标，去掉“使用默认 LabVIEW 图标文件”前的勾选，在弹出的对话框中选择添加刚才保存的图标文件，注意“图标图像”的类型要与编辑该图标时选择的类型一致，如图 选择预览 $\\rightarrow$ 生成预览，然后可以看到将来会生成哪些文件，其中就包括我们的独立可执行应用程序，现在还看不到我们自定义的图标，不用着急，最后生成以后就可以看到了，如图 最后选择“生成”，LabVIEW 就会弹出生成状态窗口，当生成结束后会提示生成的应用程序所在路径，您可以单击浏览打开应用程序所在目录，然后就可以看到带自定义图标的应用程序了，如果单击完成，则会关闭生成状态窗口，如图 至此，我们已经完成了生成独立可执行应用程序的操作，如果目标电脑上已经安装了 LabVIEW 运行引擎和其他需要的组件，那么就可以将生成的 exe 文件拷贝到目标电脑上直接运行了。 以下篇幅介绍在生成 exe 的基础上如何生成 installer，即生成安装文件的操作。 生成我的安装程序 在同一个项目中右键单击程序生成规范，选择新建 $\\rightarrow$ 安装程序，如图 在“产品信息”中设置您的产品名称和安装程序生成目录，产品名称会影响安装程序所在的路径名，并且对应着在 windows 添加删除程序列表中应用程序的名字，如图 选择“目标”，修改目标名称，该名称决定了将来安装程序运行结束后，可执行文件会释放到哪个文件夹中，如图 选择“源文件”，在项目文件视图中单击选择之前创建的应用程序生成规范，然后单击添加箭头，将应用程序添加到目标文件夹中，右边目标视图可以看到添加结果，如图 选择“快捷方式”，修改右边的快捷方式名称和子目录名称。快捷方式名称对应着将来在开始菜单中看到的快捷方式图标的名称，子目录对应着快捷方式在开始菜单中所处的文件夹名称，如图 选择“附加安装程序”，勾选相应的 LabVIEW 运行引擎和必要的驱动程序以及工具包等，之后这些驱动以及工具包会一起包含在生成的 installer 中。LabVIEW 在这里会自动帮您勾选一些必要的 NI 安装程序，但是有可能并没有包含所有需要安装的程序，您的程序中使用到了哪些驱动以及工具包，在这里配置的时候就需要勾选哪些工具包。对于一些特定的工具包，如 NI OPCServers、DSC 运行引擎等不支持直接打包部署（KB: 5SS56RMQ 56P8BSJT），因此在这里会无法勾选或者勾选无效，这些工具包需要在目标电脑上再单独安装，如果您不能确定该工具包是否支持打包部署，请联系 NI 技术支持。 单击“生成”按钮开始生成安装程序，同样会弹出一个生成状态窗口，生成过程完成后，单击浏览可以打开安装文件所在路径，您会看到一个 setup. Exe 文件，这个文件就是最终的安装文件。单击“完成”按钮关闭状态窗口。如图 现在，您可以将打包生成好的安装程序拷贝到目标电脑上运行了，需要注意的是，拷贝的时候要将整个文件夹拷贝到目标电脑上然后再运行 setup. Exe，安装过程与普通 windows 应用程序没有区别，安装结束后您就可以在目标电脑上运行您自己的应用程序了。 使用 LabVIEW 如何生成应用程序（exe）和安装程序（installer） 项目软件 DAQ 数据采集程序安装指南安装 解压文件夹； 进入 我的安装程序/Volume/setup. Exe，双击安装。 数据采集 进入 我的应用程序/Volume/数据采集与存储. Exe 双击打开，界面如下： 选中所使用的通道： 选中 数据采集 选项卡； 更改左侧采样率，点击 开始 按钮，即可观测数据是否输入； 按照需要，更改右侧采集文件参数设置，点击 开始 按钮，即开始文件存储。 采集的文件以 TDMS 形式存放于 我的应用程序/Volume/数据采集与存储. Exe 同文件夹下： 注意事项如果遇到设置错误，需要关闭软件，重新打开进行设置。","link":"/275db2337dd9/"},{"title":"基于 Alist 和 RaiDrive 挂载云盘到本地","text":"本文首先介绍了基于 Alist 进行多个云盘管理，然后介绍了基于 RaiDrive 挂载云盘到本地的过程，最后介绍了基于 PowerShell 脚本自动化挂载的操作。 Alist 管理多个云盘Alist 文档 Alist 使用指南 第一步：安装本文介绍 Windows 系统下最新版 Alist 使用方法，其他系统请参考 Alist 文档。 Alist 手动安装 1234567# 下载 Alistunzip alist-xxxx.zip # 解压下载的文件，得到可执行文件# 第一次启用时需要设置密码，然后登录.\\alist.exe admin random # 随机生成密码.\\alist.exe admin set NEW_PASSWORD # # 手动设置一个密码 `NEW_PASSWORD`是指你需要设置的密码# 下次直接启用，使用设置的密码登录.\\alist.exe server # 启动 Alist 服务 安装完之后在浏览器登录：http://127.0.0.1:5244/@login. 第二步：添加云盘登录完成后点击底部 Manage/管理 按钮，进入管理界面。 从左侧的 Storages 导航进入添加云盘界面，添加自己的云盘，下面是一些需要注意的设置项： Driver: 选择云盘类型，这里选择 AliyunDriveOpen，即阿里云盘； Mount Path: 设置挂载路径，这里设置为 阿里云盘，即在 Alist 界面中显示的云盘名称； WebDAV policy: 设置 WebDAV 策略，这里选择 native proxy，即使用 Alist 自带的 WebDAV 代理； Refresh Token: 设置阿里云盘的 Refresh Token，这里使用 Alist 提供的工具 获取； Order by: 设置排序方式，这里选择 name，即按照名称排序； Order direction: 设置排序方向，这里选择 asc，即升序排列。 设置完成后启用服务然后登录即可以看到添加的云盘，点击云盘名称即可进入云盘。 Alist 使用指南：添加阿里云盘 Open RaiDrive 挂载云盘到本地RaiDrive 官网 RaiDrive 说明文档 点击添加，选择 NAS 选项，然后选择 WebDAV； 进行如下设置：取消选择地址，设置地址和端口为 Alist 服务的地址和端口，这里是 http://127.0.0.1和5244，然后输入 Alist 设置的 admin 密码，点击确定即可。 PowerShell 脚本自动化挂载利用 PowerShell 脚本自动化挂载云盘到本地有两个理由： 由于每次关机之后 Alist 服务会停止，所以需要每次开机后手动启动 Alist 服务； RaiDrive 可以设置自动启动，但是会有广告弹窗，且自启动的方式不是我喜欢的模式。 123456Set-Location -Path &quot;Path to alist.exe&quot; # need to change directory to where the alist.exe is locatedWrite-Host &quot;Current directory is: $pwd&quot;Write-Host &quot;Launch RaiDrive...&quot;Start-Process -FilePath &quot;Path to RaiDrive.exe&quot; # need to change directory to where the RaiDrive.exe is locatedWrite-Host &quot;Launch Alist server...&quot;.\\alist.exe server 将以上代码保存为 alist.ps1，并将其路径添加到 PowerShell $PROFILE 中，即可以在 Terminal 中自动化挂载。","link":"/cdc589e0e429/"}],"tags":[{"name":"ANSYS","slug":"ANSYS","link":"/tags/ANSYS/"},{"name":"FEM","slug":"FEM","link":"/tags/FEM/"},{"name":"Alist","slug":"Alist","link":"/tags/Alist/"},{"name":"RaiDrive","slug":"RaiDrive","link":"/tags/RaiDrive/"},{"name":"PowerShell","slug":"PowerShell","link":"/tags/PowerShell/"},{"name":"CLI","slug":"CLI","link":"/tags/CLI/"},{"name":"Terminal","slug":"Terminal","link":"/tags/Terminal/"},{"name":"Shell","slug":"Shell","link":"/tags/Shell/"},{"name":"Git","slug":"Git","link":"/tags/Git/"},{"name":"GitHub","slug":"GitHub","link":"/tags/GitHub/"},{"name":"Coding","slug":"Coding","link":"/tags/Coding/"},{"name":"Blog","slug":"Blog","link":"/tags/Blog/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"JAX","slug":"JAX","link":"/tags/JAX/"},{"name":"Flax","slug":"Flax","link":"/tags/Flax/"},{"name":"Jupyter Notebook","slug":"Jupyter-Notebook","link":"/tags/Jupyter-Notebook/"},{"name":"Gitee","slug":"Gitee","link":"/tags/Gitee/"},{"name":"PicGo","slug":"PicGo","link":"/tags/PicGo/"},{"name":"LabVIEW","slug":"LabVIEW","link":"/tags/LabVIEW/"},{"name":"LaTeX","slug":"LaTeX","link":"/tags/LaTeX/"},{"name":"MATLAB","slug":"MATLAB","link":"/tags/MATLAB/"},{"name":"Obsidian","slug":"Obsidian","link":"/tags/Obsidian/"},{"name":"Vim","slug":"Vim","link":"/tags/Vim/"},{"name":"Neovim","slug":"Neovim","link":"/tags/Neovim/"},{"name":"PyTorch","slug":"PyTorch","link":"/tags/PyTorch/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"TensorFlow","slug":"TensorFlow","link":"/tags/TensorFlow/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"Ubuntu","slug":"Ubuntu","link":"/tags/Ubuntu/"},{"name":"VPN","slug":"VPN","link":"/tags/VPN/"},{"name":"VSCode","slug":"VSCode","link":"/tags/VSCode/"},{"name":"WSL","slug":"WSL","link":"/tags/WSL/"},{"name":"Windows","slug":"Windows","link":"/tags/Windows/"},{"name":"Machine Learning","slug":"Machine-Learning","link":"/tags/Machine-Learning/"},{"name":"Zotero","slug":"Zotero","link":"/tags/Zotero/"},{"name":"Deep Learning","slug":"Deep-Learning","link":"/tags/Deep-Learning/"},{"name":"Neural Network","slug":"Neural-Network","link":"/tags/Neural-Network/"},{"name":"Symbolic Regression","slug":"Symbolic-Regression","link":"/tags/Symbolic-Regression/"},{"name":"DSP","slug":"DSP","link":"/tags/DSP/"},{"name":"Fault Diagnosis","slug":"Fault-Diagnosis","link":"/tags/Fault-Diagnosis/"},{"name":"Mathematics","slug":"Mathematics","link":"/tags/Mathematics/"},{"name":"System Identification","slug":"System-Identification","link":"/tags/System-Identification/"},{"name":"Dynamics","slug":"Dynamics","link":"/tags/Dynamics/"},{"name":"Modal Analysis","slug":"Modal-Analysis","link":"/tags/Modal-Analysis/"},{"name":"Paper Submission","slug":"Paper-Submission","link":"/tags/Paper-Submission/"},{"name":"Time Series","slug":"Time-Series","link":"/tags/Time-Series/"},{"name":"Inverse Problem","slug":"Inverse-Problem","link":"/tags/Inverse-Problem/"},{"name":"Filter","slug":"Filter","link":"/tags/Filter/"},{"name":"C++","slug":"C","link":"/tags/C/"}],"categories":[{"name":"经验积累","slug":"经验积累","link":"/categories/%E7%BB%8F%E9%AA%8C%E7%A7%AF%E7%B4%AF/"},{"name":"知识学习","slug":"知识学习","link":"/categories/%E7%9F%A5%E8%AF%86%E5%AD%A6%E4%B9%A0/"},{"name":"项目开发","slug":"项目开发","link":"/categories/%E9%A1%B9%E7%9B%AE%E5%BC%80%E5%8F%91/"},{"name":"软件使用","slug":"软件使用","link":"/categories/%E8%BD%AF%E4%BB%B6%E4%BD%BF%E7%94%A8/"}],"pages":[{"title":"学术索引","text":"Academic Search Engines arXiv Google Scholar ResearchGate Sci-Hub 国家自然科学基金大数据知识管理服务门户 Publisher Search Engine AAAS Science ACM ACM Digital Library ASME ASME Digital Collection Elsevier Elsevier ScienceDirect IEEE IEEE Xplore National Academy of Sciences PNAS Oxford University Press Oxford Academic Springer Nature Nature Search Springer Nature SpringerLink Springer Nature Springer Nature Showcase Taylor &amp; Francis Taylor &amp; Francis Online Wiley Wiley Online Library Elsevier Journals Journal Artificial Intelligence Automatica Computer Methods in Applied Mechanics and Engineering Computers &amp; Structures Computers in Industry ISA Transactions Journal of Computational and Applied Mathematics Journal of Computational Physics Journal of Sound and Vibration Mechanical Systems and Signal Processing Measurement Engineering Applications of Artificial Intelligence Applied Soft Computing IEEE Journals Journal IEEE Sensors Journal IEEE Transactions on Automatic Control IEEE Transactions on Industrial Electronics IEEE Transactions on Industrial Informatics IEEE Transactions on Instrumentation and Measurement IEEE Transactions on Neural Networks and Learning Systems IEEE Transactions on Pattern Analysis and Machine Intelligence 其他期刊 Publisher Journal AAAS Science Advances Nature Communications Physics Nature Nature Communications Nature Nature Machine Intelligence Springer International Journal of Computer Vision (IJCV) Wiley Advanced Science 国际会议 Publisher Conference Neural Information Processing Systems Foundation Neural Information Processing Systems (NeurIPS) International Machine Learning Society International Conference on Machine Learning (ICML) ICLR Foundation International Conference on Learning Representations (ICLR) IEEE International Conference on Computer Vision (ICCV) 学者与论文合集 astro automata Prof. Ing. Jiří Tůma, CSc. (vsb.cz) Stephen P. Boyd (stanford.edu) Lennart Ljung, Linköping University (liu.se) Maziar Raissi Bayesian Deep Learning Workshop | NeurIPS 2021 labml.ai Annotated PyTorch Paper Implementations Mechanical Systems and Signal Processing | Physics-Informed Machine Learning Enabling Fault Feature Extraction and Robust Failure Prognosis | ScienceDirect.com by Elsevier 数据集 Nonlinear Benchmark Nonlinear Benchmark (google.com) Nonlinear Benchmark - Bouc-Wen (google.com) Two-story frame with Bouc-Wen hysteretic links as a multi-degree of freedom nonlinear response simulator | Zenodo Bearing Data Center | Case School of Engineering | Case Western Reserve University","link":"/academic-index/index.html"},{"title":"在线资源","text":"Online Books Book Link GitHub Code Deep Learning Book Link Dive into Deep Learning Link Finite Difference Computing with PDEs - A Modern Software Approach Link Code Neural networks and deep learning Link Adapted for Math 204 at the University of Victoria Link Introduction to Probability for Data Science Link Deep Learning with PyTorch Link Deep Learning for Time Series Data Cookbook None Code Machine Learning Engineering Open Book Link Kalman and Bayesian Filters in Python Link Code State Space Models: A Modern Approach Link Code 在线书籍 书籍 链接 代码 简单粗暴 TensorFlow 2 Link Code TensorFlow 2.0 实战教程，30 天快速上手！ Link None 神经网络与深度学习 Link 动手学深度学习 Link 统计计算(北京大学-李东风) Link 深度学习教程中文版 Link CS 自学指南 Link 计算机体系结构基础 Link None AI 算法工程师手册 Link None Online Courses Courses Link Notes Stanford AI Courses Link None Stanford - Deep Learning Link CS 230 - Deep Learning - Deep Learning Tips and Tricks cheatsheet Purdue - Machine Learning Link Toronto - Neural Networks and Machine Learning Link Stanford - Unsupervised Feature Learning and Deep Learning Tutorial Link MIT - Analysis and Design of Feedback Control Systems Link Washington - Meachanical Engineering Analysis Link Applied Mathematics Link Vibration data Matlab Linear Algebra Link Multivariable Calculus Link Software on Windows Fences Utools Quicker Snipaste Optimizer ContextMenuManager","link":"/online-resources/index.html"},{"title":"项目文档","text":"General Documentations MS Docs Center Git Docs MS GitHub Docs MS Visual Studio Docs MS Visual Studio IDE Docs Weights &amp; Biases Docs Google Style Guides CppCoreGuidelines Microsoft Projects Projects Projects [MS .NET] [Documentation] [MS C#] [Documentation] [MS PowerShell] [Documentation] [MS PowerToys] [Documentation] [MS Terminal] [Documentation] [MS VS Code] [Documentation] [MS WSL] [Documentation] [MS winget] [Documentation] Python PackagesBest-of Machine Learning with Python Projects Projects [TensorFlow] [Documentation] [PyTorch] [Documentation] [JAX] [Documentation] [Flax] [Documentation] [Keras] [Documentation] [Einops] [Documentation] [Scikit-learn] [Documentation] [Numpy] [Documentation] [Matplotlib] [Documentation] [Pandas] [Documentation] [Scipy] [Documentation] [Hydra] [Documentation] [Black] [Documentation]","link":"/official-projects/index.html"}]}